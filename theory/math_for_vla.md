# VLA 数学必备：从直觉到实作（Math for VLA Implementers）

> **目标**：这不是数学系教材，而是“为了能看懂论文、写出 loss、调好机器人”的最小实践清单。
> **核心直觉**：深度学习 = 用微积分（优化）去寻找概率（模型）的最优参数；机器人学 = 用线性代数与几何描述物理移动。

---

## 0. 动作视角：我们在控制什么？

在 VLA 中，动作输出通常有两种主要的数学表示：

### 0.1 关节空间（Joint-space）
- **公式**：
  $$q = [q_1, q_2, \dots, q_n]^\top \in \mathbb{R}^n$$
- **变量定义**：`q` (关节向量), `n` (自由度/电机个数)。
- **物理意义**：直接控制马达旋转角度。
- **公式大白话**：
  - **给定** 一个机器人。
  - **翻译**：我直接告诉每个电机关联几度（比如大臂抬 30 度，手腕转 10 度）。这是最原始的控制方式。

### 0.2 任务空间（Task-space / TCP）
- **公式**：
  $$\Delta x = [\Delta p_x, \Delta p_y, \Delta p_z, \Delta \theta_x, \Delta \theta_y, \Delta \theta_z]^\top \in \mathbb{R}^6$$
- **变量定义**：`Δp` (平移增量), `Δθ` (旋转增量)。
- **物理意义**：控制末端执行器（TCP）在空间中的移动。
- **公式大白话**：
  - **给定** 一个目标位置。
  - **翻译**：我告诉机器人“往左挪 5 厘米，往下低 2 度”。我不管关节怎么动，我只管手去哪。

---

## 1. 线性代数：模型的大脑

### 1.1 内积与相似度（Dot Product）
- **公式**：
  $$\text{sim}(A, B) = A \cdot B = \sum_{i=1}^d A_i B_i = \|A\| \|B\| \cos(\theta)$$
- **变量定义**：`A, B` 是特征向量；`d` 是维度；`theta` 是它们之间的夹角。
- **物理意义**：当向量方向完全一致时，内积最大；正交时为 0。它是衡量“语义相似度”的核心。
- **公式大白话**：
  - **给定** 两个向量（比如图像特征和文本特征）。
  - **翻译**：把它们对应的每一项相乘再加起来。如果结果很大，说明它们在同一个方向上，模型认为它们“很像”。
- **ASCII 描述系统（向量投影）**：
```text
          B (目标向量)
         /
        /  . (相似度 = A 在 B 上的投影长度)
       /  /
      /--/---> A (当前向量)
```

### 1.2 矩阵乘法与线性层
- **公式**：
  $$y = Wx + b$$
- **变量定义**：`x` (输入, `d_in`), `y` (输出, `d_out`), `W` (权重, `d_out x d_in`), `b` (偏置, `d_out`)。
- **物理意义**：将高维特征从一个语义空间投影到另一个空间。
- **公式大白话**：
  - **给定** 输入特征 `x`。
  - **翻译**：通过矩阵 `W` 对 `x` 进行“加权组合”，再加个偏置 `b`，得到新的特征 `y`。这相当于把信息从“视觉空间”搬到了“动作空间”。

### 1.3 低秩分解与 LoRA
- **公式**：
  $$\Delta W = A \cdot B, \quad A \in \mathbb{R}^{d \times r}, B \in \mathbb{R}^{r \times k}$$
- **变量定义**：`r` 是**秩（Rank）**，通常 `r << d, k`。
- **物理意义**：假设大模型的知识更新只需要在极小的子空间内进行。LoRA 通过训练 `A` 和 `B` 来大幅减少参数量。
- **公式大白话**：
  - **给定** 一个巨大的权重改变量 `ΔW`。
  - **翻译**：我们不用直接存那个大矩阵，而是把它拆成两个很窄的矩阵 `A` 和 `B` 相乘。就像把一张高清大图压成两个极小的特征条，既省显存又能学到核心变化。

---

## 2. 微积分与优化：学习的驱动力

### 2.1 链式法则（Chain Rule）
- **公式**：
  $$\frac{\partial \mathcal{L}}{\partial x} = \frac{\partial \mathcal{L}}{\partial y} \cdot \frac{\partial y}{\partial x}$$
- **变量定义**：`L` (最终损失), `y` (上一层输出/激活值), `x` (当前层参数/输入)。
- **物理意义**：误差的回溯。它定义了如何将最终的 Loss 误差分配给网络中的每一个神经元。
- **公式大白话**：
  - **给定** 最终的错误评分 `L`。
  - **翻译**：如果想知道底层参数 `x` 对错误的贡献，先看上一层 `y` 对错误的影响，再看 `x` 是如何导致 `y` 变化的。就像找事故责任，一级级往回追溯。

### 2.2 雅可比矩阵（Jacobian）
- **公式**：
  $$J(q) = \frac{\partial f(q)}{\partial q}, \quad \dot{x} = J(q) \dot{q}$$
- **变量定义**：`f(q)` (正向运动学函数), `q` (关节向量), `x_dot` (末端速度), `q_dot` (关节速度)。
- **深度解析**：
  - **物理直觉**：它描述了机器人每个关节的“微小转动”如何转换成末端坐标的“微小位移”。
  - **公式大白话**：
    - **给定** 关节的变化速度 `dq`。
    - **翻译**：把每个关节的速度乘以它对应的权重（雅可比矩阵里的项），就能算出机器人手指头在空间里往哪飘、飘多快。
  - **逆运动学 (IK)**：在 VLA 中，如果模型输出的是末端增量 $\Delta x$，我们需要求 $\Delta q \approx J(q)^{-1} \Delta x$。
  - **奇异位形 (Singularity)**：当 Jacobian 矩阵的行列式为 0（矩阵不满秩）时，意味着机器人处于某些尴尬姿势（如手臂伸得笔直），此时末端在某些方向上无法移动，数学上会导致逆矩阵爆炸。
- **ASCII 描述系统（小变化传递）**：
```text
    关节速度 q_dot  ---[ Jacobian J ]--->  末端速度 x_dot
    
    [ Δq1 ]      [ J11 J12 ... ]      [ Δx ]
    [ Δq2 ]  *   [ J21 J22 ... ]  =   [ Δy ]
    [ ... ]      [ ... ... ... ]      [ Δz ]
    
    直觉: J 就像是不同关节对末端位移的“杠杆率”。
```
- **VLA 应用**：**末端控制适配**。即使 VLA 预测的是笛卡尔坐标系的动作，底层控制器也必须通过 Jacobian 将其转化为关节电机的电流或位置命令。

### 2.3 梯度裁剪（Gradient Clipping）
- **公式**：
  $$g = \min\left(1, \frac{\text{threshold}}{\|g\|_2}\right) \cdot g$$
- **变量定义**：`g` (原始梯度向量), `threshold` (设定的最大模长/阈值), `||g||_2` (梯度的 L2 范数/长度)。
- **深度解析**：
  - **痛点：梯度爆炸**。在 Transformer 或长序列 VLA 训练中，由于损失函数的地形非常陡峭（像悬崖），某个 Batch 的梯度可能会瞬间变得极大。
  - **公式大白话**：
    - **给定** 算出来的梯度 `g`。
    - **翻译**：看看这个梯度的“力气”是不是太大了（超过了阈值）。如果是，就按比例把它“缩”回去，但还是往原来的方向使劲。
  - **后果**：权重更新过猛（$w \leftarrow w - \eta g$），导致参数直接飞出有效范围（NaN），模型崩溃。
  - **机制**：如果梯度的“长度”（L2 范数 $\|g\|_2$）超过了设定的阈值，就把整个梯度向量按比例缩放回阈值长度，但保持其**方向**不变。
- **ASCII 描述系统（几何视图）**：
```text
          未裁剪梯度 g (太长了!)
          /
         / 
        /  . (阈值圈 threshold)
       /  /
      /--/---> 裁剪后的梯度 g' (保留方向，缩短长度)
```
- **VLA 应用**：**多模态平衡**。视觉、文本和动作数据的梯度量级可能完全不同，裁剪能防止某一种模态（如动作预测的剧烈波动）主导甚至摧毁整个模型的权重。
- **物理直觉**：就像是在悬崖边开车，限制你的最大油门。你可以往任何方向开，但速度不能超过安全极限。

---

## 3. 概率与损失：衡量“对不对”

### 3.1 条件概率与贝叶斯（Conditional Probability & Bayes）
- **公式**：
  $$P(a | s, g) = \frac{P(s, g | a) P(a)}{P(s, g)}$$
- **变量定义**：`P(a|s,g)` (在给定状态 s 和目标 g 下采取动作 a 的概率), `P(a)` (动作的先验分布), `P(s,g|a)` (似然项)。
- **物理意义**：VLA 模型的核心本质就是一个条件概率分布。它回答了：“看到这个场景，为了达成这个目标，最该做的动作是什么？”
- **公式大白话**：
  - **给定** 环境 `s` 和任务 `g`。
  - **翻译**：我们要找一个动作 `a`，让它在当前这个特定条件下发生的可能性最大。就像在餐馆点菜，你的选择（动作）取决于菜单（状态）和你的口味（目标）。

### 3.2 负对数似然（NLL）
- **公式**：
  $$\mathcal{L}_{NLL} = -\log P(a | s, g)$$
- **变量定义**：`a` 为动作；`s` 为观测状态；`g` 为目标。
- **物理意义**：最大化专家动作出现的概率。
- **公式大白话**：
  - **给定** 当前看到的画面 `s` 和任务目标 `g`。
  - **翻译**：计算模型预测出“专家那个动作 `a`”的概率有多大。概率越大（越接近 1），这个 Loss 就越小。目标是让模型百分之百猜对专家的选择。

### 3.3 交叉熵（Cross-Entropy）
- **公式**：
  $$H(P, Q) = - \sum_i P(x_i) \log Q(x_i)$$
- **变量定义**：`P` (真实标签的分布，通常是 One-hot), `Q` (模型预测的概率分布)。
- **物理意义**：衡量两个分布之间的信息量差距。
- **公式大白话**：
  - **给定** 一个标准答案 `P`。
  - **翻译**：看看模型给出的答案 `Q` 和标准答案有多“合拍”。如果模型在错误选项上浪费了太多概率，这个得分就会很惨。

### 3.4 变分推断与 ELBO（Evidence Lower Bound）
- **公式**：
  $$\text{ELBO} = \mathbb{E}_{q(z|x)}[\log p(x|z)] - D_{KL}(q(z|x) \| p(z))$$
- **变量定义**：`x` (观测数据), `z` (潜变量), `q(z|x)` (编码器), `p(x|z)` (解码器), `p(z)` (先验分布)。
- **物理意义**：这是 VAE 和 ACT 框架的数学灵魂。它要求模型既能精准还原动作（第一项），又不能让隐含空间太乱（第二项）。
- **公式大白话**：
  - **给定** 复杂的动作数据。
  - **翻译**：我们想把动作压缩成一个简单的“潜空间密码”。第一项要求这个密码能解开（还原回动作），第二项要求这个密码要长得像个标准的高斯分布，别太离谱。
- **ASCII 描述系统（ACT 视角）**：
```text
    输入 (s, a) ---> [编码器 q] ---> 潜变量 z (满足正态分布 KL)
                                      |
                                      v
    输出 (a_pred) <--- [解码器 p] <---+--- 输入 (s, g)
    
    直觉: ELBO 就是在“还原精度”和“分布规整度”之间找平衡。
```

### 3.5 KL 散度（KL Divergence）
- **公式**：
  $$D_{KL}(P \| Q) = \sum_{i} P(x_i) \log \frac{P(x_i)}{Q(x_i)}$$
- **变量定义**：`P` 是真实分布（或目标分布），`Q` 是模型预测分布。
- **物理意义**：衡量两个分布的非对称“距离”。在 RL 中用于限制策略更新步长。
- **公式大白话**：
  - **给定** 两个分佈（一个是标准的 `P`，一个是模型的 `Q`）。
  - **翻译**：如果用 `Q` 去模仿 `P`，会损失多少信息？如果结果很大，说明两个分布长得完全不一样。
- **ASCII 描述系统 (RL PPO 裁剪)**：
```text
          L_clip (损失函数值)
             ^
             |      /----------\ (平原: 即使优势很大，也不再更新)
             |     /            \
    (不更新) --/--------------    \--- (不更新)
             |   /  (激进区)
    ---------+------------------------> r_theta (新旧策略比)
             0   1.0-eps  1.0  1.0+eps

    直觉: 只要新旧策略差异超过 eps，梯度就“断”了，强制模型小步快跑。
```

### 3.3 重参数化（Reparameterization Trick）
- **公式**：
  $$z = \mu + \sigma \odot \epsilon, \quad \epsilon \sim \mathcal{N}(0, I)$$
- **变量定义**：`z` (最终采样的动作/隐含向量), `μ` (分布的均值), `σ` (分布的标准差), `ε` (标准正态分布产生的外部噪声)。
- **深度解析**：
  - **核心痛点**：如果你直接从 $\mathcal{N}(\mu, \sigma)$ 采样一个动作 $z$，采样这个动作（Sampling）本身是随机的、**不可导**的。误差无法传回 $\mu$ 和 $\sigma$。
  - **公式大白话**：
    - **给定** 均值 `μ` 和标准差 `σ`。
    - **翻译**：与其直接从分布里“盲抽”一个动作，不如先拿一个标准的纯噪声 `ε`，把它拉长 `σ` 倍，再挪到 `μ` 的位置。这样动作 `z` 就变成了一个可以用公式算出来的“确定值”，模型就能学会怎么调整 `μ` 和 `σ` 了。
  - **解决方案**：把“随机性”从参数中剥离。让模型预测均值 $\mu$ 和标准差 $\sigma$，然后引入一个独立的标准正态分布噪声 $\epsilon$。
  - **结果**：$z$ 现在是关于 $\mu$ 和 $\sigma$ 的**确定性函数**（线性组合）。由于 $\epsilon$ 是独立的，反向传播可以绕过它，直接更新 $\mu$ 和 $\sigma$。
- **ASCII 描述系统（计算流图）**：
```text
    不可导 (采样在中间):         可导 (重参数化):
    
    [mu, sigma]               [mu, sigma] ----+
         |                          |         |
    ( 采样 a ) <--- 阻断 --- Loss   ( a = mu + sigma * eps ) <--- Loss
         |                          |
       噪声                         eps (噪声外挂)
```
- **VLA 应用**：**ACT (CVAE) 架构**。ACT 输出的动作不是死板的，而是从一个潜空间分布中采样的，重参数化保证了我们可以训练这个“灵活”的分布。

---

## 4. 几何与变换：物理世界的导航

### 4.1 齐次变换矩阵（SE(3)）
- **公式**：
  $$T = \begin{bmatrix} R & t \\ 0 & 1 \end{bmatrix}, \quad P_A = T_{AB} P_B$$
- **变量定义**：`R` (3x3 旋转矩阵), `t` (3x1 平移向量)。
- **物理意义**：从坐标系 B 到坐标系 A 的点位映射。
- **公式大白话**：
  - **给定** 坐标系 B 里的一个点 `P_B`。
  - **翻译**：左乘变换矩阵 `T_AB`，就能算出这个点在另一个坐标系 A（比如机器人基座）里的位置。就像把“相机拍到的坐标”翻译成“手臂能看懂的坐标”。
- **ASCII 描述系统**：
```text
      [Frame A] (基座)           [Frame B] (相机)           [Frame C] (目标)
          Z                         Z                         Z
          |   T_ab (标定矩阵)        |   T_bc (识别结果)        |
          +----> X   ==========>    +----> X   ==========>    +----> X
         /                         /                         /
        Y                         Y                         Y

    变换公式: P_in_A = T_ab * T_bc * P_in_C  (从右往左读，像剥洋葱)
```

### 4.2 旋转的表示
- **变量定义**：`Roll/Pitch/Yaw` (三个轴的旋转角), `6D Rotation` (通常指旋转矩阵的前两列, 6 个实数)。
- **物理意义**：描述物体是怎么“歪”的。
- **公式大白话**：
  - **给定** 一个旋转动作。
  - **翻译**：如果用欧拉角，就像在球面上走，走到南北极就会迷路（万向节死锁）；如果用 6D 旋转，就像在平滑的高速公路上开车，怎么转都不会突然跳变，神经网络学起来最舒服。
- **ASCII 描述系统（流形直觉）**：
```text
    欧拉角 (有断层):  ---[死锁点]--- (导致控制跳变)
    6D 旋转 (平滑):   ~~~~~~~~~~~~~~~~ (连续可导，适合神经网络学习)
```

---

## 5. 控制与时间：动作的物理约束

### 5.1 动作平滑（Action Smoothness）
- **公式**：
  $$\mathcal{L}_{smooth} = \lambda_1 \sum \|a_t - a_{t-1}\|^2 + \lambda_2 \sum \|(a_t - a_{t-1}) - (a_{t-1} - a_{t-2})\|^2$$
- **变量定义**：`a_t` (第 t 步的动作), `λ1, λ2` (平滑系数权重), `a_t - a_{t-1}` (速度), `(a_t - a_{t-1}) - (a_{t-1} - a_{t-2})` (加速度/Jerk)。
- **物理意义**：第一项惩罚速度过快，第二项惩罚加速度（Jerk）过大。
- **公式大白话**：
  - **给定** 一串连续的动作命令。
  - **翻译**：如果相邻两帧动作跳得太远，或者加速太猛，就给模型“扣分”。目标是让机器人动起来像丝绸一样顺滑，而不是一惊一乍地“抽风”。
- **VLA 应用**：确保生成的轨迹在真实硬件上不会产生震动或剧烈冲击。

---

## 6. 前沿：扩散与流匹配

### 6.1 扩散模型前向过程（Diffusion Forward）
- **公式**：
  $$x_t = \sqrt{\bar{\alpha}_t} x_0 + \sqrt{1 - \bar{\alpha}_t} \epsilon, \quad \epsilon \sim \mathcal{N}(0, I)$$
- **变量定义**：`x0` 是原始动作，`xt` 是 `t` 步后的带噪动作，`alpha_bar` 是噪声进度表，`ε` 是高斯噪声。
- **物理意义**：将动作逐步转化为纯随机噪声。
- **公式大白话**：
  - **给定** 一个完美的专家动作轨迹 `x0`。
  - **翻译**：按照时间步 `t`，把原始动作弄模糊一点（乘以一个缩放系数），再往里加一点随机噪声 `ε`。时间越久（`t` 越大），原始动作留下的痕迹就越少，最后变成一堆乱码。
- **ASCII 描述系统**：
```text
    [训练: 加噪] x0 (动作) ---> x1 ---> ... ---> xT (纯噪声)
    [推理: 去噪] x0 (生成) <--- x1 <--- ... <--- xT (采样)
                 ^          |预测噪声 ε|          ^
                 |          └──────────┘          |
              (高清晰)       (迭代 T 步)        (全乱码)
```

### 6.2 流匹配向量场（Flow Matching Vector Field）
- **公式**：
  $$v_t = x_1 - x_0, \quad x_t = (1-t)x_0 + t x_1$$
- **变量定义**：`x0` (目标动作), `x1` (初始噪声), `vt` (流速度/向量场), `xt` (t时刻在直线上的位置)。
- **物理意义**：在 $x_0$ 和 $x_1$ 之间画一条直线。模型学习去预测这个直线的速度向量。
- **公式大白话**：
  - **给定** 噪声 `x1` 和目标动作 `x0`。
  - **翻译**：在它们之间拉一条直近的线。`vt` 就是在这条线上跑的速度方向。模型只需要学会“怎么从起点沿直线跑向终点”就行了，不需要像扩散模型那样绕弯路。

---

## 7. 状态估计与滤波：处理传感器的“脏数据”

### 7.1 卡尔曼滤波（Kalman Filter）核心直觉
- **公式（更新步）**：
  $$\hat{x}_k = \hat{x}_k^- + K_k (z_k - H \hat{x}_k^-)$$
- **变量定义**：`x_hat_k` (最终估计值), `x_hat_k^-` (根据模型预测的值), `K_k` (卡尔曼增益), `z_k` (传感器测量值), `H` (观测矩阵)。
- **物理意义**：在“模型预测”和“传感器测量”之间找平衡。
- **公式大白话**：
  - **给定** 机器人觉得自己在哪（预测）和传感器说它在哪（测量）。
  - **翻译**：如果传感器很准（噪声小），就多听传感器的；如果传感器老抽风，就多信自己的模型。`K` 就像一个权衡利弊的“端水大师”。
- **ASCII 描述系统（融合直觉）**：
```text
    预测分布 (虚线)       测量分布 (点线)
          _                      _
         / \                    / \
      --/---\--              --/---\--
          |                      |
          +----------[融合]-------+
                     |
                最终估计 (更窄、更准)
```

### 7.2 指数移动平均（EMA / Low-pass Filter）
- **公式**：
  $$y_t = \alpha \cdot x_t + (1 - \alpha) \cdot y_{t-1}$$
- **变量定义**：`xt` (当前瞬时输入), `yt` (平滑后的输出), `α` (平滑系数, 0-1)。
- **物理意义**：滤除高频抖动，保留长期趋势。
- **公式大白话**：
  - **给定** 此时此刻的原始数据。
  - **翻译**：不要全信这一次的数据，留一点百分比给过去。这样如果数据突然蹦一下，输出只会缓慢跟进，看起来很平滑。

---

## 8. 强化学习深层数学：从 BC 到自主进化的跨越

### 8.1 贝尔曼方程（Bellman Equation）
- **公式**：
  $$V(s) = \max_a \left( R(s, a) + \gamma \sum_{s'} P(s' | s, a) V(s') \right)$$
- **变量定义**：`V(s)` (状态价值), `R` (即时奖励), `γ` (折扣因子), `P` (环境转移概率)。
- **物理意义**：现在的价值 = 现在的奖励 + 未来的期望收益。
- **公式大白话**：
  - **给定** 现在的处境 `s`。
  - **翻译**：我这一步走得对不对，不仅看现在能不能吃到果子（即时奖励），还要看走完这一步之后，未来的日子是不是更有奔头（未来的总价值）。

### 8.2 策略梯度（Policy Gradient）
- **公式**：
  $$\nabla_\theta J(\theta) = \mathbb{E} [ \nabla_\theta \log \pi_\theta(a|s) \cdot A(s, a) ]$$
- **变量定义**：`J` (总目标函数), `π` (策略网络), `A` (优势函数, 动作比平均水平好多少)。
- **物理意义**：如果一个动作表现得好（A > 0），就增加这个动作出现的概率。
- **公式大白话**：
  - **给定** 模型做出的一个尝试。
  - **翻译**：如果结果比预期好（赢了），就顺着梯子往上爬，让下次做这个动作的可能性更大；如果搞砸了，就往反方向调。

---

## 9. 控制论数学：让模型输出变成物理动作

### 9.1 PD 控制（Proportional-Derivative）
- **公式**：
  $$u(t) = K_p e(t) + K_d \frac{de(t)}{dt}$$
- **变量定义**：`u` (控制输出, 如力矩), `e` (误差, 目标-当前), `Kp` (比例增益), `Kd` (微分增益)。
- **物理意义**：`Kp` 负责减小差距，`Kd` 负责防止冲过头（阻尼）。
- **公式大白话**：
  - **给定** 离目标的距离 `e`。
  - **翻译**：离得远就使大劲（Kp），快到了就赶紧踩刹车（Kd）。只有 Kp 机器人会像弹簧一样晃，有了 Kd 才能稳稳停住。

---

## 10. Transformer 内部的数学微操

### 10.1 缩放点积注意力（Scaled Dot-Product Attention）
- **公式**：
  $$\text{Attention}(Q, K, V) = \text{softmax}\left( \frac{QK^\top}{\sqrt{d_k}} \right) V$$
- **变量定义**：`Q` (查询), `K` (键), `V` (值), `dk` (向量维度)。
- **物理意义**：计算全局相关性。
- **公式大白话**：
  - **给定** 图像特征和任务指令。
  - **翻译**：拿指令（Q）去图像里到处对比（K），看哪里最匹配。除以根号 `dk` 是为了防止数字太大导致梯度消失。最后按匹配度把图像里的有用信息（V）抓出来。

---

## 11. 优化器与采样微操：决定训练成败的细节

### 11.1 Adam 优化器（一阶与二阶动量）
- **公式**：
  $$m_t = \beta_1 m_{t-1} + (1-\beta_1) g_t, \quad v_t = \beta_2 v_{t-1} + (1-\beta_2) g_t^2$$
- **变量定义**：`mt` (速度/一阶动量), `vt` (路面颠簸程度/二阶动量), `gt` (当前梯度), `β1, β2` (衰减系数)。
- **物理意义**：`mt` 让你在顺坡时冲得更快，`vt` 在坡太陡（梯度波动大）时帮你踩刹车。
- **公式大白话**：
  - **给定** 此时此刻的坡度（梯度）。
  - **翻译**：不要只看这一步的坡，要记着之前的速度（动量）。如果路面一直很平，就加速；如果路面突然坑坑洼洼（梯度变化剧烈），就缩减步长，稳着点走。

### 11.2 温度采样（Temperature Scaling）
- **公式**：
  $$P_i = \frac{\exp(z_i / T)}{\sum \exp(z_j / T)}$$
- **变量定义**：`zi` (模型输出的原始分/Logits), `T` (温度)。
- **物理意义**：控制模型输出的“创造力”或“确定性”。
- **公式大白话**：
  - **给定** 模型的多个选择评分。
  - **翻译**：如果 `T` 很大，所有分数的差距就被拉平了，模型会开始乱试（随机性强）；如果 `T` 接近 0，最高分会压倒一切，模型变得非常死板、只敢选最有把握的。

---

## 12. 信息论基础：模型到底学到了什么？

### 12.1 熵（Entropy）
- **公式**：
  $$H(X) = - \sum P(x_i) \log P(x_i)$$
- **变量定义**：`P(xi)` (某个事件发生的概率)。
- **物理意义**：衡量不确定性。
- **公式大白话**：
  - **给定** 一个概率分布。
  - **翻译**：如果结果完全随机（像抛硬币），熵就很大；如果结果一眼就能看穿（百分百发生），熵就是 0。在强化学习中，我们有时会给熵加分，鼓励模型多去探索未知的可能性。

---

## 📅 实践者 2 周速成清单

- [ ] **Day 1-2**：齐次变换矩阵 SE(3) 与 6D 旋转。能够手写相机坐标系到机械臂基座的坐标转换流程。
- [ ] **Day 3-4**：雅可比矩阵 (Jacobian) 与 PD 控制。理解为什么末端速度控制需要通过 Jacobian 转为关节速度。
- [ ] **Day 5-6**：最大似然估计 (MLE) 与 NLL Loss。理解 MSE 其实就是假设噪声服从高斯分布时的 NLL。
- [ ] **Day 7-8**：重参数化技巧与 KL 散度。动手实现一个简单的 CVAE (ACT 的核心)。
- [ ] **Day 9-10**：扩散模型与流匹配。理清“预测噪声”与“预测速度场”的数学差异。
- [ ] **Day 11-12**：强化学习基础。理解贝尔曼方程如何处理“长远眼光”问题。
- [ ] **Day 13-14**：系统性实验。实现一个带 EMA 平滑、梯度裁剪和 Action 惩罚项的完整 VLA 训练循环。

---

[← 返回理论首页](./README.md)
