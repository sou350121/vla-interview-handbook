# VLA 数学必备：从直觉到实作（Math for VLA Implementers）

> **目标**：这不是数学系教材，而是“为了能看懂论文、写出 loss、调好机器人”的最小实践清单。
> **核心直觉**：深度学习 = 用微积分（优化）去寻找概率（模型）的最优参数；机器人学 = 用线性代数与几何描述物理移动。

---

## 0. 动作视角：我们在控制什么？

在 VLA 中，动作输出通常有两种主要的数学表示：

- **关节空间（Joint-space, `q`）**：
  - **内容**：直接控制马达旋转角度。
  - **数学**：
    $$q = [q_1, q_2, \dots, q_n]^\top \in \mathbb{R}^n$$
    其中 `n` 是机器人自由度（如 7 轴臂）。每个元素代表一个电机的角度或位置。
- **任务空间（Task-space, `x`）**：
  - **内容**：控制末端执行器（TCP）在空间中的位置和姿态。
  - **数学**：
    $$\Delta x = [\Delta p_x, \Delta p_y, \Delta p_z, \Delta \theta_x, \Delta \theta_y, \Delta \theta_z]^\top \in \mathbb{R}^6$$
    通常预测相对于当前位姿的**增量（Delta）**。前三个是平移，后三个是旋转表示（如欧拉角或旋转向量）。

---

## 1. 线性代数：模型的大脑

### 1.1 内积与相似度（Dot Product）
- **公式**：
  $$\text{sim}(A, B) = A \cdot B = \sum_{i=1}^d A_i B_i = \|A\| \|B\| \cos(\theta)$$
- **变量定义**：`A, B` 是特征向量；`d` 是维度；`theta` 是它们之间的夹角。
- **物理意义**：当向量方向完全一致时，内积最大；正交时为 0。它是衡量“语义相似度”的核心。
- **ASCII 描述系统（向量投影）**：
```text
          B (目标向量)
         /
        /  . (相似度 = A 在 B 上的投影长度)
       /  /
      /--/---> A (当前向量)
```

### 1.2 矩阵乘法与线性层
- **公式**：
  $$y = Wx + b$$
- **变量定义**：`x` (输入, `d_in`), `y` (输出, `d_out`), `W` (权重, `d_out x d_in`), `b` (偏置, `d_out`)。
- **物理意义**：将高维特征从一个语义空间投影到另一个空间。

### 1.3 低秩分解与 LoRA
- **公式**：
  $$\Delta W = A \cdot B, \quad A \in \mathbb{R}^{d \times r}, B \in \mathbb{R}^{r \times k}$$
- **变量定义**：`r` 是**秩（Rank）**，通常 `r << d, k`。
- **物理意义**：假设大模型的知识更新只需要在极小的子空间内进行。LoRA 通过训练 `A` 和 `B` 来大幅减少参数量。

---

## 2. 微积分与优化：学习的驱动力

### 2.1 链式法则（Chain Rule）
- **公式**：
  $$\frac{\partial \mathcal{L}}{\partial x} = \frac{\partial \mathcal{L}}{\partial y} \cdot \frac{\partial y}{\partial x}$$
- **物理意义**：误差的回溯。它定义了如何将最终的 Loss 误差分配给网络中的每一个神经元。

### 2.2 雅可比矩阵（Jacobian）
- **公式**：
  $$J(q) = \frac{\partial f(q)}{\partial q}, \quad \Delta x \approx J(q) \Delta q$$
- **变量定义**：`f(q)` 是正向运动学函数；`q` 是关节角；`x` 是末端位姿。
- **物理意义**：关节速度与末端速度之间的线性映射。
- **ASCII 描述系统（小变化传递）**：
```text
    关节变化 Δq  ---[ Jacobian J ]--->  末端变化 Δx
    
    [ Δq1 ]      [ J11 J12 ... ]      [ Δx ]
    [ Δq2 ]  *   [ J21 J22 ... ]  =   [ Δy ]
    [ ... ]      [ ... ... ... ]      [ Δz ]
    
    直觉: J 就像是不同关节对末端位移的“杠杆率”。
```

### 2.3 梯度裁剪（Gradient Clipping）
- **公式**：
  $$g = \min\left(1, \frac{\text{threshold}}{\|g\|_2}\right) \cdot g$$
- **物理意义**：防止“步子跨得太大”。如果梯度的模长超过阈值，就等比例缩放，保证训练稳定。

---

## 3. 概率与损失：衡量“对不对”

### 3.1 负对数似然（NLL）
- **公式**：
  $$\mathcal{L}_{NLL} = -\log P(a | s, g)$$
- **变量定义**：`a` 为动作；`s` 为观测状态；`g` 为目标。
- **物理意义**：最大化专家动作出现的概率。

### 3.2 KL 散度（KL Divergence）
- **公式**：
  $$D_{KL}(P \| Q) = \sum_{i} P(x_i) \log \frac{P(x_i)}{Q(x_i)}$$
- **变量定义**：`P` 是真实分布（或目标分布），`Q` 是模型预测分布。
- **物理意义**：衡量两个分布的非对称“距离”。在 RL 中用于限制策略更新步长。
- **ASCII 描述系统 (RL PPO 裁剪)**：
```text
          L_clip (损失函数值)
             ^
             |      /----------\ (平原: 即使优势很大，也不再更新)
             |     /            \
    (不更新) --/--------------    \--- (不更新)
             |   /  (激进区)
    ---------+------------------------> r_theta (新旧策略比)
             0   1.0-eps  1.0  1.0+eps

    直觉: 只要新旧策略差异超过 eps，梯度就“断”了，强制模型小步快跑。
```

### 3.3 重参数化（Reparameterization）
- **公式**：
  $$z = \mu + \sigma \odot \epsilon, \quad \epsilon \sim \mathcal{N}(0, I)$$
- **物理意义**：将不可导的“采样操作”转化为可导的“平移+缩放”。

---

## 4. 几何与变换：物理世界的导航

### 4.1 齐次变换矩阵（SE(3)）
- **公式**：
  $$T = \begin{bmatrix} R & t \\ 0 & 1 \end{bmatrix}, \quad P_A = T_{AB} P_B$$
- **变量定义**：`R` (3x3 旋转矩阵), `t` (3x1 平移向量)。
- **物理意义**：从坐标系 B 到坐标系 A 的点位映射。
- **ASCII 描述系统**：
```text
      [Frame A] (基座)           [Frame B] (相机)           [Frame C] (目标)
          Z                         Z                         Z
          |   T_ab (标定矩阵)        |   T_bc (识别结果)        |
          +----> X   ==========>    +----> X   ==========>    +----> X
         /                         /                         /
        Y                         Y                         Y

    变换公式: P_in_A = T_ab * T_bc * P_in_C  (从右往左读，像剥洋葱)
```

---

## 5. 控制与时间：动作的物理约束

### 5.1 动作平滑（Action Smoothness）
- **公式**：
  $$\mathcal{L}_{smooth} = \lambda_1 \sum \|a_t - a_{t-1}\|^2 + \lambda_2 \sum \|(a_t - a_{t-1}) - (a_{t-1} - a_{t-2})\|^2$$
- **物理意义**：第一项惩罚速度过快，第二项惩罚加速度（Jerk）过大。
- **VLA 应用**：确保生成的轨迹在真实硬件上不会产生震动或剧烈冲击。

---

## 6. 前沿：扩散与流匹配

### 6.1 扩散模型前向过程（Diffusion Forward）
- **公式**：
  $$x_t = \sqrt{\bar{\alpha}_t} x_0 + \sqrt{1 - \bar{\alpha}_t} \epsilon, \quad \epsilon \sim \mathcal{N}(0, I)$$
- **变量定义**：`x0` 是原始动作，`xt` 是 `t` 步后的带噪动作，`alpha_bar` 是噪声进度表。
- **物理意义**：将动作逐步转化为纯随机噪声。
- **ASCII 描述系统**：
```text
    [训练: 加噪] x0 (动作) ---> x1 ---> ... ---> xT (纯噪声)
    [推理: 去噪] x0 (生成) <--- x1 <--- ... <--- xT (采样)
                 ^          |预测噪声 ε|          ^
                 |          └──────────┘          |
              (高清晰)       (迭代 T 步)        (全乱码)
```

### 6.2 流匹配向量场（Flow Matching Vector Field）
- **公式**：
  $$v_t = x_1 - x_0, \quad x_t = (1-t)x_0 + t x_1$$
- **物理意义**：在 $x_0$ 和 $x_1$ 之间画一条直线。模型学习去预测这个直线的速度向量。

---

## 📅 实践者 2 周速成清单

- [ ] **Day 1-3**：重温矩阵乘法 & 齐次变换。
- [ ] **Day 4-6**：推导 MSE Loss 到高斯 NLL 的关系。
- [ ] **Day 7-9**：理解 PPO Clip 公式的分段函数。
- [ ] **Day 10-12**：理解 Diffusion 的重参数化加噪公式。
- [ ] **Day 13-14**：实现一个带 $\Delta a$ 惩罚的 BC 训练循环。

---

[← 返回理论首页](./README.md)
