# Galaxea G0: 双系统 VLA 框架

> [!IMPORTANT]
> **Galaxea G0** 是**星海图智能（Galaxea）** 开发的**双系统 VLA 框架**，通过分离**规划（VLM）**和**执行（VLA）**，实现了更强的泛化能力和长时域任务处理能力。

## 1. 概述
Galaxea G0 是一个创新的双系统架构，旨在解决传统单一 VLA 模型在**长时域移动操作**（long-horizon mobile manipulation）任务中的泛化瓶颈。

-   **开发者**: 星海图智能（Galaxea）
-   **论文**: [Galaxea Open-World Dataset and G0 Dual-System VLA Model (arXiv:2509.00576)](https://arxiv.org/abs/2509.00576)
-   **核心创新**: **双系统架构** - 将高层规划和低层执行解耦
-   **数据集**: Galaxea Open-World Dataset（500+ 小时，50 个真实场景）

## 2. 核心创新：双系统架构

### 2.1. 为什么需要双系统？
传统的单一 VLA 模型面临以下挑战：
-   **长时域任务**: 需要同时处理高层规划（"先去客厅，再去厨房"）和低层控制（"抓取杯子"）。
-   **泛化瓶颈**: 单一模型难以同时优化语义理解和精细操作。
-   **数据效率**: 需要大量端到端数据，但长时域数据收集成本极高。

### 2.2. G0 的解决方案：分层解耦
Galaxea G0 采用**两个独立但协作的模型**：

```
用户指令 → [ G0-VLM ] → 子任务序列 → [ G0-VLA ] → 机器人动作
          (规划大脑)                    (执行小脑)
```

#### 2.2.1. G0-VLM (Vision-Language Model)
-   **职责**: 多模态规划，高层推理
-   **输入**: 视觉观察 + 用户指令（如 "把客厅的杯子拿到厨房"）
-   **输出**: 子任务序列（如 `["导航到客厅", "抓取杯子", "导航到厨房", "放下杯子"]`）
-   **优势**: 保留 VLM 的强大语义理解和常识推理能力

#### 2.2.2. G0-VLA (Vision-Language-Action Model)
-   **职责**: 细粒度执行，低层控制
-   **输入**: 当前子任务 + 视觉观察
-   **输出**: 连续动作（关节角度、底盘速度）
-   **优势**: 专注于精确的感知-动作映射，不被长时域任务分心

## 3. 训练策略：三阶段课程学习

Galaxea G0 采用**三阶段渐进式训练**：

### 阶段 1: 跨具身预训练 (Cross-Embodiment Pre-training)
-   **数据**: Open X-Embodiment 等大规模多样化数据
-   **目标**: 学习通用的世界知识和动作先验
-   **效果**: 模型获得广泛的任务理解能力

### 阶段 2: 单具身预训练 (Single-Embodiment Pre-training)
-   **数据**: **Galaxea Open-World Dataset**（同一机器人 R1 Lite，500+ 小时）
-   **目标**: 适配特定机器人的感知-动作能力
-   **关键**: 这是 G0 性能提升的**核心阶段**

### 阶段 3: 任务后训练 (Task-Specific Post-training)
-   **数据**: 高质量的特定任务演示
-   **目标**: 精调复杂技能（如精细抓取、灵巧操作）
-   **效果**: 最终性能优化

## 4. Galaxea Open-World Dataset

这是 G0 的**关键数据资产**：

### 4.1. 数据规模
-   **时长**: 500+ 小时
-   **场景**: 50 个真实环境（住宅、厨房、零售、办公室）
-   **任务**: 150+ 种任务（移动、抓取、放置、导航）
-   **具身**: 统一使用 Galaxea R1 Lite 机器人

### 4.2. 数据特点
-   **真实世界**: 非模拟，真实的杂乱环境
-   **子任务标注**: 精确的层级标注（任务 → 子任务 → 动作）
-   **语言富集**: 每个子任务都有自然语言描述
-   **开源**: 完全公开，可用于研究

### 4.3. 与其他数据集的对比
| 数据集 | 时长 | 具身一致性 | 移动操作 | 子任务标注 |
| :--- | :--- | :--- | :--- | :--- |
| **Galaxea Open-World** | **500+ hr** | **单一机器人** | **✓** | **✓** |
| Open X-Embodiment | 1000+ hr | 多机器人 | 部分 | ✗ |
| BridgeData | 100+ hr | 单一机器人 | ✗ | ✗ |

## 5. 性能表现

G0 模型在多个基准测试中表现出色：

### 5.1. 桌面操作 (Tabletop Manipulation)
-   **成功率**: 显著优于单一 VLA 基线
-   **泛化**: 对新物体和新场景泛化能力强

### 5.2. 少样本学习 (Few-Shot Learning)
-   **优势**: 单具身预训练阶段使模型能快速适应新任务

### 5.3. 长时域移动操作 (Long-Horizon Mobile Manipulation)
-   **核心优势**: 双系统架构在多步骤任务中表现突出
-   **示例**: "从卧室拿遥控器到客厅，然后去厨房拿杯子" - 成功率 85%+

## 6. 双系统 vs 单系统
| 特性 | **双系统 (G0)** | 单系统 (传统 VLA) |
| :--- | :--- | :--- |
| **长时域任务** | **强（分层规划）** | 弱（端到端困难）|
| **泛化能力** | **强（VLM 保留）** | 中（易过拟合）|
| **数据效率** | **高（分阶段训练）** | 低（需大量端到端数据）|
| **推理速度** | 稍慢（两阶段）| 快（一次推理）|
| **可解释性** | **强（子任务可见）** | 弱（黑盒）|

## 7. 面试要点
-   **双系统架构**: 记住 G0-VLM（规划）+ G0-VLA（执行）的分工。
-   **三阶段训练**: 跨具身 → 单具身（关键）→ 任务后训练。
-   **Galaxea Open-World Dataset**: 500+ 小时，50 场景，统一具身，子任务标注。
-   **核心优势**: 长时域移动操作，泛化能力强。
-   **与其他模型对比**: 
    - vs Pi0: Pi0 是单一模型，G0 是双系统。
    - vs WALL-OSS: WALL-OSS 强调 Uni-CoT，G0 强调分层解耦。

## 8. 参考资源
-   **论文**: [arXiv:2509.00576](https://arxiv.org/abs/2509.00576)
-   **数据集**: [Hugging Face - Galaxea Open-World Dataset](https://huggingface.co/datasets/Galaxea/Open-World-Dataset)
-   **GitHub**: [Galaxea G0](https://github.com/Galaxea/G0)
-   **官网**: [星海图智能](https://galaxea-ai.com/)
