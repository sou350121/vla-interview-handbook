# VLA 总工程师研究方案 (2025-2030)

> **创建日期**: 2025-12-06
> **作者**: VLA 总工程师
> **背景**: 综合工程师与生物学家三轮辩论、VLA 十大挑战、当前技术现状
> **目标**: 制定务实但有远见的 VLA 研究路线图

---

## 一、战略定位: 我们在哪里，要去哪里

### 1.1 现状评估

```
┌─────────────────────────────────────────────────────────────────┐
│              VLA 技术成熟度评估 (2025 年初)                      │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│   感知层                                                        │
│   ├── RGB 视觉: ████████████████████ 90% 成熟                  │
│   ├── 深度感知: ████████████░░░░░░░░ 60%                        │
│   ├── 触觉集成: ████████░░░░░░░░░░░░ 40% ← 关键短板             │
│   └── 本体感觉: ██████░░░░░░░░░░░░░░ 30%                        │
│                                                                 │
│   认知层                                                        │
│   ├── 语言理解: ██████████████████░░ 85%                        │
│   ├── 空间推理: ██████████░░░░░░░░░░ 50%                        │
│   └── 因果推理: ████████░░░░░░░░░░░░ 40%                        │
│                                                                 │
│   执行层                                                        │
│   ├── 动作生成: ████████████████░░░░ 75%                        │
│   ├── 跨机器人: ████████░░░░░░░░░░░░ 40% ← 关键短板             │
│   └── 安全保障: ██████░░░░░░░░░░░░░░ 30% ← 关键短板             │
│                                                                 │
│   部署层                                                        │
│   ├── 算力效率: ████████████░░░░░░░░ 60%                        │
│   ├── Sim2Real: ██████████░░░░░░░░░░ 50%                        │
│   └── 持续学习: ████░░░░░░░░░░░░░░░░ 20%                        │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

### 1.2 核心洞察: 生物学家 vs 工程师辩论的结论

| 议题 | 生物学家观点 | 工程师观点 | **我的决策** |
| :--- | :--- | :--- | :--- |
| 层级控制 | 需要真正的层级 | 工程上已有 | **混合架构: VLA + 传统控制** |
| 预测编码 | 认知架构，不只是省计算 | 实现困难 | **渐进引入: 先关键节点，后全面** |
| 运动基元 | 关键缺失 | 我们在尝试 | **高优先级: 语义基元发现** |
| 触觉 | 必须有 | 必须有 | **第一优先级** |
| 安全性 | 系统属性 | 独立模块 | **从整合开始，向涌现演进** |

### 1.3 战略目标

```
┌─────────────────────────────────────────────────────────────────┐
│              2025-2030 战略目标                                  │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│   2025 年底: "能感知"                                           │
│   └── 触觉 + 本体感觉完整集成                                   │
│       成功率提升: 桌面操作 80% → 90%                            │
│                                                                 │
│   2027 年底: "能推理"                                           │
│   └── 运动基元 + 简化预测编码                                   │
│       数据效率提升: 10x (few-shot 新任务)                       │
│                                                                 │
│   2030 年底: "能协作"                                           │
│   └── 安全涌现 + 人机双向交互                                   │
│       部署规模: 万台级                                          │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

---

## 二、研究布局: 五大战线

### 战线 1: 多模态感知 (Multimodal Perception)

**问题**: VLA 是"截肢患者"，只有视觉

**目标**: 2025 年底实现视觉-触觉-本体感觉完整融合

```
┌─────────────────────────────────────────────────────────────────┐
│              多模态感知研究计划                                   │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│   P1.1 触觉集成 (最高优先级)                                    │
│   ┌─────────────────────────────────────────────────────────┐   │
│   │  阶段 1 (Q1-Q2 2025): 硬件选型与基础集成                 │   │
│   │  ├── DIGIT (低成本, 有预训练模型)                        │   │
│   │  ├── 千觉 GelStereo (高精度, 3D 输出)                    │   │
│   │  └── 开发统一的触觉数据格式                              │   │
│   │                                                          │   │
│   │  阶段 2 (Q3-Q4 2025): VLA 融合架构                       │   │
│   │  ├── 方案 A: 早期融合 (触觉 token 与视觉 token 混合)     │   │
│   │  ├── 方案 B: 双流融合 (独立编码，中层交叉注意力)         │   │
│   │  └── 消融实验确定最优方案                                │   │
│   │                                                          │   │
│   │  阶段 3 (2026): 触觉预训练                               │   │
│   │  ├── 自监督: 触觉图像预测任务                            │   │
│   │  ├── 利用 Meta Sparsh 迁移学习                           │   │
│   │  └── 建立触觉-语言对齐数据集                             │   │
│   └─────────────────────────────────────────────────────────┘   │
│                                                                 │
│   P1.2 本体感觉增强                                             │
│   ┌─────────────────────────────────────────────────────────┐   │
│   │  当前: 关节编码器 (位置)                                 │   │
│   │  目标: 位置 + 速度 + 力矩 + IMU                          │   │
│   │                                                          │   │
│   │  研究问题:                                               │   │
│   │  • 本体感觉如何编码? 独立 token vs 状态向量?            │   │
│   │  • 如何处理不同机器人的不同传感器配置?                   │   │
│   │  • 如何建立"身体图式"——让 VLA 知道自己的能力边界?       │   │
│   └─────────────────────────────────────────────────────────┘   │
│                                                                 │
│   P1.3 深度与 3D 理解                                           │
│   ┌─────────────────────────────────────────────────────────┐   │
│   │  短期: RGB-D 输入 (RealSense 等)                         │   │
│   │  中期: 多视角 3D 重建                                    │   │
│   │  长期: 神经隐式表示 (NeRF/3DGS 用于操作)                │   │
│   └─────────────────────────────────────────────────────────┘   │
│                                                                 │
│   里程碑:                                                       │
│   • M1.1 (2025 Q2): 触觉 VLA 原型，精细操作成功率 +15%        │
│   • M1.2 (2025 Q4): 多模态融合架构确定                        │
│   • M1.3 (2026 Q4): 发布开源多模态 VLA 训练框架               │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

**关键决策**:
- 硬件: 先用 DIGIT (有 Meta 预训练支持)，长期切 千觉 (更高精度)
- 架构: 尝试两种融合方案，数据驱动选择
- 数据: 必须建立触觉-语言对齐数据集

---

### 战线 2: 运动基元与层级控制 (Motor Primitives & Hierarchy)

**问题**: VLA 缺乏可重用的动作单元，每个任务从零学习

**目标**: 2027 年实现语义基元发现和层级控制

```
┌─────────────────────────────────────────────────────────────────┐
│              运动基元研究计划                                     │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│   P2.1 语义基元发现                                             │
│   ┌─────────────────────────────────────────────────────────┐   │
│   │  核心问题: 如何自动发现"语义有意义"的动作单元?           │   │
│   │                                                          │   │
│   │  方案 A: VLM 辅助标注                                    │   │
│   │  ├── 输入: 动作轨迹视频                                  │   │
│   │  ├── VLM: "这段动作在做什么?"                           │   │
│   │  ├── 输出: 语义标签 + 时间边界                           │   │
│   │  └── 聚类形成基元库                                      │   │
│   │                                                          │   │
│   │  方案 B: 层级 VAE                                        │   │
│   │  ├── 底层: 学习连续动作分布                              │   │
│   │  ├── 中层: 发现离散潜在变量 (基元 ID)                    │   │
│   │  └── 顶层: 基元序列规划                                  │   │
│   │                                                          │   │
│   │  方案 C: FAST + 语义对齐                                 │   │
│   │  ├── DCT + BPE 发现统计基元                              │   │
│   │  └── 与 VLM 语义空间对齐                                 │   │
│   └─────────────────────────────────────────────────────────┘   │
│                                                                 │
│   P2.2 层级控制架构                                             │
│   ┌─────────────────────────────────────────────────────────┐   │
│   │                                                          │   │
│   │   高层: VLM (任务理解, 目标设定)                          │   │
│   │          │ 子目标                                        │   │
│   │          ▼                                               │   │
│   │   中层: 基元选择器 (选择基元 + 参数)                     │   │
│   │          │ 基元 ID + 参数                                │   │
│   │          ▼                                               │   │
│   │   底层: 基元执行器 (生成连续动作)                        │   │
│   │          │ 关节命令                                      │   │
│   │          ▼                                               │   │
│   │   控制层: 传统控制 (PID/阻抗/MPC)                        │   │
│   │                                                          │   │
│   │   关键: 每层有自己的时间尺度                             │   │
│   │   • 高层: 秒级 (任务规划)                                │   │
│   │   • 中层: 100ms 级 (基元选择)                            │   │
│   │   • 底层: 10ms 级 (动作生成)                             │   │
│   │   • 控制层: 1ms 级 (伺服控制)                            │   │
│   │                                                          │   │
│   └─────────────────────────────────────────────────────────┘   │
│                                                                 │
│   P2.3 反馈整合 (借鉴生物学)                                    │
│   ┌─────────────────────────────────────────────────────────┐   │
│   │  生物学家的批评: 工程层级是单向的，没有反馈              │   │
│   │                                                          │   │
│   │  我的方案: 渐进式反馈                                    │   │
│   │  • 阶段 1: 底层 → 中层反馈 (执行状态)                   │   │
│   │  • 阶段 2: 中层 → 高层反馈 (基元完成/失败)              │   │
│   │  • 阶段 3: 全层级双向 (类似生物)                        │   │
│   └─────────────────────────────────────────────────────────┘   │
│                                                                 │
│   里程碑:                                                       │
│   • M2.1 (2026 Q2): 基元库 v1 (50+ 语义基元)                  │
│   • M2.2 (2026 Q4): 层级控制原型                              │
│   • M2.3 (2027 Q4): Few-shot 新任务学习 (只需学基元组合)      │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

**关键决策**:
- 先用 VLM 辅助标注 (方案 A)，再探索自动发现 (方案 B/C)
- 层级架构借鉴生物，但用工程方法实现
- 反馈是关键，必须渐进引入

---

### 战线 3: 预测与安全 (Prediction & Safety)

**问题**: VLA 是被动的，没有预测；安全是附加模块

**目标**: 2028 年实现简化版预测编码，安全作为系统属性

```
┌─────────────────────────────────────────────────────────────────┐
│              预测与安全研究计划                                   │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│   P3.1 简化版预测编码                                           │
│   ┌─────────────────────────────────────────────────────────┐   │
│   │  生物学家要求: 完整的自由能框架                          │   │
│   │  工程师担忧: 实现太复杂                                  │   │
│   │                                                          │   │
│   │  我的方案: 关键节点预测                                  │   │
│   │                                                          │   │
│   │  不是每层都预测，而是在关键节点加入:                     │   │
│   │                                                          │   │
│   │  ┌─────────────────────────────────────────────────┐    │   │
│   │  │  节点 1: 视觉预测                                │    │   │
│   │  │  • 预测下一帧 (World Model)                      │    │   │
│   │  │  • 误差大 → 触发重新规划                         │    │   │
│   │  │  • 节省: 不是每帧都完整推理                       │    │   │
│   │  ├─────────────────────────────────────────────────┤    │   │
│   │  │  节点 2: 触觉预测                                │    │   │
│   │  │  • 预测接触时的触觉反馈                          │    │   │
│   │  │  • 误差大 (意外阻力) → 安全响应                  │    │   │
│   │  ├─────────────────────────────────────────────────┤    │   │
│   │  │  节点 3: 动作结果预测                            │    │   │
│   │  │  • 预测动作执行后的状态                          │    │   │
│   │  │  • 误差大 → 调整后续动作                         │    │   │
│   │  └─────────────────────────────────────────────────┘    │   │
│   │                                                          │   │
│   │  实现: 用 World Model (类似 Dreamer) 但只在关键节点      │   │
│   └─────────────────────────────────────────────────────────┘   │
│                                                                 │
│   P3.2 安全涌现                                                 │
│   ┌─────────────────────────────────────────────────────────┐   │
│   │  当前: 安全是独立模块 (SafetyWrapper)                    │   │
│   │  目标: 安全作为系统属性涌现                              │   │
│   │                                                          │   │
│   │  渐进路线:                                               │   │
│   │                                                          │   │
│   │  阶段 1 (2025): 外部安全层                               │   │
│   │  ├── 传统: 力矩限制、碰撞检测、安全区域                  │   │
│   │  └── 与 VLA 协调: 安全层可中断 VLA 动作                  │   │
│   │                                                          │   │
│   │  阶段 2 (2026-2027): 安全感知训练                        │   │
│   │  ├── 在训练数据中加入危险场景                            │   │
│   │  ├── RL 中加入安全约束 (Constrained RL)                  │   │
│   │  └── VLA 学会"预测危险"                                 │   │
│   │                                                          │   │
│   │  阶段 3 (2028+): 安全涌现                                │   │
│   │  ├── 预测编码使 VLA 天然对"意外"敏感                    │   │
│   │  ├── 意外 → 减速/停止 (类似生物反射)                    │   │
│   │  └── 不需要外部安全层干预                                │   │
│   └─────────────────────────────────────────────────────────┘   │
│                                                                 │
│   里程碑:                                                       │
│   • M3.1 (2026 Q4): 简化预测编码原型                          │
│   • M3.2 (2027 Q4): 安全感知训练框架                          │
│   • M3.3 (2028 Q4): 首个"天然安全" VLA 演示                  │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

**关键决策**:
- 预测编码从关键节点开始，不追求完整自由能框架
- 安全从外部层开始，渐进向涌现演进
- 用 World Model 技术实现预测，已有成熟工具

---

### 战线 4: 效率与泛化 (Efficiency & Generalization)

**问题**: VLA 太大无法本地部署；无法跨机器人泛化

**目标**: 2027 年实现边缘部署，2028 年实现跨机器人迁移

```
┌─────────────────────────────────────────────────────────────────┐
│              效率与泛化研究计划                                   │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│   P4.1 模型效率                                                 │
│   ┌─────────────────────────────────────────────────────────┐   │
│   │  目标: 在 Jetson Orin 上实时运行 (<100ms/推理)           │   │
│   │                                                          │   │
│   │  技术路线:                                               │   │
│   │  ├── 量化: 4-bit QLoRA 训练, AWQ 部署                   │   │
│   │  ├── 蒸馏: 7B → 1B 知识蒸馏                             │   │
│   │  ├── 架构: 探索 SmolVLA 类轻量设计                      │   │
│   │  └── 加速: Action Chunking (减少推理频率)               │   │
│   │                                                          │   │
│   │  分层部署:                                               │   │
│   │  ┌───────────────────────────────────────────────────┐  │   │
│   │  │  云端: 大模型 (7B+), 处理复杂推理                  │  │   │
│   │  │  边缘: 小模型 (1B), 处理常规任务                   │  │   │
│   │  │  策略: 简单任务本地, 复杂任务云端                  │  │   │
│   │  │        网络断开时降级到本地模式                    │  │   │
│   │  └───────────────────────────────────────────────────┘  │   │
│   └─────────────────────────────────────────────────────────┘   │
│                                                                 │
│   P4.2 跨机器人泛化                                             │
│   ┌─────────────────────────────────────────────────────────┐   │
│   │  核心挑战: 动作空间异构                                  │   │
│   │                                                          │   │
│   │  方案 1: 通用动作表示                                    │   │
│   │  ├── 定义"原子动作": 末端位移、抓取开合                 │   │
│   │  ├── robot-specific decoder 转换为关节命令               │   │
│   │  └── 新机器人只需训练 decoder                            │   │
│   │                                                          │   │
│   │  方案 2: 上下文学习                                      │   │
│   │  ├── prompt: "你是 7-DoF 机械臂，关节限位是..."         │   │
│   │  ├── VLA 根据 prompt 调整动作生成                        │   │
│   │  └── 类似 LLM 的 in-context learning                     │   │
│   │                                                          │   │
│   │  方案 3: 运动基元迁移                                    │   │
│   │  ├── 基元是机器人无关的语义单元                          │   │
│   │  ├── 只需为新机器人学习"基元 → 动作"映射               │   │
│   │  └── 这就是为什么运动基元如此重要！                      │   │
│   └─────────────────────────────────────────────────────────┘   │
│                                                                 │
│   里程碑:                                                       │
│   • M4.1 (2026 Q2): 1B VLA 边缘部署                           │
│   • M4.2 (2027 Q4): 跨 3 种机器人零样本迁移演示               │
│   • M4.3 (2028 Q4): 开源跨机器人 VLA 框架                     │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

---

### 战线 5: 数据与评估 (Data & Evaluation)

**问题**: 数据不够、不干净；评估不可靠

**目标**: 建立高质量数据闭环和可靠评估体系

```
┌─────────────────────────────────────────────────────────────────┐
│              数据与评估研究计划                                   │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│   P5.1 数据质量提升                                             │
│   ┌─────────────────────────────────────────────────────────┐   │
│   │  问题: 百万轨迹，但质量参差不齐                          │   │
│   │                                                          │   │
│   │  方案 1: Critic 筛选 (借鉴 GR-RL)                        │   │
│   │  ├── 训练 Critic 评估演示质量                            │   │
│   │  ├── 剔除低质量、失败轨迹                                │   │
│   │  └── 只用高质量数据训练 VLA                              │   │
│   │                                                          │   │
│   │  方案 2: 形态对称增强 (借鉴 GR-RL)                       │   │
│   │  ├── 左右镜像、旋转变换                                  │   │
│   │  └── 数据量 2-4x                                         │   │
│   │                                                          │   │
│   │  方案 3: 视频生成合成                                    │   │
│   │  ├── 用 Video Diffusion 生成训练轨迹                     │   │
│   │  ├── 配合仿真验证可行性                                  │   │
│   │  └── 理论上无限数据                                      │   │
│   └─────────────────────────────────────────────────────────┘   │
│                                                                 │
│   P5.2 触觉数据集                                               │
│   ┌─────────────────────────────────────────────────────────┐   │
│   │  当前缺失: 大规模触觉-语言-动作数据集                    │   │
│   │                                                          │   │
│   │  计划:                                                   │   │
│   │  • 2025 Q2: 启动触觉数据采集                             │   │
│   │  • 2025 Q4: 10 万轨迹 (触觉 + 视觉 + 动作)               │   │
│   │  • 2026 Q4: 100 万轨迹，开源发布                         │   │
│   └─────────────────────────────────────────────────────────┘   │
│                                                                 │
│   P5.3 评估体系                                                 │
│   ┌─────────────────────────────────────────────────────────┐   │
│   │  问题: 仿真 Benchmark 与真机差距大                       │   │
│   │                                                          │   │
│   │  方案:                                                   │   │
│   │  • 建立标准化真机测试流程                                │   │
│   │  • 多样化测试场景 (光照、材质、干扰)                    │   │
│   │  • 对抗测试 (故意引入故障)                              │   │
│   │  • 长期稳定性测试 (100+ 小时连续运行)                   │   │
│   └─────────────────────────────────────────────────────────┘   │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

---

## 三、资源配置

### 3.1 团队结构

```
┌─────────────────────────────────────────────────────────────────┐
│              VLA 研究团队结构                                    │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│   总工程师 (1 人)                                               │
│   └── 战略决策、跨团队协调                                      │
│                                                                 │
│   战线 1: 感知团队 (6 人)                                       │
│   ├── 触觉工程师 (2): 硬件集成、驱动开发                        │
│   ├── 视觉算法 (2): 多模态融合、深度估计                        │
│   └── 传感器融合 (2): 本体感觉、状态估计                        │
│                                                                 │
│   战线 2: 基元团队 (5 人)                                       │
│   ├── 运动学习 (2): 基元发现、层级架构                          │
│   ├── 控制工程师 (2): 传统控制、安全约束                        │
│   └── VLM 对齐 (1): 语义基元与 VLM 对齐                         │
│                                                                 │
│   战线 3: 预测安全团队 (4 人)                                   │
│   ├── World Model (2): 预测编码实现                             │
│   └── 安全工程师 (2): 安全约束、形式化验证                      │
│                                                                 │
│   战线 4: 部署团队 (4 人)                                       │
│   ├── 优化工程师 (2): 量化、蒸馏、加速                          │
│   └── 系统工程师 (2): 边缘部署、云边协同                        │
│                                                                 │
│   战线 5: 数据团队 (4 人)                                       │
│   ├── 数据工程师 (2): 数据采集、清洗、增强                      │
│   └── 评估工程师 (2): Benchmark、测试流程                       │
│                                                                 │
│   总计: 24 人                                                   │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

### 3.2 预算分配

| 项目 | 2025 | 2026 | 2027 | 总计 |
| :--- | :--- | :--- | :--- | :--- |
| 人力 | 500万 | 600万 | 700万 | 1800万 |
| 硬件 (机器人、传感器) | 200万 | 150万 | 100万 | 450万 |
| 算力 (GPU 集群) | 300万 | 400万 | 500万 | 1200万 |
| 数据采集 | 100万 | 150万 | 100万 | 350万 |
| **总计** | **1100万** | **1300万** | **1400万** | **3800万** |

---

## 四、风险与应对

```
┌─────────────────────────────────────────────────────────────────┐
│              风险评估与应对                                       │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│   风险 1: 触觉集成比预期困难                                    │
│   概率: 中 | 影响: 高                                           │
│   应对:                                                         │
│   • 同时推进 DIGIT 和 千觉 两条路线                             │
│   • 与 Meta (FAIR) 建立合作，获取技术支持                       │
│   • 备选: 先用简化触觉 (力传感器) 而非视觉触觉                  │
│                                                                 │
│   风险 2: 语义基元发现失败                                      │
│   概率: 中 | 影响: 高                                           │
│   应对:                                                         │
│   • 三个方案并行 (VLM 标注 / 层级 VAE / FAST+对齐)              │
│   • 降级方案: 手工定义基元库 (类似 DMP)                         │
│   • 与 Stanford IRIS Lab 合作探索                               │
│                                                                 │
│   风险 3: 预测编码计算成本过高                                  │
│   概率: 高 | 影响: 中                                           │
│   应对:                                                         │
│   • 只在关键节点使用，不追求完整                                │
│   • 探索轻量 World Model (如 IRIS, Genie 的简化版)             │
│   • 长期: 关注神经形态芯片发展                                  │
│                                                                 │
│   风险 4: 边缘部署性能不达标                                    │
│   概率: 中 | 影响: 中                                           │
│   应对:                                                         │
│   • 分层部署 (云端 + 边缘)                                      │
│   • 激进量化 (2-bit 探索)                                       │
│   • 关注下一代边缘芯片 (Orin Next, Apple M3 Ultra 等)           │
│                                                                 │
│   风险 5: 竞争对手领先                                          │
│   概率: 高 | 影响: 高                                           │
│   应对:                                                         │
│   • 聚焦差异化: 触觉 + 运动基元 (竞争对手较少关注)              │
│   • 快速迭代: 3 个月一个版本                                    │
│   • 开源策略: 部分开源吸引社区贡献                              │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

---

## 五、总结: 研究方案核心

```
┌─────────────────────────────────────────────────────────────────┐
│              VLA 总工程师研究方案核心                            │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│   🎯 核心判断:                                                  │
│                                                                 │
│   1. 触觉是第一优先级                                           │
│      → 这是工程师和生物学家唯一完全一致的共识                   │
│      → 立即启动，2025 年必须完成基础集成                        │
│                                                                 │
│   2. 运动基元是关键缺失                                         │
│      → 生物学家说得对，这是数据效率低的根本原因                 │
│      → 用 VLM 帮助发现语义基元，而非纯统计方法                  │
│                                                                 │
│   3. 预测编码从简化版开始                                       │
│      → 完整实现太难，但原理是对的                               │
│      → 关键节点预测 + World Model                               │
│                                                                 │
│   4. 安全从外部层向涌现演进                                     │
│      → 短期用传统方法保证安全                                   │
│      → 长期让 VLA 天然具备安全意识                              │
│                                                                 │
│   5. 向生物学习原理，用工程方法实现                             │
│      → 这是三轮辩论后的核心共识                                 │
│      → 既不照搬生物，也不忽视生物                               │
│                                                                 │
│   📅 关键里程碑:                                                │
│                                                                 │
│   2025 Q4: 多模态 VLA v1 (视觉 + 触觉 + 本体)                  │
│   2026 Q4: 基元库 v1 + 层级控制原型                            │
│   2027 Q4: 边缘部署 + 跨机器人迁移                             │
│   2028 Q4: 简化预测编码 + 安全涌现演示                         │
│   2030: 产品级 VLA，万台部署                                   │
│                                                                 │
│   💡 最终愿景:                                                  │
│                                                                 │
│   生物学家描述了山顶的风景                                      │
│   工程师在寻找上山的路                                          │
│   我的任务是带领团队，一步一步走上去                            │
│                                                                 │
│   不是 5 亿年，而是 5 年                                        │
│   因为我们站在进化的肩膀上                                      │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

---

## 附录: 技术依赖关系

```
┌─────────────────────────────────────────────────────────────────┐
│              技术依赖关系图                                       │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│                     ┌─────────────────┐                         │
│                     │  产品级 VLA     │                         │
│                     │  (2030)         │                         │
│                     └────────┬────────┘                         │
│                              │                                  │
│              ┌───────────────┼───────────────┐                  │
│              ▼               ▼               ▼                  │
│   ┌──────────────┐  ┌──────────────┐  ┌──────────────┐         │
│   │ 安全涌现     │  │ 跨机器人    │  │ 人机协作    │         │
│   │ (2028)       │  │ (2028)       │  │ (2029)       │         │
│   └──────┬───────┘  └──────┬───────┘  └──────┬───────┘         │
│          │                 │                 │                  │
│          ▼                 ▼                 ▼                  │
│   ┌──────────────┐  ┌──────────────┐  ┌──────────────┐         │
│   │ 预测编码     │  │ 运动基元    │  │ 层级控制    │         │
│   │ (2027)       │  │ (2026)       │  │ (2027)       │         │
│   └──────┬───────┘  └──────┬───────┘  └──────┬───────┘         │
│          │                 │                 │                  │
│          └────────────┬────┴────────────────┘                   │
│                       ▼                                         │
│              ┌──────────────┐                                   │
│              │ 多模态感知   │  ← 基础，必须先完成               │
│              │ (触觉+本体)  │                                   │
│              │ (2025)       │                                   │
│              └──────────────┘                                   │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

---

**文档版本**: v1.0
**审批状态**: 待审批
**下次评审**: 2025 Q2

