## ASCII Diagram Cheat Sheet

集中提炼 `theory/` 中所有关键的 ASCII 结构图，便于记忆核心架构、流程与对比。

### 1. Quantization Flow
```
┌─────────────────────────────────────────────────────────────────┐
│                    量化流程 (Quantization Flow)                  │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│   FP32 权重                    INT8/INT4 权重                   │
│   ┌─────────┐                  ┌─────────┐                      │
│   │ 0.0234  │                  │   3     │                      │
│   │ 0.1567  │   ──────────▶    │   20    │                      │
│   │-0.0891  │    量化 (Q)      │  -11    │                      │
│   │ 0.2103  │                  │   27    │                      │
│   └─────────┘                  └─────────┘                      │
│       ▲                             │                           │
│       │                             │                           │
│       └─────────────────────────────┘                           │
│              反量化 (DeQ)                                        │
│                                                                 │
│   存储: 32-bit ────────▶ 4-bit (8x 压缩)                        │
│   精度: 高 ────────────▶ 低 (有损失)                            │
└─────────────────────────────────────────────────────────────────┘
```

### 2. Symmetric vs Asymmetric Quantization
```
对称量化 (Symmetric)              非对称量化 (Asymmetric)
        Z = 0                           Z ≠ 0

    -127 ◀──────▶ +127              0 ◀──────────▶ 255
      │     0     │                 │      Z       │
      ├─────┼─────┤                 ├──────┼───────┤
      │     │     │                 │      │       │
   ───┴─────┴─────┴───           ──┴──────┴───────┴──
     min   0    max               min    0       max
      └─────┬─────┘                └───────┬───────┘
            │                              │
       数据分布对称                    数据分布偏移
     (适合权重 weights)           (适合激活值 activations)
```

### 3. LoRA Architecture
```
┌─────────────────────────────────────────────────────────────────┐
│                    LoRA 架构示意图                               │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│         输入 x                                                  │
│           │                                                     │
│     ┌─────┴─────┐                                               │
│     │           │                                               │
│     ▼           ▼                                               │
│  ┌──────┐   ┌──────┐                                            │
│  │  W₀  │   │  A   │  ← 低秩矩阵 (r << d)                       │
│  │      │   │ r×k  │    可训练                                  │
│  │ d×k  │   └──┬───┘                                            │
│  │      │      │                                                │
│  │ 冻结 │      ▼                                                │
│  └──┬───┘   ┌──────┐                                            │
│     │       │  B   │  ← 低秩矩阵                                │
│     │       │ d×r  │    可训练                                  │
│     │       └──┬───┘                                            │
│     │          │                                                │
│     │    ΔW = B·A                                               │
│     │          │                                                │
│     └────┬─────┘                                                │
│          │  W = W₀ + α·BA                                       │
│          ▼                                                      │
│        输出 h                                                   │
│                                                                 │
│  参数量: d×k (冻结) + r×(d+k) (训练) ≈ 0.1% ~ 1%                │
└─────────────────────────────────────────────────────────────────┘
```

### 4. Co-training Mix
```
┌─────────────────────────────────────────────────────────────────┐
│                   Co-training 数据混合策略                       │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  ┌──────────────────┐       ┌──────────────────┐               │
│  │   机器人数据      │       │   互联网数据      │               │
│  │   (Robot Data)   │       │   (Web Data)     │               │
│  │                  │       │                  │               │
│  │  📷 + 🎯 + 🦾    │       │  📷 + 📝         │               │
│  │  图像 指令 动作   │       │  图像 文本        │               │
│  └────────┬─────────┘       └────────┬─────────┘               │
│           │                          │                          │
│           │    混合比例 1:1          │                          │
│           └──────────┬───────────────┘                          │
│                      ▼                                          │
│           ┌──────────────────────┐                              │
│           │      VLA 模型        │                              │
│           │   ┌──────┬──────┐   │                              │
│           │   │Action│ Text │   │                              │
│           │   │ Head │ Head │   │                              │
│           │   └──┬───┴──┬───┘   │                              │
│           └──────┼──────┼───────┘                              │
│                  │      │                                       │
│           ┌──────┴──┐ ┌─┴──────┐                               │
│           │ Action  │ │  Text  │                               │
│           │  Loss   │ │  Loss  │                               │
│           │ (机器人)│ │ (互联网)│                               │
│           └─────────┘ └────────┘                               │
│                                                                 │
│   效果: 保持语义能力 ✓  学习动作控制 ✓  防止灾难性遗忘 ✓         │
└─────────────────────────────────────────────────────────────────┘
```

### 5. Action Generation Matrix
```
┌─────────────────────────────────────────────────────────────────┐
│              三种动作生成范式对比 (Action Generation)            │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  1. 离散化 Tokenization (RT-1, RT-2)                            │
│     ┌───────────────────────────────┐                           │
│     │ 连续动作 ──▶ 离散 Bins ──▶ Token 预测   │                 │
│     └───────────────────────────────┘                           │
│     ⚡ 快速 (1步)  |  📉 精度损失  |  ✅ 多模态                  │
│                                                                 │
│  2. 扩散策略 Diffusion (Octo)                                   │
│     ┌───────────────────────────────┐                           │
│     │ 噪声 ════▶ 去噪 ════▶...═══▶ 动作 │                         │
│     └───────────────────────────────┘                           │
│     🐢 慢 (50-100步)  |  🎯 高精度  |  ✅ 多模态                │
│                                                                 │
│  3. 流匹配 Flow Matching (π0)                                   │
│     ┌───────────────────────────────┐                           │
│     │ 噪声 ════════════════════▶ 动作 │                          │
│     └───────────────────────────────┘                           │
│     ⚡ 极快 (1-10步)  |  🎯 高精度  |  ✅ 多模态                  │
└─────────────────────────────────────────────────────────────────┘
```

### 6. π0.5 Unified Flow
```
┌─────────────────────────────────────────────────────────────────┐
│                    π0.5 统一架构 (Unified Model)                 │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│   输入: 📷 图像 + 📝 语言指令                                    │
│              │                                                  │
│              ▼                                                  │
│   ┌──────────────────────────────┐                              │
│   │          VLM Backbone         │                              │
│   └─────────────────┬──────────────┘                             │
│                     ▼                                           │
│   ┌────────────────────┬─────────────────────┐                  │
│   │  Latent Thought     │                      │                 │
│   │  (subtask planner)  │                      │                 │
│   └─────────┬──────────┘                      │                 │
│             ▼                                 ▼                 │
│      ┌────────────┐                     ┌────────────┐           │
│      │ FAST Token  │                     │ Flow Match  │           │
│      │ (Pretrain)  │                     │  (Inference)│           │
│      └────────────┘                     └────────────┘           │
│                │                                 │              │
│                └──────────────┬──────────────────┘              │
│                               ▼                                 │
│                      🦾 连续动作输出 (50Hz)                       │
└─────────────────────────────────────────────────────────────────┘
```

### 7. π0.6 + Recap Flow
```
┌─────────────────────────────────────────────────────────────────┐
│                π0.6 / π*0.6 架构与训练流程                       │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│                     ┌──────────────────┐                        │
│                     │  5B VLM Backbone │                        │
│                     └────────┬─────────┘                        │
│                              ▼                                  │
│                     ┌──────────────────┐                        │
│                     │  Action Expert   │                        │
│                     └────────┬─────────┘                        │
│                              ▼                                  │
│                         🦾 精细动作                               │
│                                                                 │
│   Recap Training Pipeline:                                         │
│   Phase1: Collect successes/failures                              │
│              │                                                   │
│           Analyze trajectories                                    │
│              │                                                   │
│   Phase2: Recap Offline RL (reward positives, penalize negatives)│
│              │                                                   │
│           Update policy                                           │
│              │                                                   │
│   Phase3: Self-improvement → surpass human demonstrations         │
└─────────────────────────────────────────────────────────────────┘
```

### 8. VLA Architecture Evolution
```
┌─────────────────────────────────────────────────────────────────┐
│                    VLA 架构演进路线图                            │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│   RT-1 (2022)              RT-2 (2023)              π0 (2024)   │
│   ┌─────────┐              ┌─────────┐              ┌─────────┐ │
│   │EffNet   │              │ PaLI-X  │              │ Gemma   │ │
│   │   +     │   ────▶      │  55B    │   ────▶      │  +Flow  │ │
│   │Tokenize │              │ VLM+Act │              │ Matching│ │
│   └─────────┘              └─────────┘              └─────────┘ │
│     小模型                   大VLM                    高效推理   │
│                                                                 │
│   ┌─────────────────────────────────────────────────────────┐   │
│   │                    通用 VLA 架构模板                     │   │
│   │                                                         │   │
│   │    📷 Image          📝 Language                        │   │
│   │       │                  │                              │   │
│   │       ▼                  ▼                              │   │
│   │  ┌─────────┐       ┌───────────┐                        │   │
│   │  │ Vision  │       │ Language  │                        │   │
│   │  │ Encoder │       │ Encoder   │                        │   │
│   │  └────┬────┘       └─────┬─────┘                        │   │
│   │       │                  │                              │   │
│   │       └────────┬─────────┘                              │   │
│   │                │ Fusion                                 │   │
│   │                ▼                                        │   │
│   │       ┌─────────────────┐                               │   │
│   │       │  Transformer    │                               │   │
│   │       │    Backbone     │                               │   │
│   │       └────────┬────────┘                               │   │
│   │                │                                        │   │
│   │                ▼                                        │   │
│   │       ┌─────────────────┐                               │   │
│   │       │   Action Head   │                               │   │
│   │       │ Token/Diff/Flow │                               │   │
│   │       └────────┬────────┘                               │   │
│   │                │                                        │   │
│   │                ▼                                        │   │
│   │          🦾 Robot Action                                │   │
│   └─────────────────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────────────────┘
```

### 9. Flash Attention vs Standard
```
┌─────────────────────────────────────────────────────────────────┐
│              Flash Attention vs 标准 Attention                  │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│   标准 Attention (内存瓶颈)           Flash Attention (分块)    │
│                                                                 │
│   ┌───────────────────┐               ┌───────────────────┐     │
│   │      Q · K^T      │               │   Q₁·K₁  Q₁·K₂   │     │
│   │   ┌─────────────┐ │               │  ┌─────┐┌─────┐  │     │
│   │   │             │ │   ────▶       │  │ 块1 ││ 块2 │  │     │
│   │   │   N × N     │ │   分块        │  └─────┘└─────┘  │     │
│   │   │  (巨大!)    │ │               │  ┌─────┐┌─────┐  │     │
│   │   │             │ │               │  │ 块3 ││ 块4 │  │     │
│   │   └─────────────┘ │               │  └─────┘└─────┘  │     │
│   └───────────────────┘               └───────────────────┘     │
│   内存: O(N²) ❌                       内存: O(N) ✅             │
│                                                                 │
├─────────────────────────────────────────────────────────────────┤
│                        内存层级优化                              │
│                                                                 │
│   ┌────────────────┐     ┌────────────────┐                     │
│   │      HBM       │     │     SRAM       │                     │
│   │   (显存)       │     │   (L2 Cache)   │                     │
│   │   24GB+        │ ◀─▶ │    ~20MB       │                     │
│   │   慢 1TB/s     │     │   快 19TB/s    │                     │
│   └────────────────┘     └────────────────┘                     │
│          │                      │                               │
│          │   标准: 多次读写      │   Flash: 一次加载             │
│          │   Q,K ──▶ S ──▶ P    │   全部在 SRAM 计算            │
│          │   每步写回 HBM       │   只写最终结果                 │
│   结果: 2-4x 加速, 显存 O(N²) → O(N)                            │
└─────────────────────────────────────────────────────────────────┘
```

### 10. WALL-OSS Uni-CoT
```
┌─────────────────────────────────────────────────────────────────┐
│                    WALL-OSS 架构 (Uni-CoT)                      │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│   输入: 📷 图像 + 📝 指令                                          │
│              │                                                  │
│              ▼                                                  │
│   ┌─────────────────────────────────────────┐                  │
│   │       Qwen2.5 VLMoE Backbone            │                  │
│   └─────────────────┬───────────────────────┘                  │
│                     │                                          │
│                     ▼                                          │
│   ┌─────────────────────────────────────────┐                  │
│   │           Uni-CoT 推理链                 │                  │
│   │  ┌─────────────────────────────────┐    │                  │
│   │  │ 1. 高层推理: 理解任务               │    │                  │
│   │  │ 2. 子任务分解: 找海绵→抓取→擦拭     │    │                  │
│   │  │ 3. 细粒度动作: (x,y,z) 轨迹         │    │                  │
│   └─────────────────┬───────────────────────┘                  │
│                     │                                          │
│         ┌───────────┴───────────┐                              │
│         ▼                       ▼                              │
│   ┌───────────┐          ┌───────────┐                         │
│   │ 离散头    │          │ 连续头    │                         │
│   │(FAST Token)│          │(Flow Match)│                        │
│   └─────┬─────┘          └─────┬─────┘                         │
│         │                      │                               │
│         └──────────┬───────────┘                               │
│                    ▼                                           │
│              🦾 双头动作输出                                     │
└─────────────────────────────────────────────────────────────────┘
```

