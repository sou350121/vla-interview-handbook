---
title: "VLA Handbookï¼šä»ç†è®ºåˆ°å®è·µ"
subtitle: "Vision-Language-Action å®Œå…¨æŒ‡å—"
author: "VLA Handbook Contributors"
date: "2025å¹´12æœˆ18æ—¥"
documentclass: report
geometry: margin=2.5cm
fontsize: 11pt
toc: true
toc-depth: 3
numbersections: true
colorlinks: true
linkcolor: blue
urlcolor: blue
header-includes:
  - \usepackage{ctex}
  - \usepackage{fancyhdr}
  - \pagestyle{fancy}
  - \fancyhead[L]{VLA Handbook}
  - \fancyhead[R]{\thepage}
  - \fancyfoot[C]{}
---

\newpage

# å‰è¨€

æœ¬ä¹¦æ˜¯ **VLA Handbook** é¡¹ç›®çš„å®Œæ•´ç†è®ºéƒ¨åˆ†ï¼Œç³»ç»Ÿæ€§åœ°ä»‹ç»äº†è§†è§‰-è¯­è¨€-åŠ¨ä½œ (Vision-Language-Action) æ¨¡å‹çš„æ ¸å¿ƒæ¦‚å¿µã€å…³é”®æŠ€æœ¯ä¸å·¥ç¨‹å®è·µã€‚

**é€‚ç”¨è¯»è€…**ï¼š
- å‡†å¤‡æœºå™¨äºº/å…·èº«æ™ºèƒ½æ–¹å‘é¢è¯•çš„å·¥ç¨‹å¸ˆ
- å¸Œæœ›ç³»ç»Ÿå­¦ä¹  VLA æŠ€æœ¯æ ˆçš„ç ”ç©¶è€…
- å¯¹å¤šæ¨¡æ€æœºå™¨äººæ„Ÿå…´è¶£çš„å­¦ç”Ÿ

**å¦‚ä½•ä½¿ç”¨æœ¬ä¹¦**ï¼š
1. **ç³»ç»Ÿå­¦ä¹ **ï¼šæŒ‰ç« èŠ‚é¡ºåºé˜…è¯»ï¼Œå»ºç«‹å®Œæ•´çŸ¥è¯†ä½“ç³»
2. **é¢è¯•å‡†å¤‡**ï¼šé‡ç‚¹å…³æ³¨æ¯ç« æœ«å°¾çš„ Q&A éƒ¨åˆ†
3. **æŸ¥é˜…å‚è€ƒ**ï¼šä½¿ç”¨ç›®å½•å¿«é€Ÿå®šä½ç‰¹å®šä¸»é¢˜

**åœ¨çº¿ç‰ˆæœ¬**ï¼šhttps://github.com/sou350121/VLA-Handbook

\newpage

# ç¬¬ä¸€éƒ¨åˆ†ï¼šåŸºç¡€æ¶æ„


\newpage

# ç¬¬1ç«  Transformer vs CNN


## ä¸»è¦æ•°å­¦æ€æƒ³ (Main Mathematical Idea)

> **"Global Attention vs. Local Connectivity (å½’çº³åç½®çš„æƒè¡¡)"**

Transformer å’Œ CNN çš„æ ¸å¿ƒå¯¹ç«‹åœ¨äºå¦‚ä½•å¤„ç†ä¿¡æ¯ï¼š
1.  **CNN (å·ç§¯)**: å‡è®¾ "ç›¸é‚»çš„åƒç´ æ˜¯ç›¸å…³çš„" (**Local Connectivity**) å’Œ "ç‰¹å¾åœ¨å“ªé‡Œå¹¶ä¸é‡è¦" (**Translation Invariance**)ã€‚è¿™æ˜¯ä¸€ç§å¼ºçƒˆçš„**å½’çº³åç½® (Inductive Bias)**ã€‚
2.  **Transformer (æ³¨æ„åŠ›)**: å‡è®¾ "ä»»ä½•ä¸¤ä¸ªåƒç´ ä¹‹é—´éƒ½å¯èƒ½ç›¸å…³" (**Global Attention**)ã€‚å®ƒæ²¡æœ‰é¢„è®¾çš„åç½®ï¼Œå®Œå…¨ä¾èµ–æ•°æ®é©±åŠ¨çš„å…³ç³»å‘ç° (**Content-based Interactions**)ã€‚

ä»æ•°å­¦ä¸Šè®²ï¼ŒCNN çš„å·ç§¯æ ¸æ˜¯ä¸€ä¸ª**å›ºå®š**çš„å±€éƒ¨ç®—å­ $y_i = \sum_j w_{i-j} x_j$ï¼Œè€Œ Transformer çš„æ³¨æ„åŠ›æ˜¯ä¸€ä¸ª**åŠ¨æ€**çš„å…¨å±€ç®—å­ $y_i = \sum_j \text{softmax}(q_i^T k_j) v_j$ï¼Œå…¶ä¸­æƒé‡å–å†³äºè¾“å…¥æœ¬èº«ã€‚

---

åœ¨ VLA (Vision-Language-Action) é¢è¯•ä¸­ï¼Œç†è§£ Backbone (éª¨å¹²ç½‘ç»œ) çš„å·®å¼‚è‡³å…³é‡è¦ã€‚è™½ç„¶ç°åœ¨çš„è¶‹åŠ¿æ˜¯ Transformer (ViT) ä¸€ç»Ÿå¤©ä¸‹ï¼Œä½† CNN (ResNet, EfficientNet) ä¾ç„¶åœ¨ RT-1 ç­‰ç»å…¸æ¨¡å‹ä¸­æ‰®æ¼”é‡è¦è§’è‰²ã€‚

## 1. æ ¸å¿ƒå·®å¼‚ä¸€è§ˆè¡¨

| ç‰¹æ€§ | CNN (å·ç§¯ç¥ç»ç½‘ç»œ) | Transformer (è‡ªæ³¨æ„åŠ›æœºåˆ¶) |
| :--- | :--- | :--- |
| **æ ¸å¿ƒæ“ä½œ** | Convolution (å·ç§¯) | Self-Attention (è‡ªæ³¨æ„åŠ›) |
| **æ„Ÿå—é‡ (Receptive Field)** | å±€éƒ¨ (Local) -> é€æ¸æ‰©å¤§ | å…¨å±€ (Global) |
| **å½’çº³åç½® (Inductive Bias)** | å¼º (å¹³ç§»ä¸å˜æ€§, å±€éƒ¨æ€§) | å¼± (éœ€æµ·é‡æ•°æ®å­¦ä¹ ) |
| **è®¡ç®—å¤æ‚åº¦** | $O(N)$ (çº¿æ€§) | $O(N^2)$ (å¹³æ–¹çº§) |
| **å¹¶è¡Œæ€§** | é«˜ | æé«˜ |
| **æ“…é•¿é¢†åŸŸ** | å›¾åƒçº¹ç†, è¾¹ç¼˜æ£€æµ‹ | è¯­ä¹‰ç†è§£, é•¿è·ç¦»ä¾èµ– |
| **ä»£è¡¨æ¨¡å‹** | ResNet, EfficientNet | ViT, BERT, GPT |

## 2. CNN (Convolutional Neural Networks)

### åŸç†
CNN æ¨¡ä»¿ç”Ÿç‰©è§†è§‰çš®å±‚ï¼Œé€šè¿‡**æ»‘åŠ¨çª—å£ (Sliding Window)** æå–ç‰¹å¾ã€‚
- **å±€éƒ¨æ€§ (Locality)**: æ¯æ¬¡åªçœ‹ä¸€å°å—åŒºåŸŸ (e.g., 3x3 åƒç´ )ã€‚
- **å¹³ç§»ä¸å˜æ€§ (Translation Invariance)**: çŒ«åœ¨å›¾ç‰‡å·¦ä¸Šè§’è¿˜æ˜¯å³ä¸‹è§’ï¼Œè¯†åˆ«å‡ºçš„ç‰¹å¾æ˜¯ä¸€æ ·çš„ã€‚
- **å±‚çº§ç»“æ„**: æµ…å±‚å­¦è¾¹ç¼˜/çº¹ç†ï¼Œæ·±å±‚å­¦å½¢çŠ¶/ç‰©ä½“ã€‚

### åœ¨ VLA ä¸­çš„åº”ç”¨
- **RT-1**: ä½¿ç”¨ **EfficientNet-B3** ä½œä¸ºè§†è§‰ç¼–ç å™¨ã€‚
- **ä¼˜åŠ¿**: è®­ç»ƒæ”¶æ•›å¿«ï¼Œå¯¹å°æ•°æ®é›†å‹å¥½ (å› ä¸ºæœ‰å¾ˆå¼ºçš„å½’çº³åç½®)ã€‚
- **åŠ£åŠ¿**: éš¾ä»¥æ•æ‰é•¿è·ç¦»å…³ç³» (æ¯”å¦‚ï¼šæ¡Œå­å·¦è¾¹çš„æ¯å­å’Œæ¡Œå­å³è¾¹çš„å£¶ä¹‹é—´çš„å…³ç³»ï¼ŒCNN éœ€è¦å †å å¾ˆå¤šå±‚æ‰èƒ½"çœ‹"åˆ°ä¸¤è€…)ã€‚

## 3. Transformer (Attention Is All You Need)

### åŸç†
Transformer æŠ›å¼ƒäº†å·ç§¯ï¼Œå®Œå…¨ä¾èµ– **Self-Attention (è‡ªæ³¨æ„åŠ›æœºåˆ¶)**ã€‚
- **å…¨å±€æ„Ÿå—é‡**: æ¯ä¸€ä¸ª Token (åƒç´ å—) éƒ½èƒ½ç›´æ¥"å…³æ³¨"åˆ°å›¾åƒä¸­çš„å…¶ä»–æ‰€æœ‰ Tokenã€‚
- **åŠ¨æ€æƒé‡**: å·ç§¯æ ¸çš„æƒé‡æ˜¯å›ºå®šçš„ (è®­ç»ƒå¥½å)ï¼Œè€Œ Attention Map æ˜¯æ ¹æ®è¾“å…¥åŠ¨æ€ç”Ÿæˆçš„ã€‚

### åœ¨ VLA ä¸­çš„åº”ç”¨
- **RT-2 / OpenVLA / Pi0**: ä½¿ç”¨ **ViT (Vision Transformer)** æˆ– **SigLIP**ã€‚
- **ä¼˜åŠ¿**:
    - **å¤šæ¨¡æ€ç»Ÿä¸€**: å›¾åƒ Patch å’Œæ–‡æœ¬ Token å¯ä»¥è¢«åŒç­‰å¯¹å¾…ï¼Œç›´æ¥æ‹¼æ¥è¾“å…¥ Transformerã€‚
    - **Scaling Law**: æ•°æ®è¶Šå¤šï¼Œæ¨¡å‹è¶Šå¤§ï¼Œæ•ˆæœè¶Šå¥½ (ç”±å¼±å½’çº³åç½®å†³å®š)ã€‚
- **åŠ£åŠ¿**: è®­ç»ƒæå…¶æ˜‚è´µï¼Œéœ€è¦æµ·é‡æ•°æ® (JFT-300M, LAION-5B) æ‰èƒ½è¶…è¶Š CNNã€‚

## 4. ä¸ºä»€ä¹ˆ VLA è½¬å‘ Transformer?

1.  **å¤šæ¨¡æ€èåˆ**: æœºå™¨äººéœ€è¦åŒæ—¶å¤„ç†è§†è§‰ (Vision) å’Œè¯­è¨€ (Language)ã€‚Transformer æ˜¯ç›®å‰å”¯ä¸€èƒ½å®Œç¾ç»Ÿä¸€è¿™ä¸¤ç§æ¨¡æ€çš„æ¶æ„ (Early Fusion)ã€‚
2.  **è¯­ä¹‰ç†è§£**: æœºå™¨äººä¸å†åªæ˜¯"æ‰§è¡ŒåŠ¨ä½œ"ï¼Œè€Œæ˜¯éœ€è¦"ç†è§£ç¯å¢ƒ"ã€‚Transformer åœ¨è¯­ä¹‰æå–ä¸Šè¿œå¼ºäº CNNã€‚
3.  **æ—¶åºå»ºæ¨¡**: åŠ¨ä½œåºåˆ— (Action Sequence) æœ¬è´¨ä¸Šæ˜¯æ—¶é—´åºåˆ—ã€‚Transformer (GPT é£æ ¼) å¤©ç”Ÿé€‚åˆå¤„ç†åºåˆ—é¢„æµ‹é—®é¢˜ã€‚

## 5. æ·±åº¦è§£æ: ViT & SigLIP æŠ€æœ¯ç»†èŠ‚
åœ¨ OpenVLA å’Œ Pi0 ç­‰ç°ä»£æ¨¡å‹ä¸­ï¼ŒViT (Vision Transformer) é€šå¸¸æ­é… **SigLIP** é¢„è®­ç»ƒç›®æ ‡ä½¿ç”¨ã€‚

### 5.1 Vision Transformer (ViT) æ ¸å¿ƒç»„ä»¶
ViT å°†å›¾åƒè§†ä¸ºä¸€ç³»åˆ— Patch çš„åºåˆ—ï¼Œå®Œå…¨æ‘’å¼ƒäº†å·ç§¯ã€‚

1.  **Patchify & Linear Projection (åˆ‡ç‰‡ä¸çº¿æ€§æ˜ å°„)**:
    - è¾“å…¥å›¾åƒ $x \in \mathbb{R}^{H \times W \times C}$ è¢«åˆ‡åˆ†ä¸º $N$ ä¸ª $P \times P$ çš„ Patch $x_p \in \mathbb{R}^{N \times (P^2 \cdot C)}$ã€‚
    - **å…¬å¼**:
      $$
      z_0 = [x_p^1 E; x_p^2 E; \cdots; x_p^N E] + E_{pos}
      $$
      å…¶ä¸­ $E \in \mathbb{R}^{(P^2 \cdot C) \times D}$ æ˜¯å¯å­¦ä¹ çš„çº¿æ€§æŠ•å½±çŸ©é˜µï¼Œ$E_{pos} \in \mathbb{R}^{(N+1) \times D}$ æ˜¯ä½ç½®ç¼–ç ã€‚
    - **å…³é”®ç»†èŠ‚**: è¿™ä¸€æ­¥ç­‰ä»·äºä¸€ä¸ª `Conv2d(in_channels=3, out_channels=D, kernel_size=P, stride=P)` æ“ä½œã€‚

2.  **Positional Embedding Interpolation (ä½ç½®ç¼–ç æ’å€¼)**:
    - **é—®é¢˜**: VLA ä»»åŠ¡ä¸­ï¼Œè¾“å…¥å›¾åƒåˆ†è¾¨ç‡å¯èƒ½å˜åŒ– (e.g., 224x224 -> 384x384)ï¼Œå¯¼è‡´ Patch æ•°é‡ $N$ å˜åŒ–ã€‚
    - **è§£å†³æ–¹æ¡ˆ**: é¢„è®­ç»ƒçš„ 1D ä½ç½®ç¼–ç ä¸èƒ½ç›´æ¥ç”¨ã€‚éœ€è¦å°†å…¶ reshape æˆ 2D ç½‘æ ¼ï¼Œè¿›è¡Œ **åŒçº¿æ€§æ’å€¼ (Bicubic/Bilinear Interpolation)** åˆ°æ–°çš„å°ºå¯¸ï¼Œå†å±•å¹³å› 1Dã€‚è¿™æ˜¯ ViT èƒ½å¤„ç†ä¸åŒåˆ†è¾¨ç‡çš„å…³é”®ã€‚

3.  **CLS Token vs Average Pooling**:
    - **CLS Token**: åŸå§‹ ViT åœ¨åºåˆ—å¼€å¤´åŠ ä¸€ä¸ªç‰¹æ®Šçš„ `[CLS]` Tokenï¼Œå…¶è¾“å‡ºä½œä¸ºæ•´å¼ å›¾çš„ç‰¹å¾ (BERT é£æ ¼)ã€‚
    - **Average Pooling (GAP)**: ç°ä»£ ViT (å¦‚ SigLIP) å¾€å¾€å»æ‰ CLS Tokenï¼Œç›´æ¥å¯¹æ‰€æœ‰ Patch çš„è¾“å‡ºå–å¹³å‡ (Global Average Pooling)ã€‚
      - **ä¼˜åŠ¿**: èƒ½å¤Ÿåˆ©ç”¨å…¨å›¾ä¿¡æ¯ï¼Œä¸”å¯¹ Learning Rate æ›´é²æ£’ (MAP è®ºæ–‡æŒ‡å‡º GAP ä¼˜äº CLS)ã€‚

### 5.2 SigLIP (Sigmoid Loss for Language Image Pre-training)
OpenVLA çš„è§†è§‰ç¼–ç å™¨ä½¿ç”¨çš„æ˜¯ **SigLIP** (æ¥è‡ª Google DeepMind)ï¼Œè€Œéä¼ ç»Ÿçš„ CLIPã€‚

#### 1. ä¸ºä»€ä¹ˆä¸ç”¨ CLIP (Softmax Loss)?
ä¼ ç»Ÿçš„ CLIP ä½¿ç”¨ **InfoNCE Loss** (åŸºäº Softmax)ï¼Œéœ€è¦ç»´æŠ¤å·¨å¤§çš„è´Ÿæ ·æœ¬å¯¹ (Negative Pairs)ã€‚
$$
L_{CLIP} = -\frac{1}{N} \sum_{i=1}^N \log \frac{e^{x_i \cdot y_i / \tau}}{\sum_{j=1}^N e^{x_i \cdot y_j / \tau}}
$$
- **é€šä¿¡ç“¶é¢ˆ**: åˆ†æ¯ $\sum e^{...}$ éœ€è¦èšåˆæ‰€æœ‰ GPU ä¸Šçš„æ‰€æœ‰æ ·æœ¬ (Global Reduction)ã€‚åœ¨åˆ†å¸ƒå¼è®­ç»ƒä¸­ï¼Œè¿™ä¼šå¯¼è‡´å·¨å¤§çš„é€šä¿¡å¼€é”€ã€‚

#### 2. SigLIP çš„åˆ›æ–° (Sigmoid Loss)
SigLIP å°† $N \times N$ çš„åŒ¹é…é—®é¢˜è½¬åŒ–ä¸º **$N^2$ ä¸ªç‹¬ç«‹çš„äºŒåˆ†ç±»é—®é¢˜**ã€‚
$$
L_{SigLIP} = - \frac{1}{N} \sum_{i=1}^N \sum_{j=1}^N \left[ \mathbb{I}_{i=j} \log \sigma(x_i \cdot y_j / \tau + b) + \mathbb{I}_{i \neq j} \log (1 - \sigma(x_i \cdot y_j / \tau + b)) \right]
$$
- **$\mathbb{I}_{i=j}$**: æ­£æ ·æœ¬å¯¹ (å¯¹è§’çº¿)ï¼Œæ ‡ç­¾ä¸º 1ã€‚
- **$\mathbb{I}_{i \neq j}$**: è´Ÿæ ·æœ¬å¯¹ (éå¯¹è§’çº¿)ï¼Œæ ‡ç­¾ä¸º 0ã€‚
- **ä¼˜åŠ¿**:
    1.  **æ— éœ€å…¨å±€åŒæ­¥**: æ¯ä¸ª GPU åªéœ€å¤„ç†è‡ªå·±æ‰‹å¤´çš„è´Ÿæ ·æœ¬ï¼Œæ¢¯åº¦è®¡ç®—æ˜¯å±€éƒ¨çš„ã€‚
    2.  **Batch Size ç‹¬ç«‹**: æ€§èƒ½ä¸å†å¼ºä¾èµ–äºè¶…å¤§ Batch Size (CLIP éœ€è¦å¤§ Batch æä¾›è¶³å¤Ÿè´Ÿæ ·æœ¬ï¼ŒSigLIP å¯¹ Batch å¤§å°ä¸æ•æ„Ÿ)ã€‚

#### 3. å…³é”®å®ç°ç»†èŠ‚: Bias Initialization
SigLIP å¼•å…¥äº†ä¸€ä¸ªå¯å­¦ä¹ çš„ Bias $b$ (é€šå¸¸åˆå§‹åŒ–ä¸º $- \log N$)ã€‚
- **åŸå› **: åœ¨è®­ç»ƒåˆæœŸï¼Œæ­£æ ·æœ¬æå°‘ (1ä¸ª)ï¼Œè´Ÿæ ·æœ¬æå¤š ($N-1$ä¸ª)ã€‚å¦‚æœ Bias ä¸º 0ï¼ŒSigmoid è¾“å‡º 0.5ï¼Œä¼šå¯¼è‡´å·¨å¤§çš„åˆå§‹ Loss (å› ä¸ºå¤§éƒ¨åˆ†åº”è¯¥æ˜¯ 0)ã€‚
- **Trick**: åˆå§‹åŒ– $b = -10$ æˆ– $- \log N$ï¼Œå¼ºåˆ¶åˆå§‹æ¦‚ç‡æ¥è¿‘ 0ï¼ŒåŒ¹é…è´Ÿæ ·æœ¬å ä¸»å¯¼çš„å…ˆéªŒåˆ†å¸ƒï¼Œæå¤§åœ°ç¨³å®šäº†è®­ç»ƒã€‚

## 6. è‡ªæ³¨æ„åŠ›æœºåˆ¶è¯¦è§£ (Self-Attention Deep Dive)

### 6.1 è®¡ç®—å…¬å¼

è‡ªæ³¨æ„åŠ›æœºåˆ¶çš„æ ¸å¿ƒå…¬å¼ï¼š

$$
\text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right) V
$$

å…¶ä¸­ï¼š
- $Q = XW_Q$, $K = XW_K$, $V = XW_V$ (çº¿æ€§æŠ•å½±)
- $d_k$: Key çš„ç»´åº¦ (ç”¨äºç¼©æ”¾ï¼Œé˜²æ­¢ç‚¹ç§¯è¿‡å¤§å¯¼è‡´ softmax é¥±å’Œ)
- $X \in \mathbb{R}^{N \times d}$: è¾“å…¥åºåˆ— (N ä¸ª Tokenï¼Œæ¯ä¸ª d ç»´)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Self-Attention è®¡ç®—æµç¨‹                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚   è¾“å…¥ X [N, d]                                                 â”‚
â”‚       â”‚                                                         â”‚
â”‚       â”œâ”€â”€â–¶ W_Q â”€â”€â–¶ Q [N, d_k]                                   â”‚
â”‚       â”œâ”€â”€â–¶ W_K â”€â”€â–¶ K [N, d_k]                                   â”‚
â”‚       â””â”€â”€â–¶ W_V â”€â”€â–¶ V [N, d_v]                                   â”‚
â”‚                                                                 â”‚
â”‚   Step 1: QK^T / âˆšd_k  â”€â”€â–¶  Attention Scores [N, N]             â”‚
â”‚   Step 2: softmax(...)  â”€â”€â–¶  Attention Weights [N, N]           â”‚
â”‚   Step 3: Weights Ã— V   â”€â”€â–¶  Output [N, d_v]                    â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 6.2 è®¡ç®—å¤æ‚åº¦åˆ†æ

| æ­¥éª¤ | æ“ä½œ | æ—¶é—´å¤æ‚åº¦ | ç©ºé—´å¤æ‚åº¦ |
| :--- | :--- | :--- | :--- |
| çº¿æ€§æŠ•å½± | $XW_Q, XW_K, XW_V$ | $O(Nd^2)$ | $O(Nd)$ |
| $QK^T$ | çŸ©é˜µä¹˜æ³• | $O(N^2 d)$ | $O(N^2)$ âš ï¸ |
| Softmax | æŒ‰è¡Œå½’ä¸€åŒ– | $O(N^2)$ | $O(N^2)$ |
| $\text{Attn} \times V$ | çŸ©é˜µä¹˜æ³• | $O(N^2 d)$ | $O(Nd)$ |
| **æ€»è®¡** | | **$O(N^2 d)$** | **$O(N^2)$** |

**å…³é”®æ´å¯Ÿ**:
- **æ—¶é—´å¤æ‚åº¦**: $O(N^2 d)$ï¼Œå¯¹åºåˆ—é•¿åº¦ $N$ æ˜¯å¹³æ–¹çº§
- **ç©ºé—´å¤æ‚åº¦**: $O(N^2)$ï¼Œéœ€è¦å­˜å‚¨å®Œæ•´çš„ $N \times N$ æ³¨æ„åŠ›çŸ©é˜µ
- **ç“¶é¢ˆ**: å½“ $N$ å¾ˆå¤§æ—¶ (å¦‚ VLA ä¸­å¤šå¸§å›¾åƒ + è¯­è¨€ Token)ï¼Œæ˜¾å­˜æˆä¸ºä¸»è¦ç“¶é¢ˆ
- **è§£å†³æ–¹æ¡ˆ**: Flash Attention (å‚è§ [flash_attention.md](./flash_attention.md))

### 6.3 Multi-Head Attention

å°†æ³¨æ„åŠ›åˆ†æˆå¤šä¸ª"å¤´"ï¼Œæ¯ä¸ªå¤´å…³æ³¨ä¸åŒçš„ç‰¹å¾å­ç©ºé—´ï¼š

$$
\text{MultiHead}(Q, K, V) = \text{Concat}(\text{head}_1, ..., \text{head}_h) W^O
$$

$$
\text{head}_i = \text{Attention}(QW_i^Q, KW_i^K, VW_i^V)
$$

**ä¼˜åŠ¿**:
- ä¸åŒå¤´å¯ä»¥å…³æ³¨ä¸åŒç±»å‹çš„å…³ç³» (ä½ç½®ã€è¯­ä¹‰ã€çº¹ç†ç­‰)
- å‚æ•°é‡ä¸å˜ ($d_k = d / h$)ï¼Œä½†è¡¨è¾¾èƒ½åŠ›æ›´å¼º

---

## 7. é¢è¯•å¸¸è§é—®é¢˜

**Q: è‡ªæ³¨æ„åŠ›æœºåˆ¶æ˜¯ä»€ä¹ˆï¼Ÿè®¡ç®—å¤æ‚åº¦æ€ä¹ˆç®—ï¼Ÿ**
A: è‡ªæ³¨æ„åŠ›è®©åºåˆ—ä¸­æ¯ä¸ªä½ç½®éƒ½èƒ½ç›´æ¥å…³æ³¨å…¶ä»–æ‰€æœ‰ä½ç½®ã€‚è®¡ç®— $QK^T$ éœ€è¦ $O(N^2 d)$ æ—¶é—´å’Œ $O(N^2)$ ç©ºé—´ï¼Œå…¶ä¸­ $N$ æ˜¯åºåˆ—é•¿åº¦ï¼Œ$d$ æ˜¯ç‰¹å¾ç»´åº¦ã€‚è¿™æ˜¯ Transformer å¤„ç†é•¿åºåˆ—æ—¶çš„ä¸»è¦ç“¶é¢ˆã€‚

**Q: ä¸ºä»€ä¹ˆè¦é™¤ä»¥ $\sqrt{d_k}$ï¼Ÿ**
A: å½“ $d_k$ è¾ƒå¤§æ—¶ï¼Œ$QK^T$ çš„ç‚¹ç§¯å€¼ä¼šå¾ˆå¤§ï¼Œå¯¼è‡´ softmax è¾“å‡ºæ¥è¿‘ one-hot (æ¢¯åº¦æ¶ˆå¤±)ã€‚é™¤ä»¥ $\sqrt{d_k}$ å¯ä»¥ç¨³å®šæ¢¯åº¦ã€‚

**Q: ä¸ºä»€ä¹ˆ ViT éœ€è¦æ¯” ResNet æ›´å¤šçš„æ•°æ®?**
A: å› ä¸º ViT ç¼ºä¹ **å½’çº³åç½® (Inductive Bias)**ã€‚CNN å¤©ç”ŸçŸ¥é“"ç›¸é‚»åƒç´ ç›¸å…³"å’Œ"å¹³ç§»ä¸å˜"ï¼Œè€Œ ViT å¿…é¡»ä»æ•°æ®ä¸­è‡ªå·±å­¦ä¹ è¿™äº›è§„å¾‹ã€‚

**Q: ä»€ä¹ˆæ˜¯ Patchify?**
A: å°†ä¸€å¼ å›¾ç‰‡åˆ‡æˆä¸€ä¸ªä¸ªå°æ–¹å— (e.g., 16x16 åƒç´ )ï¼Œæ‹‰å¹³æˆå‘é‡ï¼Œä½œä¸º Transformer çš„è¾“å…¥ Tokenã€‚è¿™ç›¸å½“äº NLP ä¸­çš„åˆ†è¯ (Tokenization)ã€‚


---

\newpage

# ç¬¬2ç«  Flash Attention ä¸æ¨ç†ä¼˜åŒ–


Flash Attention æ˜¯ Transformer æ¨¡å‹ï¼ˆåŒ…æ‹¬ VLAï¼‰åœ¨éƒ¨ç½²æ—¶çš„æ ¸å¿ƒä¼˜åŒ–æŠ€æœ¯ï¼Œè§£å†³äº†æ ‡å‡† Attention çš„å†…å­˜ç“¶é¢ˆé—®é¢˜ã€‚

## 0. ä¸»è¦æ•¸å­¸æ€æƒ³ (Main Mathematical Idea)

> **ç¬¬ä¸€æ€§åŸç†**: **Locality of Reference (å¼•ç”¨çš„å±€éƒ¨æ€§ / Tiling)**

åœ¨ç°ä»£è®¡ç®—ç¡¬ä»¶ï¼ˆGPUï¼‰ä¸­ï¼Œ**æ¬è¿æ•°æ®**æ¯”**è®¡ç®—æ•°æ®**è¦æ…¢å¾—å¤šä¸”æ˜‚è´µå¾—å¤šã€‚æ•°å­¦å…¬å¼ç­‰ä»·å¹¶ä¸ä»£è¡¨è®¡ç®—æ•ˆç‡ç­‰ä»·ã€‚

- **æ ¸å¿ƒæ•°å­¦å·¥å…·**: **Block Matrix Multiplication (åˆ†å—çŸ©é˜µä¹˜æ³•)** ä¸ **Online Statistics (åœ¨çº¿ç»Ÿè®¡é‡)**ã€‚
- **è§£é¢˜é€»è¾‘**:
    1.  **åˆ†å— (Tiling)**: å°†å·¨å¤§çš„çŸ©é˜µ $N \times N$ åˆ‡åˆ†æˆå°å—ï¼Œä½¿å¾—æ¯ä¸ªå°å—å¯ä»¥å®Œå…¨å¡è¿› GPU æå¿«çš„ç‰‡ä¸Šç¼“å­˜ (SRAM)ã€‚
    2.  **åœ¨çº¿ Softmax**: æ ‡å‡† Softmax éœ€è¦éå†å…¨è¡Œæ‰èƒ½è®¡ç®—å½’ä¸€åŒ–å› å­ã€‚Flash Attention åˆ©ç”¨æ•°å­¦æŠ€å·§ ($e^{x-m}$)ï¼Œä½¿å¾— Softmax å¯ä»¥åˆ†å—å¢é‡è®¡ç®—ï¼Œæ— éœ€ç­‰å¾…å…¨è¡Œç»“æœã€‚
    3.  **é‡è®¡ç®—**: æœ‰æ—¶ä¸ºäº†çœå»æ˜‚è´µçš„æ˜¾å­˜è¯»å†™ (HBM I/O)ï¼Œå®æ„¿åœ¨ SRAM ä¸­é‡æ–°ç®—ä¸€éï¼ˆRecomputationï¼‰ã€‚è¿™æ˜¯å…¸å‹çš„"æ—¶é—´æ¢ç©ºé—´ï¼Œç©ºé—´æ¢å¸¦å®½"ã€‚

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Flash Attention vs æ ‡å‡† Attention                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚   æ ‡å‡† Attention (å†…å­˜ç“¶é¢ˆ)           Flash Attention (åˆ†å—)    â”‚
â”‚                                                                 â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚   â”‚      Q Â· K^T      â”‚               â”‚   Qâ‚Â·Kâ‚  Qâ‚Â·Kâ‚‚   â”‚     â”‚
â”‚   â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚               â”‚  â”Œâ”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”  â”‚     â”‚
â”‚   â”‚   â”‚             â”‚ â”‚   â”€â”€â”€â”€â–¶       â”‚  â”‚ å—1 â”‚â”‚ å—2 â”‚  â”‚     â”‚
â”‚   â”‚   â”‚   N Ã— N     â”‚ â”‚   åˆ†å—        â”‚  â””â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”˜  â”‚     â”‚
â”‚   â”‚   â”‚  (å·¨å¤§!)    â”‚ â”‚               â”‚  â”Œâ”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”  â”‚     â”‚
â”‚   â”‚   â”‚             â”‚ â”‚               â”‚  â”‚ å—3 â”‚â”‚ å—4 â”‚  â”‚     â”‚
â”‚   â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚               â”‚  â””â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”˜  â”‚     â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚   å†…å­˜: O(NÂ²) âŒ                       å†…å­˜: O(N) âœ…             â”‚
â”‚                                                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                        å†…å­˜å±‚çº§ä¼˜åŒ–                              â”‚
â”‚                                                                 â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚   â”‚      HBM       â”‚     â”‚     SRAM       â”‚                     â”‚
â”‚   â”‚   (æ˜¾å­˜)       â”‚     â”‚   (L2 Cache)   â”‚                     â”‚
â”‚   â”‚   24GB+        â”‚ â—€â”€â–¶ â”‚    ~20MB       â”‚                     â”‚
â”‚   â”‚   æ…¢ 1TB/s     â”‚     â”‚   å¿« 19TB/s    â”‚                     â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚          â”‚                      â”‚                               â”‚
â”‚          â”‚   æ ‡å‡†: å¤šæ¬¡è¯»å†™      â”‚   Flash: ä¸€æ¬¡åŠ è½½             â”‚
â”‚          â”‚   Q,K â”€â”€â–¶ S â”€â”€â–¶ P    â”‚   å…¨éƒ¨åœ¨ SRAM è®¡ç®—            â”‚
â”‚          â”‚   æ¯æ­¥å†™å› HBM       â”‚   åªå†™æœ€ç»ˆç»“æœ                 â”‚
â”‚          â”‚                      â”‚                               â”‚
â”‚   ç»“æœ: 2-4x åŠ é€Ÿ, æ˜¾å­˜ O(NÂ²) â†’ O(N)                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## 1. ä¸ºä»€ä¹ˆéœ€è¦ Flash Attention?

### æ ‡å‡† Attention çš„é—®é¢˜
æ ‡å‡†çš„ Scaled Dot-Productæ ‡å‡† Attention è®¡ç®—å…¬å¼ï¼š

```
Attention(Q, K, V) = softmax(QÂ·K^T / âˆšd_k) Â· V
```

- **å†…å­˜ç“¶é¢ˆ**: è®¡ç®— $QK^T$ éœ€è¦å­˜å‚¨ $N \times N$ çš„æ³¨æ„åŠ›çŸ©é˜µï¼Œå…¶ä¸­ $N$ æ˜¯åºåˆ—é•¿åº¦ã€‚
- **å®ä¾‹**: å¯¹äº ViT (åºåˆ—é•¿åº¦ 196), $196 \times 196 = 38,416$ ä¸ªæµ®ç‚¹æ•°ã€‚VLA ä¸­è‹¥åŒ…å«å¤šå¸§å›¾åƒï¼Œ$N$ å¯èƒ½è¾¾åˆ°æ•°åƒã€‚
- **æ˜¾å­˜å ç”¨**: $O(N^2)$ çš„å†…å­˜å ç”¨ä½¿å¾—é•¿åºåˆ—æ¨ç†å‡ ä¹ä¸å¯è¡Œã€‚

## 2. Flash Attention çš„æ ¸å¿ƒæ€æƒ³

### Tiling (åˆ†å—è®¡ç®—)
Flash Attention é€šè¿‡ **åˆ†å— (Tiling)** é¿å…å®é™…å­˜å‚¨å®Œæ•´çš„ $QK^T$ çŸ©é˜µã€‚

**ç®—æ³•æµç¨‹**:
1. å°† $Q, K, V$ åˆ†å‰²æˆå°å— (Tiles)ã€‚
2. é€å—è®¡ç®— Attentionï¼Œåœ¨ SRAM (L2 Cache) ä¸­å®Œæˆã€‚
3. ä½¿ç”¨ **åœ¨çº¿ Softmax (Online Softmax)** æŠ€æœ¯å¢é‡æ›´æ–°å½’ä¸€åŒ–ã€‚
4. æœ€ç»ˆåˆå¹¶ç»“æœï¼Œé¿å…å°†ä¸­é—´ç»“æœå†™å› HBM (High Bandwidth Memory)ã€‚

### 2.1 Kernel Fusion (ç®—å­èåˆ): IO-Aware Computing
Flash Attention çš„æ ¸å¿ƒæ´å¯Ÿæ˜¯ï¼š**Transformer çš„ç“¶é¢ˆä¸åœ¨è®¡ç®— (FLOPs)ï¼Œè€Œåœ¨æ˜¾å­˜è¯»å†™ (HBM IO)**ã€‚

-   **HBM vs SRAM**:
    -   **HBM (High Bandwidth Memory)**: æ˜¾å­˜ï¼Œå®¹é‡å¤§ (24GB+)ï¼Œä½†é€Ÿåº¦æ…¢ (1-2 TB/s)ã€‚
    -   **SRAM (L2 Cache)**: ç‰‡ä¸Šç¼“å­˜ï¼Œå®¹é‡å° (å‡ å MB)ï¼Œä½†é€Ÿåº¦æå¿« (19 TB/s+)ã€‚
-   **æ ‡å‡† Attention**: éœ€è¦å¤šæ¬¡è¯»å†™ HBMã€‚
    1.  è¯» $Q, K$ -> ç®— $S = QK^T$ -> å†™å› HBM ($N^2$)ã€‚
    2.  è¯» $S$ -> ç®— $P = \text{softmax}(S)$ -> å†™å› HBM ($N^2$)ã€‚
    3.  è¯» $P, V$ -> ç®— $O = PV$ -> å†™å› HBMã€‚
-   **Flash Attention Fusion**:
    -   å°†ä¸Šè¿°æ‰€æœ‰æ­¥éª¤èåˆè¿›**åŒä¸€ä¸ª CUDA Kernel**ã€‚
    -   æ•°æ®ä¸€æ—¦ä» HBM åŠ è½½åˆ° SRAMï¼Œå°±åœ¨ SRAM ä¸­å®Œæˆ $QK^T$, Softmax, $PV$ çš„æ‰€æœ‰è®¡ç®—ï¼ŒåªæŠŠæœ€ç»ˆç»“æœ $O$ å†™å› HBMã€‚
    -   **ç»“æœ**: HBM è¯»å†™é‡ä» $O(N^2)$ é™ä½åˆ° $O(N)$ï¼Œå°½ç®¡ FLOPs æ²¡å˜ï¼Œä½†ç«¯åˆ°ç«¯é€Ÿåº¦æå‡äº† 2-4 å€ã€‚

### 2.2 Recomputation (é‡è®¡ç®—): æ¢å–æ˜¾å­˜çš„è‰ºæœ¯
åœ¨è®­ç»ƒæ—¶çš„åå‘ä¼ æ’­ (Backward Pass) ä¸­ï¼Œé€šå¸¸éœ€è¦ä¿å­˜å‰å‘ä¼ æ’­çš„ä¸­é—´æ¿€æ´»å€¼ (Activations) æ¥è®¡ç®—æ¢¯åº¦ã€‚

-   **æ ‡å‡†åšæ³•**: ä¿å­˜å·¨å¤§çš„ $N \times N$ æ³¨æ„åŠ›çŸ©é˜µ $P$ã€‚è¿™ç›´æ¥å¯¼è‡´äº† OOM (Out of Memory)ã€‚
-   **Flash Attention åšæ³•**:
    -   **ä¸ä¿å­˜** $P$ çŸ©é˜µã€‚
    -   åœ¨åå‘ä¼ æ’­æ—¶ï¼Œåˆ©ç”¨ä¿å­˜åœ¨ SRAM ä¸­çš„ $Q, K, V$ å—ï¼Œ**é‡æ–°è®¡ç®—**ä¸€é Attentionã€‚
-   **ä¸ºä»€ä¹ˆæ›´å¿«?**
    -   ç›´è§‰ä¸Šï¼Œé‡è®¡ç®—ä¼šå¢åŠ  FLOPsï¼Œåº”è¯¥å˜æ…¢ã€‚
    -   ä½†ç”±äº Attention æ˜¯ **IO-Bound** (å—é™äºå¸¦å®½) çš„ï¼Œé‡è®¡ç®—å¸¦æ¥çš„é¢å¤– FLOPs å¼€é”€ï¼Œè¿œå°äºä» HBM è¯»å–å·¨å¤§çŸ©é˜µ $P$ çš„æ—¶é—´å¼€é”€ã€‚
    -   **ç»“è®º**: Recomputation ä¸ä»…çœäº†æ˜¾å­˜ï¼Œåè€Œå› ä¸ºå‡å°‘äº† IO è€Œå˜å¿«äº†ã€‚

### æ•°å­¦æ¨å¯¼ï¼šåœ¨çº¿ Softmax

æ ‡å‡† Softmax éœ€è¦ä¸¤æ¬¡æ‰«æåºåˆ—ï¼ˆä¸€æ¬¡æ±‚å’Œï¼Œä¸€æ¬¡å½’ä¸€åŒ–ï¼‰ã€‚Flash Attention ä½¿ç”¨å¢é‡æ›´æ–°ï¼š

```
softmax(x)_i = exp(x_i) / Î£ exp(x_j)  (j=1 åˆ° N)
```

é€šè¿‡ç»´æŠ¤è¿è¡Œä¸­çš„ **æœ€å¤§å€¼ m** å’Œ **ç´¯ç§¯å’Œ l**ï¼Œå¯ä»¥é€å—æ›´æ–°ï¼š

```
m_new = max(m_old, m_block)

l_new = exp(m_old - m_new) * l_old + exp(m_block - m_new) * l_block
```

## 3. åœ¨ VLA ä¸­çš„åº”ç”¨

### Wall-X / OpenVLA
- **Wall-X**: requirements.txt ä¸­æ˜ç¡®ä¾èµ– `flash-attn==2.7.4`ã€‚
- **OpenVLA**: æ”¯æŒ Flash Attention 2 åŠ é€Ÿæ¨ç†ï¼Œå°¤å…¶åœ¨å¤„ç†é•¿å†å²åºåˆ—æ—¶ã€‚

### Pi0
- Pi0 ä½¿ç”¨ Flow Matchingï¼Œæ¨ç†æ—¶éœ€è¦å¤šæ­¥ ODE Solverã€‚Flash Attention åœ¨æ¯ä¸€æ­¥éƒ½èƒ½æ˜¾è‘—å‡å°‘æ˜¾å­˜å ç”¨ã€‚

### æ€§èƒ½æå‡
- **é€Ÿåº¦**: 2-4x åŠ é€Ÿï¼ˆç›¸æ¯”æ ‡å‡† Attentionï¼‰ã€‚
- **æ˜¾å­˜**: å†…å­˜å ç”¨ä» $O(N^2)$ é™è‡³ $O(N)$ã€‚
- **éƒ¨ç½²**: ä½¿å¾—åœ¨æ¶ˆè´¹çº§ GPU (e.g., RTX 4090) ä¸Šéƒ¨ç½² 7B VLA æˆä¸ºå¯èƒ½ã€‚

## 4. Flash Attention vs å…¶ä»–ä¼˜åŒ–

| æŠ€æœ¯ | å†…å­˜å¤æ‚åº¦ | ç²¾åº¦ | é€‚ç”¨åœºæ™¯ |
| :--- | :--- | :--- | :--- |
| **Standard Attention** | $O(N^2)$ | ç²¾ç¡® | çŸ­åºåˆ— |
| **Flash Attention** | $O(N)$ | ç²¾ç¡® | é•¿åºåˆ—ï¼ŒçœŸæœºæ¨ç† |
| **Sparse Attention** | $O(N \log N)$ | è¿‘ä¼¼ | è¶…é•¿æ–‡æœ¬ (ä¸é€‚åˆ VLA) |
| **Linear Attention** | $O(N)$ | è¿‘ä¼¼ | ç ”ç©¶é˜¶æ®µ |

## 5. KV-Cache æ¨ç†åŠ é€Ÿ (KV-Cache for Inference)

### 5.1 é—®é¢˜èƒŒæ™¯

åœ¨è‡ªå›å½’ç”Ÿæˆ (Autoregressive Generation) æ—¶ï¼Œæ¯ç”Ÿæˆä¸€ä¸ªæ–° Token éƒ½éœ€è¦è®¡ç®— Attentionï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   æ—  KV-Cache çš„æ¨ç†                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚   ç”Ÿæˆ Token 1:  è®¡ç®— Kâ‚, Vâ‚                                    â”‚
â”‚   ç”Ÿæˆ Token 2:  é‡æ–°è®¡ç®— Kâ‚, Kâ‚‚, Vâ‚, Vâ‚‚  â† é‡å¤è®¡ç®—!            â”‚
â”‚   ç”Ÿæˆ Token 3:  é‡æ–°è®¡ç®— Kâ‚, Kâ‚‚, Kâ‚ƒ, Vâ‚, Vâ‚‚, Vâ‚ƒ  â† æ›´å¤šé‡å¤!   â”‚
â”‚   ...                                                           â”‚
â”‚   ç”Ÿæˆ Token N:  é‡æ–°è®¡ç®— Kâ‚...K_N, Vâ‚...V_N  â† O(NÂ²) æ€»è®¡ç®—é‡   â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5.2 KV-Cache åŸç†

**æ ¸å¿ƒæ€æƒ³**: ç¼“å­˜å·²è®¡ç®—çš„ Key å’Œ Valueï¼Œæ–° Token åªéœ€è®¡ç®—å¢é‡ã€‚

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   æœ‰ KV-Cache çš„æ¨ç†                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚   ç”Ÿæˆ Token 1:  è®¡ç®— Kâ‚, Vâ‚ â†’ å­˜å…¥ Cache                        â”‚
â”‚   ç”Ÿæˆ Token 2:  åªè®¡ç®— Kâ‚‚, Vâ‚‚ â†’ è¿½åŠ åˆ° Cache                    â”‚
â”‚   ç”Ÿæˆ Token 3:  åªè®¡ç®— Kâ‚ƒ, Vâ‚ƒ â†’ è¿½åŠ åˆ° Cache                    â”‚
â”‚   ...                                                           â”‚
â”‚   ç”Ÿæˆ Token N:  åªè®¡ç®— K_N, V_N â†’ O(N) æ€»è®¡ç®—é‡                 â”‚
â”‚                                                                 â”‚
â”‚   Attention è®¡ç®—:                                               â”‚
â”‚   Q_new (1, d) Ã— K_cache^T (N, d) â†’ Scores (1, N)               â”‚
â”‚   Scores Ã— V_cache (N, d) â†’ Output (1, d)                       â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5.3 åŠ é€Ÿæ•ˆæœ

| æŒ‡æ ‡ | æ—  KV-Cache | æœ‰ KV-Cache |
| :--- | :--- | :--- |
| æ¯ Token è®¡ç®—é‡ | $O(N^2 d)$ | $O(Nd)$ |
| ç”Ÿæˆ N ä¸ª Token | $O(N^3 d)$ | $O(N^2 d)$ |
| N=1000 æ—¶åŠ é€Ÿæ¯” | 1x | **~1000x** |

### 5.4 æ˜¾å­˜ä»£ä»·

KV-Cache éœ€è¦é¢å¤–æ˜¾å­˜å­˜å‚¨å†å² K å’Œ Vï¼š


$$
\text{KV-Cache æ˜¾å­˜} = 2 \times L \times N \times d \times \text{batch\_size} \times \text{bytes}
$$


- $L$: Transformer å±‚æ•°
- $N$: åºåˆ—é•¿åº¦
- $d$: éšè—ç»´åº¦
- Factor 2: K å’Œ V å„ä¸€ä»½

**ç¤ºä¾‹ (Llama-7B, FP16)**:
- $L=32, d=4096, N=2048, \text{batch}=1$
- KV-Cache = $2 \times 32 \times 2048 \times 4096 \times 2 \text{ bytes} \approx 1 \text{ GB}$

### 5.5 KV-Cache ä¼˜åŒ–æŠ€æœ¯

| æŠ€æœ¯ | åŸç† | èŠ‚çœæ¯”ä¾‹ |
| :--- | :--- | :--- |
| **GQA (Grouped Query Attention)** | å¤šä¸ª Q å¤´å…±äº« K/V å¤´ | 4-8x |
| **MQA (Multi-Query Attention)** | æ‰€æœ‰ Q å¤´å…±äº«ä¸€ç»„ K/V | æ›´æ¿€è¿› |
| **Paged Attention (vLLM)** | ç±»ä¼¼è™šæ‹Ÿå†…å­˜ï¼ŒæŒ‰éœ€åˆ†é… | åŠ¨æ€ä¼˜åŒ– |
| **KV-Cache é‡åŒ–** | INT8/INT4 å­˜å‚¨ | 2-4x |

---

## 6. é¢è¯•å¸¸è§é—®é¢˜

**Q: Flash Attention çš„åŸç†æ˜¯ä»€ä¹ˆï¼Ÿ**
A: ä¸‰ä¸ªå…³é”®æŠ€æœ¯ï¼š
1. **Tiling (åˆ†å—)**: å°† $QK^T$ åˆ†æˆå°å—è®¡ç®—ï¼Œé¿å…å­˜å‚¨å®Œæ•´ $N \times N$ çŸ©é˜µ
2. **Kernel Fusion**: å°† $QK^T \to \text{softmax} \to \times V$ èåˆè¿›å•ä¸ª CUDA Kernelï¼Œå‡å°‘ HBM è¯»å†™
3. **Online Softmax**: å¢é‡æ›´æ–°å½’ä¸€åŒ–å¸¸æ•°ï¼Œæ”¯æŒåˆ†å—è®¡ç®—
ç»“æœ: å†…å­˜ $O(N^2) \to O(N)$ï¼Œé€Ÿåº¦ 2-4x åŠ é€Ÿã€‚

**Q: KV-Cache å¦‚ä½•åŠ é€Ÿæ¨ç†ï¼Ÿ**
A: åœ¨è‡ªå›å½’ç”Ÿæˆæ—¶ï¼Œç¼“å­˜å·²è®¡ç®—çš„ K å’Œ Vï¼Œæ–° Token åªéœ€è®¡ç®—å¢é‡ $K_{new}, V_{new}$ã€‚å°†æ¯ Token è®¡ç®—é‡ä» $O(N^2 d)$ é™åˆ° $O(Nd)$ï¼ŒN=1000 æ—¶çº¦ 1000 å€åŠ é€Ÿã€‚ä»£ä»·æ˜¯é¢å¤–æ˜¾å­˜ $O(LNd)$ã€‚

**Q: Flash Attention æ˜¯å¦‚ä½•åšåˆ°ç²¾ç¡®è®¡ç®—çš„ï¼Ÿ**
A: é€šè¿‡åœ¨çº¿ Softmax å’Œåˆ†å—è®¡ç®—ï¼ŒFlash Attention åœ¨æ•°å­¦ä¸Šç­‰ä»·äºæ ‡å‡† Attentionï¼Œåªæ˜¯æ”¹å˜äº†è®¡ç®—é¡ºåºå’Œå†…å­˜è®¿é—®æ¨¡å¼ï¼Œæ²¡æœ‰å¼•å…¥ä»»ä½•è¿‘ä¼¼ã€‚

**Q: ä¸ºä»€ä¹ˆä¸èƒ½ç›´æ¥ç”¨ Sparse Attention?**
A: VLA çš„æ³¨æ„åŠ›æ¨¡å¼é€šå¸¸æ˜¯å¯†é›†çš„ï¼ˆè§†è§‰ Patch ä¹‹é—´å…³ç³»ç´§å¯†ï¼‰ï¼Œç¨€ç–å‡è®¾ä¸æˆç«‹ã€‚Flash Attention ä¿æŒäº†å¯†é›†è®¡ç®—ï¼Œåªæ˜¯ä¼˜åŒ–äº†å†…å­˜ã€‚

**Q: Flash Attention å¯¹è®­ç»ƒå’Œæ¨ç†éƒ½æœ‰æ•ˆå—ï¼Ÿ**
A: æ˜¯çš„ã€‚è®­ç»ƒæ—¶é€šè¿‡ Recomputation èŠ‚çœæ˜¾å­˜ï¼Œæ¨ç†æ—¶é€šè¿‡ Kernel Fusion åŠ é€Ÿã€‚Wall-X ç­‰æ¨¡å‹åœ¨ä¸¤è€…éƒ½ä½¿ç”¨ã€‚


---

\newpage

# ç¬¬3ç«  å¤šæ¨¡æ€æ¨¡å‹åŸºç¡€


> **æ ¸å¿ƒæ¦‚å¿µ**: å¤šæ¨¡æ€æ¨¡å‹ (Multimodal Models) æ˜¯æŒ‡èƒ½å¤ŸåŒæ—¶å¤„ç†å¤šç§æ•°æ®æ¨¡æ€ï¼ˆå¦‚è§†è§‰ã€è¯­è¨€ã€éŸ³é¢‘ã€è§¦è§‰ç­‰ï¼‰çš„æ·±åº¦å­¦ä¹ æ¨¡å‹ã€‚åœ¨ VLA é¢†åŸŸï¼Œå¤šæ¨¡æ€èƒ½åŠ›æ˜¯è¿æ¥"çœ‹"ã€"è¯´"ã€"åš"çš„å…³é”®ã€‚

## 1. ä¸ºä»€ä¹ˆéœ€è¦å¤šæ¨¡æ€? (Why Multimodal?)

### 1.1 æœºå™¨äººçš„æ„ŸçŸ¥éœ€æ±‚

æœºå™¨äººåœ¨çœŸå®ä¸–ç•Œä¸­éœ€è¦åŒæ—¶å¤„ç†å¤šç§ä¿¡æ¯ï¼š

| æ¨¡æ€ | æ¥æº | ä½œç”¨ |
| :--- | :--- | :--- |
| **è§†è§‰ (Vision)** | RGB ç›¸æœºã€æ·±åº¦ç›¸æœº | ç†è§£åœºæ™¯ã€è¯†åˆ«ç‰©ä½“ |
| **è¯­è¨€ (Language)** | è¯­éŸ³æŒ‡ä»¤ã€æ–‡æœ¬ | ç†è§£ä»»åŠ¡æ„å›¾ |
| **æœ¬ä½“æ„ŸçŸ¥ (Proprioception)** | å…³èŠ‚ç¼–ç å™¨ã€IMU | æ„ŸçŸ¥è‡ªèº«çŠ¶æ€ |
| **è§¦è§‰ (Tactile)** | è§¦è§‰ä¼ æ„Ÿå™¨ | æ„ŸçŸ¥æ¥è§¦åŠ›ã€çº¹ç† |
| **éŸ³é¢‘ (Audio)** | éº¦å…‹é£ | ç¯å¢ƒå£°éŸ³ã€è¯­éŸ³äº¤äº’ |

### 1.2 å•æ¨¡æ€çš„å±€é™æ€§

- **ä»…è§†è§‰**: æ— æ³•ç†è§£æŠ½è±¡æŒ‡ä»¤ï¼ˆ"æŠŠé‚£ä¸ªå±é™©çš„ä¸œè¥¿æ‹¿èµ°"ï¼‰
- **ä»…è¯­è¨€**: æ— æ³•å®šä½å…·ä½“ç‰©ä½“ï¼ˆ"æ¡Œä¸Šçš„çº¢è‰²æ¯å­"åœ¨å“ªï¼Ÿï¼‰
- **ç¼ºä¹æœ¬ä½“æ„ŸçŸ¥**: ä¸çŸ¥é“æœºæ¢°è‡‚å½“å‰å§¿æ€ï¼Œæ— æ³•é—­ç¯æ§åˆ¶

### 1.3 å¤šæ¨¡æ€çš„ä¼˜åŠ¿


$$
\text{å¤šæ¨¡æ€ç†è§£} > \sum \text{å•æ¨¡æ€ç†è§£}
$$


- **è¯­ä¹‰æ¥åœ° (Grounding)**: å°†è¯­è¨€æ¦‚å¿µä¸è§†è§‰å®ä½“ç»‘å®š
- **è·¨æ¨¡æ€æ¨ç†**: "çº¢è‰²çš„ä¸œè¥¿"ï¼ˆè¯­è¨€ï¼‰â†’ é”å®šçº¢è‰²ç‰©ä½“ï¼ˆè§†è§‰ï¼‰â†’ æŠ“å–åŠ¨ä½œ
- **é²æ£’æ€§**: ä¸€ä¸ªæ¨¡æ€å¤±æ•ˆæ—¶ï¼Œå…¶ä»–æ¨¡æ€å¯ä»¥è¡¥å¿

## 2. å¤šæ¨¡æ€æ¶æ„æ¼”è¿› (Architecture Evolution)

### 2.1 æ—©æœŸï¼šåŒå¡”æ¨¡å‹ (Dual-Encoder)

```
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
å›¾åƒ â”€â”€â”€â”€â–¶â”‚  Image      â”‚      â”‚   Text      â”‚â—€â”€â”€â”€â”€ æ–‡æœ¬
          â”‚  Encoder    â”‚      â”‚   Encoder   â”‚
          â”‚  (ResNet)   â”‚      â”‚   (BERT)    â”‚
          â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                 â”‚                    â”‚
                 â–¼                    â–¼
              img_emb              text_emb
                 â”‚                    â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                    Cosine Similarity
```

**ä»£è¡¨**: CLIP, ALIGN
**ç‰¹ç‚¹**: å›¾åƒå’Œæ–‡æœ¬ç‹¬ç«‹ç¼–ç ï¼Œé€šè¿‡å¯¹æ¯”å­¦ä¹ å¯¹é½åˆ°åŒä¸€ç©ºé—´
**å±€é™**: æ— æ³•è¿›è¡Œæ·±åº¦çš„è·¨æ¨¡æ€äº¤äº’

### 2.2 ä¸­æœŸï¼šèåˆç¼–ç å™¨ (Fusion Encoder)

```
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
å›¾åƒ â”€â”€â”€â”€â–¶â”‚  Image      â”‚      â”‚   Text      â”‚â—€â”€â”€â”€â”€ æ–‡æœ¬
          â”‚  Encoder    â”‚      â”‚   Encoder   â”‚
          â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                 â”‚                    â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â–¼
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚  Fusion Module  â”‚
                 â”‚  (Cross-Attn)   â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â–¼
                   Fused Features
```

**ä»£è¡¨**: ViLBERT, LXMERT, UNITER
**ç‰¹ç‚¹**: é€šè¿‡ Cross-Attention å®ç°æ·±åº¦äº¤äº’
**æ”¹è¿›**: æ”¯æŒæ›´å¤æ‚çš„å¤šæ¨¡æ€æ¨ç†

### 2.3 ç°ä»£ï¼šç»Ÿä¸€è§£ç å™¨ (Unified Decoder)

```
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
å›¾åƒ â”€â”€â”€â”€â–¶â”‚  Vision     â”‚â”€â”€â”
          â”‚  Encoder    â”‚  â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                           â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                           â”œâ”€â”€â–¶â”‚     LLM Decoder     â”‚â”€â”€â–¶ è¾“å‡º
                           â”‚   â”‚  (Unified Token)    â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
æ–‡æœ¬ â”€â”€â”€â”€â–¶â”‚  Tokenizer  â”‚â”€â”€â”˜
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ä»£è¡¨**: Flamingo, LLaVA, GPT-4V, Gemini
**ç‰¹ç‚¹**: å°†è§†è§‰ç‰¹å¾ä½œä¸º"è™šæ‹Ÿ Token"è¾“å…¥åˆ° LLM
**ä¼˜åŠ¿**: åˆ©ç”¨ LLM çš„å¼ºå¤§æ¨ç†èƒ½åŠ›ï¼Œæ”¯æŒä»»æ„è¾“å…¥è¾“å‡ºç»„åˆ

## 3. VLA ä¸­çš„å¤šæ¨¡æ€èåˆç­–ç•¥ (Fusion Strategies in VLA)

### 3.1 æ—©æœŸèåˆ (Early Fusion)

åœ¨ç‰¹å¾æå–é˜¶æ®µå°±è¿›è¡Œèåˆã€‚

```python
class EarlyFusion(nn.Module):
    def __init__(self):
        self.vision_proj = nn.Linear(vision_dim, hidden_dim)
        self.language_proj = nn.Linear(language_dim, hidden_dim)
        self.proprio_proj = nn.Linear(proprio_dim, hidden_dim)
        
    def forward(self, image_feat, text_feat, proprio):
        # ç›´æ¥æ‹¼æ¥
        fused = torch.cat([
            self.vision_proj(image_feat),
            self.language_proj(text_feat),
            self.proprio_proj(proprio)
        ], dim=1)  # [B, L_v + L_t + 1, D]
        return fused
```

**ä¼˜ç‚¹**: ç®€å•é«˜æ•ˆ
**ç¼ºç‚¹**: ä¸åŒæ¨¡æ€çš„ç‰¹å¾å°ºåº¦å¯èƒ½ä¸åŒ¹é…

### 3.2 ä¸­æœŸèåˆ (Mid Fusion / Cross-Attention)

é€šè¿‡æ³¨æ„åŠ›æœºåˆ¶åŠ¨æ€èåˆã€‚

```python
class CrossModalAttention(nn.Module):
    def __init__(self, hidden_dim, num_heads=8):
        self.cross_attn = nn.MultiheadAttention(hidden_dim, num_heads)
        
    def forward(self, query_feat, context_feat):
        """
        query_feat: éœ€è¦è¢«å¢å¼ºçš„ç‰¹å¾ (e.g., åŠ¨ä½œ query)
        context_feat: æä¾›ä¸Šä¸‹æ–‡çš„ç‰¹å¾ (e.g., å›¾åƒ + è¯­è¨€)
        """
        # Query attends to Context
        attended, attn_weights = self.cross_attn(
            query=query_feat,
            key=context_feat,
            value=context_feat
        )
        return attended, attn_weights
```

**ä»£è¡¨**: RT-1 (TokenLearner)ï¼ŒOcto
**ä¼˜ç‚¹**: åŠ¨æ€å­¦ä¹ æ¨¡æ€é—´å…³ç³»
**ç¼ºç‚¹**: è®¡ç®—å¼€é”€å¤§

### 3.3 æ™šæœŸèåˆ (Late Fusion)

å„æ¨¡æ€ç‹¬ç«‹å¤„ç†åå†åˆå¹¶å†³ç­–ã€‚

```python
class LateFusion(nn.Module):
    def __init__(self):
        self.vision_policy = VisionPolicy()
        self.language_policy = LanguagePolicy()
        self.fusion_head = nn.Linear(hidden_dim * 2, action_dim)
        
    def forward(self, image, text):
        vision_out = self.vision_policy(image)
        language_out = self.language_policy(text)
        
        # å†³ç­–å±‚èåˆ
        fused = torch.cat([vision_out, language_out], dim=-1)
        action = self.fusion_head(fused)
        return action
```

**ä¼˜ç‚¹**: å„æ¨¡æ€å¯ä»¥ç‹¬ç«‹ä¼˜åŒ–
**ç¼ºç‚¹**: æ— æ³•å­¦ä¹ å¤æ‚çš„è·¨æ¨¡æ€äº¤äº’

### 3.4 VLA ä¸­çš„ä¸»æµæ–¹æ¡ˆï¼šFiLM è°ƒåˆ¶

**FiLM (Feature-wise Linear Modulation)** æ˜¯ VLA ä¸­æœ€å¸¸ç”¨çš„æ¡ä»¶æ³¨å…¥æ–¹å¼ã€‚

```python
class FiLM(nn.Module):
    """Feature-wise Linear Modulation"""
    def __init__(self, cond_dim, feature_dim):
        self.gamma = nn.Linear(cond_dim, feature_dim)  # Scale
        self.beta = nn.Linear(cond_dim, feature_dim)   # Shift
        
    def forward(self, feature, condition):
        """
        feature: è¦è°ƒåˆ¶çš„ç‰¹å¾ [B, L, D]
        condition: æ¡ä»¶ä¿¡æ¯ [B, C]
        """
        gamma = self.gamma(condition).unsqueeze(1)  # [B, 1, D]
        beta = self.beta(condition).unsqueeze(1)
        
        # è°ƒåˆ¶: Î³ * feature + Î²
        return gamma * feature + beta
```

**åº”ç”¨åœºæ™¯**:
- **RT-1**: è¯­è¨€ç‰¹å¾é€šè¿‡ FiLM è°ƒåˆ¶è§†è§‰ç‰¹å¾
- **Diffusion Policy**: æ—¶é—´æ­¥ $t$ é€šè¿‡ FiLM æ³¨å…¥åˆ° U-Net

## 4. æ ¸å¿ƒè§†è§‰ç¼–ç å™¨ (Vision Encoders)

### 4.1 ViT (Vision Transformer)

```
å›¾åƒ [H, W, 3] 
    â”‚
    â–¼ Patch Embedding (16x16)
[N_patches, D] where N = (H/16) * (W/16)
    â”‚
    â–¼ + Position Embedding
    â”‚
    â–¼ Transformer Encoder (L layers)
    â”‚
    â–¼
[CLS] token æˆ– å…¨å±€å¹³å‡æ± åŒ–
```

**ç‰¹ç‚¹**:
- å°†å›¾åƒåˆ‡åˆ†ä¸º Patch (å¦‚ 16x16)
- æ¯ä¸ª Patch ä½œä¸ºä¸€ä¸ª Token
- é€šè¿‡ Self-Attention å»ºæ¨¡å…¨å±€å…³ç³»

### 4.2 SigLIP (Sigmoid Loss for Language-Image Pre-training)

**æ”¹è¿› CLIP**:
- ä½¿ç”¨ Sigmoid æ›¿ä»£ Softmax (æ›´å¥½çš„æ‰¹é‡å¯¹æ¯”å­¦ä¹ )
- æ”¯æŒæ›´å¤§çš„ batch size
- VLA é¦–é€‰çš„è§†è§‰ç¼–ç å™¨ (OpenVLA, RDT)

### 4.3 DINOv2 (Self-supervised Vision Transformer)

**ç‰¹ç‚¹**:
- è‡ªç›‘ç£é¢„è®­ç»ƒï¼Œæ— éœ€æ ‡ç­¾
- å¼ºå¤§çš„ä½å±‚è§†è§‰ç‰¹å¾ (è¾¹ç¼˜ã€çº¹ç†)
- é€‚åˆéœ€è¦ç²¾ç¡®ç©ºé—´ä¿¡æ¯çš„ä»»åŠ¡

### 4.4 å¯¹æ¯”ä¸é€‰æ‹©

| ç¼–ç å™¨ | é¢„è®­ç»ƒæ–¹å¼ | ç‰¹ç‚¹ | VLA åº”ç”¨ |
| :--- | :--- | :--- | :--- |
| **ResNet** | ç›‘ç£å­¦ä¹  | é«˜æ•ˆï¼Œé€‚åˆ CNN ç­–ç•¥ | RT-1, Diffusion Policy |
| **ViT** | ç›‘ç£/è‡ªç›‘ç£ | å…¨å±€å»ºæ¨¡å¼º | é€šç”¨ |
| **CLIP/SigLIP** | å¯¹æ¯”å­¦ä¹  | è¯­ä¹‰å¯¹é½å¥½ | OpenVLA, RDT |
| **DINOv2** | è‡ªç›‘ç£ | ç©ºé—´ç‰¹å¾å¼º | ç²¾ç»†æ“ä½œ |

## 5. è¯­è¨€ç¼–ç å™¨ (Language Encoders)

### 5.1 BERT-style (Encoder-only)

```python
from transformers import BertModel

text = "pick up the red cup"
inputs = tokenizer(text, return_tensors="pt")
outputs = bert_model(**inputs)

## ä½¿ç”¨ [CLS] token æˆ–å¹³å‡æ± åŒ–
text_embedding = outputs.last_hidden_state[:, 0, :]  # [B, D]
```

**é€‚ç”¨**: ç†è§£å‹ä»»åŠ¡ï¼ŒæŒ‡ä»¤åµŒå…¥

### 5.2 T5-style (Encoder-Decoder)

**é€‚ç”¨**: éœ€è¦ç”Ÿæˆæ–‡æœ¬çš„ä»»åŠ¡ (å¦‚ CoT æ¨ç†)

### 5.3 LLM-style (Decoder-only)

**ä»£è¡¨**: Llama, Gemma, Qwen
**é€‚ç”¨**: ç°ä»£ VLA çš„æ ‡å‡†é€‰æ‹©ï¼Œåˆ©ç”¨å¼ºå¤§çš„ In-context Learning

---

## 5.5 PaliGemma è¯¦è§£ (VLA å¸¸ç”¨ Backbone)

> **è®ºæ–‡**: [PaliGemma: A versatile 3B VLM for transfer](https://arxiv.org/abs/2407.07726) (Google, 2024)
> **å®˜æ–¹**: [HuggingFace](https://huggingface.co/google/paligemma-3b-pt-224)

PaliGemma æ˜¯ Google æ¨å‡ºçš„è½»é‡çº§ VLMï¼Œå·²æˆä¸º **Ï€0ã€OpenVLA** ç­‰ VLA çš„é¦–é€‰ backboneã€‚

### ä¸ºä»€ä¹ˆ VLA å¸¸ç”¨ PaliGemma?

| ä¼˜åŠ¿ | è¯´æ˜ |
| :--- | :--- |
| **è½»é‡é«˜æ•ˆ** | 3B å‚æ•°ï¼Œå¯åœ¨å•å¡ (24GB) å¾®è°ƒ |
| **é¢„è®­ç»ƒå……åˆ†** | åœ¨å¤§é‡å›¾æ–‡æ•°æ®ä¸Šè®­ç»ƒï¼Œè§†è§‰ç†è§£å¼º |
| **å¼€æºå‹å¥½** | Apache 2.0 è®¸å¯ï¼Œå¯å•†ç”¨ |
| **æ¨¡å—åŒ–è®¾è®¡** | Vision Encoder å’Œ LLM è§£è€¦ï¼Œæ˜“äºé€‚é… |
| **å¤šåˆ†è¾¨ç‡** | æ”¯æŒ 224/448/896 è¾“å…¥å°ºå¯¸ |

### PaliGemma æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      PaliGemma 3B                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚   Image Input                    Text Input                  â”‚
â”‚   [224Ã—224Ã—3]                    "Pick up the cup"           â”‚
â”‚        â”‚                              â”‚                      â”‚
â”‚        â–¼                              â–¼                      â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚   â”‚   SigLIP     â”‚              â”‚   Gemma      â”‚            â”‚
â”‚   â”‚  ViT-So400m  â”‚              â”‚  Tokenizer   â”‚            â”‚
â”‚   â”‚  (400M)      â”‚              â”‚              â”‚            â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚          â”‚                             â”‚                     â”‚
â”‚   [256 patches]                  [L tokens]                  â”‚
â”‚   [256, 1152]                    [L, 2048]                   â”‚
â”‚          â”‚                             â”‚                     â”‚
â”‚          â–¼                             â”‚                     â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚                     â”‚
â”‚   â”‚  Linear Proj â”‚ (1152 â†’ 2048)       â”‚                     â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚                     â”‚
â”‚          â”‚                             â”‚                     â”‚
â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚                     â–¼                                        â”‚
â”‚            [Vision] + [Text Tokens]                          â”‚
â”‚                     â”‚                                        â”‚
â”‚                     â–¼                                        â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚   â”‚                 Gemma 2B LLM                            â”‚â”‚
â”‚   â”‚          (18 Transformer Layers)                        â”‚â”‚
â”‚   â”‚                                                         â”‚â”‚
â”‚   â”‚    Self-Attention (Vision + Text ä¸€èµ·å¤„ç†)               â”‚â”‚
â”‚   â”‚                     â†“                                   â”‚â”‚
â”‚   â”‚              Hidden States                              â”‚â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                     â”‚                                        â”‚
â”‚                     â–¼                                        â”‚
â”‚              [B, L, 2048]                                    â”‚
â”‚           (é€ç»™ Action Head)                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æ ¸å¿ƒç»„ä»¶

#### 1. SigLIP Vision Encoder

```python
## SigLIP vs CLIP
## SigLIP ä½¿ç”¨ Sigmoid Loss è€Œé Softmaxï¼Œæ›´é€‚åˆç»†ç²’åº¦ç†è§£

## é…ç½®
vision_config = {
    "model": "ViT-So400m",      # 400M å‚æ•°
    "image_size": 224,          # æˆ– 448, 896
    "patch_size": 14,           # 16Ã—16 patches
    "hidden_size": 1152,
    "num_layers": 27,
    "num_heads": 16
}

## è¾“å‡º: [B, 256, 1152] (256 = (224/14)Â² patches)
```

#### 2. Gemma 2B LLM

```python
## Gemma æ˜¯ Google çš„è½»é‡çº§ LLM
llm_config = {
    "hidden_size": 2048,
    "num_layers": 18,
    "num_heads": 8,
    "vocab_size": 256000,
    "max_position": 8192,
    "intermediate_size": 16384  # FFN
}
```

#### 3. æŠ•å½±å±‚ (Linear Projection)

```python
## å°† SigLIP ç‰¹å¾æŠ•å°„åˆ° Gemma ç©ºé—´
self.vision_proj = nn.Linear(1152, 2048)

## æŠ•å°„åï¼Œè§†è§‰ Token å’Œæ–‡æœ¬ Token åœ¨åŒä¸€ç©ºé—´
vision_tokens = self.vision_proj(siglip_output)  # [B, 256, 2048]
```

### VLA ä¸­çš„ä½¿ç”¨æ–¹å¼

```python
from transformers import AutoProcessor, PaliGemmaForConditionalGeneration

## åŠ è½½æ¨¡å‹
model = PaliGemmaForConditionalGeneration.from_pretrained(
    "google/paligemma-3b-pt-224",
    torch_dtype=torch.bfloat16
)
processor = AutoProcessor.from_pretrained("google/paligemma-3b-pt-224")

## æ–¹å¼ 1: è·å– Hidden States (ç”¨äº Action Head)
def get_vlm_features(images, text):
    inputs = processor(images=images, text=text, return_tensors="pt")
    outputs = model(
        **inputs,
        output_hidden_states=True
    )
    # æœ€åä¸€å±‚ hidden states
    hidden = outputs.hidden_states[-1]  # [B, L, 2048]
    return hidden

## æ–¹å¼ 2: ç›´æ¥ç”Ÿæˆæ–‡æœ¬ (ç”¨äº CoT)
def generate_text(images, text):
    inputs = processor(images=images, text=text, return_tensors="pt")
    outputs = model.generate(**inputs, max_new_tokens=100)
    return processor.decode(outputs[0])
```

### PaliGemma ç‰ˆæœ¬å¯¹æ¯”

| ç‰ˆæœ¬ | å‚æ•°é‡ | è¾“å…¥åˆ†è¾¨ç‡ | é€‚ç”¨åœºæ™¯ |
| :--- | :--- | :--- | :--- |
| **paligemma-3b-pt-224** | 3B | 224Ã—224 | VLA é¦–é€‰ï¼Œå¹³è¡¡æ•ˆç‡ |
| paligemma-3b-pt-448 | 3B | 448Ã—448 | éœ€è¦æ›´å¤šç»†èŠ‚ |
| paligemma-3b-pt-896 | 3B | 896Ã—896 | é«˜åˆ†è¾¨ç‡ä»»åŠ¡ |
| paligemma-3b-mix-224 | 3B | 224Ã—224 | æ··åˆä»»åŠ¡å¾®è°ƒç‰ˆ |

### PaliGemma vs å…¶ä»– VLM

| æ¨¡å‹ | å‚æ•°é‡ | å¼€æº | VLA é€‚ç”¨æ€§ |
| :--- | :--- | :--- | :--- |
| **PaliGemma** | **3B** | âœ… Apache 2.0 | â­â­â­â­â­ æœ€å¸¸ç”¨ |
| LLaVA 1.5 | 7B/13B | âœ… | â­â­â­â­ è¾ƒå¤§ä½†æˆç†Ÿ |
| Qwen-VL | 7B | âœ… | â­â­â­â­ ä¸­æ–‡æ”¯æŒå¥½ |
| GPT-4V | ~1T | âŒ | â­â­ API å»¶è¿Ÿé«˜ |
| PaLI-X | 55B | âŒ | â­ å¤ªå¤§æ— æ³•éƒ¨ç½² |

### é¢è¯•å¸¸è§é—®é¢˜

**Q: ä¸ºä»€ä¹ˆ Ï€0 é€‰æ‹© PaliGemma è€Œä¸æ˜¯æ›´å¤§çš„ LLaVA?**

A: ä¸‰ä¸ªåŸå› :
1. **æ•ˆç‡**: 3B å‚æ•°å¯åœ¨å•å¡è®­ç»ƒ/æ¨ç†ï¼Œæ»¡è¶³æœºå™¨äººå®æ—¶æ€§è¦æ±‚
2. **SigLIP**: æ¯” CLIP æ›´å¥½çš„ç»†ç²’åº¦è§†è§‰ç†è§£
3. **æ¨¡å—åŒ–**: Vision/Language è§£è€¦ï¼Œæ–¹ä¾¿æ¥ Action Head

---

**Q: PaliGemma çš„ 256 ä¸ª vision tokens å¤Ÿç”¨å—?**

A: å¯¹äºå¤§å¤šæ•°æœºå™¨äººä»»åŠ¡è¶³å¤Ÿ:
- æ¡Œé¢æ“ä½œ: 224Ã—224 åˆ†è¾¨ç‡ + 256 tokens èƒ½è¦†ç›–å…³é”®ç‰©ä½“
- éœ€è¦ç²¾ç»†æ“ä½œæ—¶: å¯ç”¨ 448/896 ç‰ˆæœ¬ (1024/4096 tokens)
- Trade-off: æ›´å¤š tokens = æ›´æ…¢æ¨ç†

---

## 5.6 ä¸»æµ VLM å¯¹æ¯”è¡¨ï¼ˆVLA è®­ç»ƒå‚è€ƒï¼‰

> **ç›®æ ‡**: ä¸º VLA å¼€å‘è€…æä¾›å½“å‰å¸‚åœºä¸Šä¸»æµ Vision Language Model çš„å¯¹æ¯”ï¼Œé‡ç‚¹å…³æ³¨**å·²åœ¨ VLA é¡¹ç›®ä¸­å®é™…ä½¿ç”¨**çš„æ¨¡å‹ã€‚
> 
> **æœ€åæ›´æ–°**: 2025å¹´12æœˆ5æ—¥

---

### 5.6.1 âœ… å·²åœ¨ VLA ä¸­å®é™…ä½¿ç”¨ï¼ˆä¼˜å…ˆæ¨èï¼‰

| æ¨¡å‹ | æœºæ„ | å‘å¸ƒæ—¶é—´ | Vision Encoder | LLM Backbone | å‚æ•°é‡ | è¾“å…¥åˆ†è¾¨ç‡ | å¼€æº | è®¸å¯è¯ | VLA åº”ç”¨æ¡ˆä¾‹ | HuggingFace |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| **PaliGemma 3B** | Google | 2024.07 | SigLIP ViT-So400m | Gemma 2B | 3B | 224/448/896 | âœ… | Apache 2.0 | **Ï€0 (Pi-Zero)**, OpenVLA å˜ä½“ | [google/paligemma-3b-pt-224](https://huggingface.co/google/paligemma-3b-pt-224) |
| **SigLIP** | Google | 2023.09 | ViT (Sigmoid Loss) | - | 400M-2.6B | 224-384 | âœ… | Apache 2.0 | **OpenVLA**, **RDT** (Vision Encoder) | [google/siglip-*](https://huggingface.co/models?search=siglip) |
| **LLaVA 1.5/1.6** | - | 2023.10/2024.01 | CLIP/ViT | Llama 2/Vicuna | 7B/13B | 336/672 | âœ… | Apache 2.0 | **OpenVLA** (Llama 2 + SigLIP ç»„åˆ) | [llava-hf/llava-1.5-*](https://huggingface.co/models?search=llava) |
| **LLaVA-NeXT** | - | 2024.12 | CLIP/ViT | Llama 3/Vicuna | 7B/13B/34B | 672/1344 | âœ… | Apache 2.0 | æœ€æ–°ç‰ˆæœ¬ï¼Œæ€§èƒ½æå‡ | [llava-hf/llava-next-*](https://huggingface.co/models?search=llava-next) |
| **PaLI-X** | Google | 2023.12 | ViT-22B | PaLM-E | 55B | 224-1024 | âŒ | - | **RT-2** | - |

**é€‰æ‹©å»ºè®®**:
- **PaliGemma 3B**: VLA è®­ç»ƒé¦–é€‰ï¼Œè½»é‡é«˜æ•ˆï¼ˆå•å¡ 24GB å¯è®­ç»ƒï¼‰ï¼Œé¢„è®­ç»ƒå……åˆ†ï¼Œæ¨¡å—åŒ–è®¾è®¡
- **SigLIP**: VLA é¦–é€‰è§†è§‰ç¼–ç å™¨ï¼Œæ¯” CLIP æ›´å¼ºçš„ç»†ç²’åº¦ç†è§£ï¼Œæ”¯æŒå¤§ batch è®­ç»ƒ
- **LLaVA**: æˆç†Ÿç¨³å®šï¼Œç¤¾åŒºæ”¯æŒå¥½ï¼Œé€‚åˆéœ€è¦æ›´å¤§æ¨¡å‹çš„åœºæ™¯

### 5.6.2 ğŸ”„ é€‚åˆ VLA è®­ç»ƒçš„å¼€æº VLMï¼ˆæ¨èå°è¯•ï¼‰

#### ğŸ†• 2025å¹´æœ€æ–°å‘å¸ƒ

| æ¨¡å‹ | æœºæ„ | å‘å¸ƒæ—¶é—´ | Vision Encoder | LLM Backbone | å‚æ•°é‡ | è¾“å…¥åˆ†è¾¨ç‡ | å¼€æº | è®¸å¯è¯ | ä¼˜åŠ¿ | HuggingFace |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| **Qwen2.5-VL** | é˜¿é‡Œå·´å·´ | 2025.03 | Window Attn ViT + MRoPE | Qwen2.5 LLM | 3B/7B/32B/72B | ä»»æ„åˆ†è¾¨ç‡ | âœ… | Apache 2.0 | **2025 SOTA**ï¼Œæ•°å­¦æ¨ç†å¼ºï¼Œé•¿è§†é¢‘æ”¯æŒ | [Qwen/Qwen2.5-VL-*](https://huggingface.co/models?search=Qwen2.5-VL) |
| **Eagle 2.5** | NVIDIA | 2025.04 | é•¿ä¸Šä¸‹æ–‡ ViT | - | 8B | é•¿è§†é¢‘ | âœ… | Apache 2.0 | é•¿ä¸Šä¸‹æ–‡å¤šæ¨¡æ€ï¼ŒVideo-MME 72.4% | [nvidia/Eagle-*](https://huggingface.co/models?search=Eagle) |
| **Seed 1.5-VL** | å­—èŠ‚è·³åŠ¨ | 2025.05 | - | - | 20B (æ¿€æ´») | - | âœ… | - | åª²ç¾ Gemini 2.5 Proï¼ŒGUI äº¤äº’å¼º | [ByteDance/Seed-*](https://huggingface.co/models?search=Seed) |
| **PLM** | Meta | 2025.05 | - | - | - | - | âœ… | MIT | å¼€æºè§†è§‰è¯­è¨€æ¨¡å‹ï¼Œå¤æ‚è§†è§‰ä»»åŠ¡ | [meta-llama/PLM](https://github.com/facebookresearch/PLM) |
| **GLM-4.5V** | æ™ºè°±AI | 2025 | 3D-RoPE ViT | GLM-4.5-Air | 106B (12B æ¿€æ´») | - | âœ… | Apache 2.0 | MoE æ¶æ„ï¼Œ3D ç©ºé—´æ¨ç† | [THUDM/GLM-4.5V](https://huggingface.co/models?search=GLM-4) |
| **Llama 4 Scout/Maverick** | Meta | 2025.04 | ViT Patch | MoE Transformer | 16-128 ä¸“å®¶ | - | âœ… | Meta Llama | 10M token ä¸Šä¸‹æ–‡ï¼Œå¤šæ¨¡æ€ | [meta-llama/Llama-4](https://huggingface.co/models?search=llama-4) |

#### 2024å¹´å‘å¸ƒï¼ˆä»æ¨èï¼‰

| æ¨¡å‹ | æœºæ„ | å‘å¸ƒæ—¶é—´ | Vision Encoder | LLM Backbone | å‚æ•°é‡ | è¾“å…¥åˆ†è¾¨ç‡ | å¼€æº | è®¸å¯è¯ | ä¼˜åŠ¿ | HuggingFace |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| **Qwen2-VL** | é˜¿é‡Œå·´å·´ | 2024.08 | InternViT | Qwen2 LLM | 2B/7B/72B | 448-1344 | âœ… | Apache 2.0 | æ€§èƒ½å¤§å¹…æå‡ | [Qwen/Qwen2-VL-*](https://huggingface.co/models?search=Qwen2-VL) |
| **InternVL2** | å•†æ±¤ | 2024.07 | InternViT-6B | InternLM2 | 2B/4B/8B/26B | 448-1344 | âœ… | Apache 2.0 | å¤šæ¨¡æ€èƒ½åŠ›å¢å¼º | [OpenGVLab/InternVL2-*](https://huggingface.co/models?search=InternVL2) |
| **MiniCPM-V 2.6** | é¢å£æ™ºèƒ½ | 2024.08 | ViT | MiniCPM | 8B | 336-1344 | âœ… | Apache 2.0 | è¶…è½»é‡çº§ï¼Œè¾¹ç¼˜éƒ¨ç½² | [openbmb/MiniCPM-V-*](https://huggingface.co/models?search=MiniCPM-V) |
| **LLaVA-NeXT** | - | 2024.06 | CLIP/ViT | Llama 3/Vicuna | 7B/13B/34B | 672/1344 | âœ… | Apache 2.0 | æœ€æ–° LLaVA ç‰ˆæœ¬ | [llava-hf/llava-next-*](https://huggingface.co/models?search=llava-next) |
| **SmolVLA** | Hugging Face | 2024.12 | ViT-Small | TinyLlama | 450M | 224 | âœ… | Apache 2.0 | è¶…è½»é‡çº§ï¼ŒVLA ç ”ç©¶å…¥é—¨ | [huggingface/smolvla](https://huggingface.co/models?search=smolvla) |

#### ç»å…¸æ¨¡å‹ï¼ˆä»å¯ç”¨ï¼‰

| æ¨¡å‹ | æœºæ„ | å‘å¸ƒæ—¶é—´ | Vision Encoder | LLM Backbone | å‚æ•°é‡ | è¾“å…¥åˆ†è¾¨ç‡ | å¼€æº | è®¸å¯è¯ | ä¼˜åŠ¿ | HuggingFace |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| **Qwen-VL** | é˜¿é‡Œå·´å·´ | 2023.11 | CLIP-ViT | Qwen LLM | 7B/72B | 448-1024 | âœ… | Apache 2.0 | ä¸­æ–‡æ”¯æŒå¥½ | [Qwen/Qwen-VL](https://huggingface.co/Qwen/Qwen-VL) |
| **CogVLM** | æ™ºè°±AI | 2023.10 | EVA2-ViT | GLM | 17B | 490 | âœ… | Apache 2.0 | è§†è§‰ç†è§£å¼ºï¼Œä¸­æ–‡æ”¯æŒ | [THUDM/cogvlm-*](https://huggingface.co/models?search=cogvlm) |
| **InternVL** | å•†æ±¤ | 2024.01 | InternViT | InternLM | 2B-26B | 448-1024 | âœ… | Apache 2.0 | å¤šåˆ†è¾¨ç‡æ”¯æŒ | [OpenGVLab/InternVL-*](https://huggingface.co/models?search=InternVL) |

**é€‚ç”¨åœºæ™¯**:
- **Qwen2.5-VL** (ğŸ†• 2025): ä¸­æ–‡æŒ‡ä»¤ VLA é¦–é€‰ï¼Œæ•°å­¦æ¨ç†å¼ºï¼Œæ”¯æŒä»»æ„åˆ†è¾¨ç‡å’Œé•¿è§†é¢‘
- **Eagle 2.5** (ğŸ†• 2025): é•¿ä¸Šä¸‹æ–‡å¤šæ¨¡æ€ä»»åŠ¡ï¼Œè§†é¢‘ç†è§£
- **Seed 1.5-VL** (ğŸ†• 2025): GUI äº¤äº’ã€å¤æ‚è§†è§‰æ¨ç†
- **GLM-4.5V** (ğŸ†• 2025): 3D ç©ºé—´æ¨ç†ä»»åŠ¡
- **Llama 4** (ğŸ†• 2025): è¶…é•¿ä¸Šä¸‹æ–‡ï¼ˆ10M tokenï¼‰ï¼Œæ–‡æ¡£åˆ†æ
- **Qwen2-VL**: ä¸­æ–‡æ”¯æŒå¥½ï¼ˆ2024 ç‰ˆæœ¬ï¼‰
- **MiniCPM-V**: è¾¹ç¼˜è®¾å¤‡éƒ¨ç½²ï¼Œèµ„æºå—é™åœºæ™¯
- **SmolVLA**: è¶…è½»é‡çº§ç ”ç©¶ï¼Œå¿«é€ŸåŸå‹éªŒè¯

### 5.6.3 âŒ é—­æº APIï¼ˆå‚è€ƒï¼Œä¸é€‚åˆç›´æ¥è®­ç»ƒï¼‰

| æ¨¡å‹ | æœºæ„ | å‘å¸ƒæ—¶é—´ | å‚æ•°é‡ | ç‰¹ç‚¹ | VLA é€‚ç”¨æ€§ |
| :--- | :--- | :--- | :--- | :--- | :--- |
| **Gemini 2.5 Pro** ğŸ†• | Google | 2025.03 | æœªå…¬å¼€ | **2025 SOTA**ï¼Œ1M token ä¸Šä¸‹æ–‡ï¼Œå†…ç½®æ€è€ƒåŠŸèƒ½ | â­â­ API è°ƒç”¨ï¼Œæˆæœ¬é«˜ |
| **Claude 3.7 Vision** ğŸ†• | Anthropic | 2025.02 | æœªå…¬å¼€ | é«˜ç²¾åº¦ OCRï¼Œå›¾è¡¨è§£æ | â­â­ API è°ƒç”¨ï¼Œå»¶è¿Ÿé—®é¢˜ |
| **GPT-4o** | OpenAI | 2024.05 | ~1T | å¤šæ¨¡æ€ç†è§£å¼ºï¼Œç»Ÿä¸€ Transformer æ¶æ„ | â­â­ API å»¶è¿Ÿé«˜ï¼Œä¸é€‚åˆå®æ—¶æ§åˆ¶ |
| **GPT-4o-mini** | OpenAI | 2024.07 | æœªå…¬å¼€ | è½»é‡ç‰ˆ GPT-4oï¼Œæˆæœ¬æ›´ä½ | â­â­ API è°ƒç”¨ï¼Œå»¶è¿Ÿä»è¾ƒé«˜ |
| **Gemini 1.5 Pro** | Google | 2024.02 | æœªå…¬å¼€ | 1M token ä¸Šä¸‹æ–‡ | â­â­ API è°ƒç”¨ï¼Œæˆæœ¬é«˜ |
| **Claude 3.5 Sonnet** | Anthropic | 2024.06 | æœªå…¬å¼€ | è§†è§‰ç†è§£å¼ºï¼Œæ€§èƒ½æå‡ | â­â­ API è°ƒç”¨ï¼Œå»¶è¿Ÿé—®é¢˜ |

**è¯´æ˜**: é—­æº API æ¨¡å‹è™½ç„¶èƒ½åŠ›å¼ºï¼Œä½†å­˜åœ¨å»¶è¿Ÿé«˜ã€æˆæœ¬é«˜ã€æ— æ³•æœ¬åœ°éƒ¨ç½²ç­‰é—®é¢˜ï¼Œä¸é€‚åˆç›´æ¥ç”¨äº VLA è®­ç»ƒã€‚å¯ä½œä¸ºå‚è€ƒæˆ–ç”¨äºæ•°æ®æ ‡æ³¨ã€CoT æ¨ç†ç­‰è¾…åŠ©ä»»åŠ¡ã€‚

**2025 å¹´é—­æºæ¨¡å‹è¶‹åŠ¿**:
- **Gemini 2.5 Pro**: ç›®å‰æ’è¡Œæ¦œç¬¬ä¸€ï¼Œå†…ç½®æ¨ç†æ€è€ƒåŠŸèƒ½
- **Claude 3.7**: OCR å’Œå›¾è¡¨è§£æèƒ½åŠ›å¤§å¹…æå‡

### 5.6.4 ç»å…¸æ¨¡å‹ï¼ˆå†å²å‚è€ƒï¼‰

| æ¨¡å‹ | æœºæ„ | å‘å¸ƒæ—¶é—´ | ç‰¹ç‚¹ | VLA å½±å“ |
| :--- | :--- | :--- | :--- | :--- |
| **BLIP-2** | Salesforce | 2023.01 | Q-Former æ¶æ„åˆ›æ–° | â­ æ—©æœŸ VLMï¼Œè¾ƒå°‘ç›´æ¥ç”¨äº VLA |
| **Flamingo** | DeepMind | 2022.04 | Perceiver Resampler, Gated Cross-Attention | â­â­ æ¶æ„åˆ›æ–°å½±å“æ·±è¿œï¼Œä½†æœªç›´æ¥ç”¨äº VLA |

### 5.6.5 VLA è®­ç»ƒé€‰æ‹©æŒ‡å—

#### å¿«é€Ÿé€‰æ‹©

```
éœ€è¦è½»é‡çº§ã€å•å¡è®­ç»ƒï¼Ÿ
  â”œâ”€ æ˜¯ â†’ PaliGemma 3B (é¦–é€‰)
  â””â”€ å¦ â†’ LLaVA 7B/13B

åªéœ€è¦ Vision Encoderï¼Ÿ
  â””â”€ SigLIP (VLA é¦–é€‰)

éœ€è¦ä¸­æ–‡æ”¯æŒï¼Ÿ
  â””â”€ Qwen-VL 7B

éœ€è¦è¾¹ç¼˜éƒ¨ç½²ï¼Ÿ
  â””â”€ MiniCPM-V 2.4B

éœ€è¦é«˜åˆ†è¾¨ç‡è¾“å…¥ï¼Ÿ
  â””â”€ InternVL æˆ– PaliGemma 896px ç‰ˆæœ¬
```

#### æŠ€æœ¯å¯¹æ¯”

| ç‰¹æ€§ | PaliGemma 3B | LLaVA 7B | Qwen-VL 7B | SigLIP (Vision) |
| :--- | :--- | :--- | :--- | :--- |
| **è®­ç»ƒæ•ˆç‡** | â­â­â­â­â­ å•å¡å¯è®­ç»ƒ | â­â­â­ éœ€è¦å¤šå¡ | â­â­â­ éœ€è¦å¤šå¡ | â­â­â­â­â­ ä»… Vision |
| **æ¨ç†é€Ÿåº¦** | â­â­â­â­ å¿« | â­â­â­ ä¸­ç­‰ | â­â­â­ ä¸­ç­‰ | â­â­â­â­â­ æå¿« |
| **è§†è§‰ç†è§£** | â­â­â­â­ å¼º | â­â­â­â­ å¼º | â­â­â­â­ å¼º | â­â­â­â­â­ æœ€å¼º |
| **ä¸­æ–‡æ”¯æŒ** | â­â­ ä¸€èˆ¬ | â­â­ ä¸€èˆ¬ | â­â­â­â­â­ ä¼˜ç§€ | - |
| **VLA ç”Ÿæ€** | â­â­â­â­â­ æœ€å¸¸ç”¨ | â­â­â­â­ æˆç†Ÿ | â­â­â­ è¾ƒå°‘ | â­â­â­â­â­ æœ€å¸¸ç”¨ |

#### å®é™…åº”ç”¨æ¡ˆä¾‹

1. **Ï€0 (Pi-Zero)**: ä½¿ç”¨ PaliGemma 3B ä½œä¸º VLM backboneï¼Œç»“åˆ Flow Matching å®ç°é«˜é¢‘æ§åˆ¶
2. **OpenVLA**: ä½¿ç”¨ Llama 2 7B + SigLIP ç»„åˆï¼Œé€šè¿‡ LoRA é«˜æ•ˆå¾®è°ƒ
3. **RT-2**: ä½¿ç”¨ PaLI-X 55Bï¼ˆé—­æºï¼‰ï¼Œè¯æ˜äº† VLM è¯­ä¹‰èƒ½åŠ›å¯è¿ç§»åˆ°æœºå™¨äººæ§åˆ¶
4. **RDT**: ä½¿ç”¨ SigLIP ä½œä¸º Vision Encoderï¼Œä¸“æ³¨äºè§†è§‰ç‰¹å¾æå–

### 5.6.6 é›†æˆå»ºè®®

#### ä½¿ç”¨ PaliGemma 3B è®­ç»ƒ VLA

```python
from transformers import AutoProcessor, PaliGemmaForConditionalGeneration
import torch

## 1. åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
model = PaliGemmaForConditionalGeneration.from_pretrained(
    "google/paligemma-3b-pt-224",
    torch_dtype=torch.bfloat16
)
processor = AutoProcessor.from_pretrained("google/paligemma-3b-pt-224")

## 2. è·å–å¤šæ¨¡æ€ç‰¹å¾ï¼ˆç”¨äº Action Headï¼‰
def get_vlm_features(images, text_instructions):
    inputs = processor(images=images, text=text_instructions, return_tensors="pt")
    outputs = model(**inputs, output_hidden_states=True)
    hidden = outputs.hidden_states[-1]  # [B, L, 2048]
    return hidden

## 3. æ¥ Action Head
action_head = nn.Linear(2048, action_dim * chunk_size)
actions = action_head(hidden[:, -1, :])  # ä½¿ç”¨æœ€åä¸€ä¸ª token
```

#### ä½¿ç”¨ SigLIP ä½œä¸º Vision Encoder

```python
from transformers import AutoProcessor, AutoModel
import torch

## åŠ è½½ SigLIP Vision Encoder
vision_encoder = AutoModel.from_pretrained("google/siglip-base-patch16-224")
processor = AutoProcessor.from_pretrained("google/siglip-base-patch16-224")

## æå–è§†è§‰ç‰¹å¾
def extract_vision_features(images):
    inputs = processor(images=images, return_tensors="pt")
    outputs = vision_encoder(**inputs)
    return outputs.last_hidden_state  # [B, N_patches, D]
```

### 5.6.7 Pre-training vs Fine-tuning vs Post-training

> **é‡è¦æ¦‚å¿µ**: åœ¨ VLA è®­ç»ƒä¸­ï¼Œè¿™ä¸‰ä¸ªæœ¯è¯­æœ‰æ˜ç¡®çš„åŒºåˆ«å’Œé¡ºåºã€‚

#### è®­ç»ƒé˜¶æ®µå¯¹æ¯”

| é˜¶æ®µ | è‹±æ–‡ | ä¸­æ–‡ | æ•°æ®æ¥æº | è®­ç»ƒç›®æ ‡ | å…¸å‹æ–¹æ³• | VLA åº”ç”¨ |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| **Pre-training** | Pre-training | é¢„è®­ç»ƒ | å¤§è§„æ¨¡é€šç”¨æ•°æ® (ImageNet, CLIP, äº’è”ç½‘å›¾æ–‡) | å­¦ä¹ é€šç”¨è§†è§‰/è¯­è¨€ç‰¹å¾ | è‡ªç›‘ç£å­¦ä¹ ã€å¯¹æ¯”å­¦ä¹  | VLM backbone (PaliGemma, SigLIP) |
| **Fine-tuning** | Fine-tuning | å¾®è°ƒ | ç›®æ ‡ä»»åŠ¡æ•°æ® (æœºå™¨äººç¤ºæ•™æ•°æ®) | é€‚é…ç‰¹å®šä»»åŠ¡ | ç›‘ç£å­¦ä¹  (BC), LoRA | OpenVLA, Ï€0 åœ¨æœºå™¨äººæ•°æ®ä¸Šå¾®è°ƒ |
| **Post-training** | Post-training | åè®­ç»ƒ | äº¤äº’æ”¶é›†çš„æ•°æ® (æˆåŠŸ+å¤±è´¥è½¨è¿¹) | è‡ªæˆ‘æ”¹è¿›ï¼Œè¶…è¶Šç¤ºæ•™ | Offline RL (Recap) | Ï€*0.6 çš„ Recap ç®—æ³• |

#### è¯¦ç»†è¯´æ˜

**1. Pre-training (é¢„è®­ç»ƒ)**

```
å¤§è§„æ¨¡æ•°æ® (ImageNet/CLIP/äº’è”ç½‘å›¾æ–‡)
        â”‚
        â–¼
  å­¦ä¹ é€šç”¨ç‰¹å¾
        â”‚
        â–¼
  é¢„è®­ç»ƒæ¨¡å‹ (å¦‚ PaliGemma 3B)
```

- **ç›®æ ‡**: åœ¨å¤§è§„æ¨¡æ•°æ®ä¸Šå­¦ä¹ é€šç”¨çš„è§†è§‰å’Œè¯­è¨€ç†è§£èƒ½åŠ›
- **æ•°æ®**: é€šå¸¸ä¸éœ€è¦æ ‡æ³¨ï¼Œä½¿ç”¨è‡ªç›‘ç£æˆ–å¯¹æ¯”å­¦ä¹ 
- **ç»“æœ**: å¾—åˆ°ä¸€ä¸ªå…·å¤‡åŸºç¡€èƒ½åŠ›çš„æ¨¡å‹
- **VLA åº”ç”¨**: 
  - PaliGemma 3B åœ¨äº’è”ç½‘å›¾æ–‡æ•°æ®ä¸Šé¢„è®­ç»ƒ
  - SigLIP åœ¨å›¾åƒ-æ–‡æœ¬å¯¹ä¸Šè¿›è¡Œå¯¹æ¯”å­¦ä¹ é¢„è®­ç»ƒ

**2. Fine-tuning (å¾®è°ƒ)**

```
é¢„è®­ç»ƒæ¨¡å‹ (PaliGemma 3B)
        â”‚
        â–¼
  ç›®æ ‡ä»»åŠ¡æ•°æ® (æœºå™¨äººç¤ºæ•™)
        â”‚
        â–¼
  å¾®è°ƒåæ¨¡å‹ (é€‚é…æœºå™¨äººæ§åˆ¶)
```

- **ç›®æ ‡**: åœ¨é¢„è®­ç»ƒæ¨¡å‹åŸºç¡€ä¸Šï¼Œç”¨ç›®æ ‡ä»»åŠ¡æ•°æ®å¾®è°ƒï¼Œä½¿å…¶é€‚é…ç‰¹å®šä»»åŠ¡
- **æ•°æ®**: éœ€è¦æ ‡æ³¨çš„ç¤ºæ•™æ•°æ® (observation-action pairs)
- **æ–¹æ³•**: 
  - **Full Fine-tuning**: æ›´æ–°æ‰€æœ‰å‚æ•°ï¼ˆæ˜¾å­˜éœ€æ±‚å¤§ï¼‰
  - **LoRA/QLoRA**: åªè®­ç»ƒå°‘é‡å‚æ•°ï¼ˆæ¨èï¼‰
- **VLA åº”ç”¨**:
  - OpenVLA: åœ¨æœºå™¨äººæ•°æ®ä¸Š LoRA å¾®è°ƒ
  - Ï€0: åœ¨æœºå™¨äººæ•°æ®ä¸Šå¾®è°ƒ PaliGemma

**3. Post-training (åè®­ç»ƒ)**

```
å¾®è°ƒåæ¨¡å‹ (Ï€0.6)
        â”‚
        â–¼
  æœºå™¨äººäº¤äº’æ”¶é›†æ•°æ® (æˆåŠŸ+å¤±è´¥)
        â”‚
        â–¼
  Offline RL (Recap ç®—æ³•)
        â”‚
        â–¼
  æ”¹è¿›åæ¨¡å‹ (Ï€*0.6, è¶…è¶Šç¤ºæ•™)
```

- **ç›®æ ‡**: é€šè¿‡åˆ†ææˆåŠŸå’Œå¤±è´¥è½¨è¿¹ï¼Œè‡ªæˆ‘æ”¹è¿›ï¼Œè¶…è¶Šäººç±»ç¤ºæ•™æ°´å¹³
- **æ•°æ®**: æœºå™¨äººå®é™…è¿è¡Œæ”¶é›†çš„æ•°æ®ï¼ˆåŒ…å«æˆåŠŸå’Œå¤±è´¥æ¡ˆä¾‹ï¼‰
- **æ–¹æ³•**: Offline RL (å¦‚ Recap ç®—æ³•)
- **ç‰¹ç‚¹**: 
  - ä¸ä»…å­¦ä¹ "æ€ä¹ˆåš"ï¼Œè¿˜å­¦ä¹ "æ€ä¹ˆåšå¾—æ›´å¥½"
  - å¯ä»¥è¶…è¶Šäººç±»ç¤ºæ•™è€…çš„æ°´å¹³
- **VLA åº”ç”¨**: Ï€*0.6 çš„ Recap ç®—æ³•

#### å®Œæ•´è®­ç»ƒæµç¨‹ç¤ºä¾‹ (Ï€0.6 â†’ Ï€*0.6)

```python
## Phase 1: Pre-training (é€šå¸¸ç”±æ¨¡å‹æä¾›æ–¹å®Œæˆ)
## ä½¿ç”¨å¤§è§„æ¨¡æ•°æ®è®­ç»ƒ PaliGemma 3B
pretrained_vlm = load_pretrained("google/paligemma-3b-pt-224")

## Phase 2: Fine-tuning (åœ¨æœºå™¨äººæ•°æ®ä¸Šå¾®è°ƒ)
## ä½¿ç”¨ç¤ºæ•™æ•°æ®å¾®è°ƒ
robot_demos = load_robot_demonstrations()  # äººç±»ç¤ºæ•™æ•°æ®
finetuned_model = fine_tune(pretrained_vlm, robot_demos, method="LoRA")
## å¾—åˆ° Ï€0.6

## Phase 3: Post-training (Recap, è‡ªæˆ‘æ”¹è¿›)
## æœºå™¨äººäº¤äº’æ”¶é›†æ•°æ®
interaction_data = robot.collect_data()  # åŒ…å«æˆåŠŸå’Œå¤±è´¥è½¨è¿¹

## ä½¿ç”¨ Offline RL æ”¹è¿›
improved_model = recap_algorithm(finetuned_model, interaction_data)
## å¾—åˆ° Ï€*0.6
```

#### å…³é”®åŒºåˆ«æ€»ç»“

| ç‰¹æ€§ | Pre-training | Fine-tuning | Post-training |
| :--- | :--- | :--- | :--- |
| **æ•°æ®æ¥æº** | é€šç”¨å¤§è§„æ¨¡æ•°æ® | ç›®æ ‡ä»»åŠ¡ç¤ºæ•™æ•°æ® | äº¤äº’æ”¶é›†çš„æˆåŠŸ+å¤±è´¥æ•°æ® |
| **è®­ç»ƒç›®æ ‡** | å­¦ä¹ é€šç”¨ç‰¹å¾ | é€‚é…ç‰¹å®šä»»åŠ¡ | è‡ªæˆ‘æ”¹è¿›ï¼Œè¶…è¶Šç¤ºæ•™ |
| **å­¦ä¹ æ–¹å¼** | è‡ªç›‘ç£/å¯¹æ¯”å­¦ä¹  | ç›‘ç£å­¦ä¹  (BC) | Offline RL |
| **æ˜¯å¦å¿…éœ€** | âœ… æ˜¯ (æ¨¡å‹åŸºç¡€) | âœ… æ˜¯ (ä»»åŠ¡é€‚é…) | âš ï¸ å¯é€‰ (æ€§èƒ½æå‡) |
| **å…¸å‹æ—¶é—´** | æ•°å‘¨/æœˆ (å¤§è§„æ¨¡) | æ•°å°æ—¶/å¤© | æ•°å¤©/å‘¨ (æŒç»­æ”¹è¿›) |

#### é¢è¯•å¸¸è§é—®é¢˜

**Q: Pre-training å’Œ Fine-tuning çš„åŒºåˆ«æ˜¯ä»€ä¹ˆï¼Ÿ**

A:
- **Pre-training**: åœ¨å¤§è§„æ¨¡é€šç”¨æ•°æ®ä¸Šå­¦ä¹ åŸºç¡€èƒ½åŠ›ï¼ˆå¦‚è§†è§‰ç†è§£ã€è¯­è¨€ç†è§£ï¼‰
- **Fine-tuning**: åœ¨é¢„è®­ç»ƒæ¨¡å‹åŸºç¡€ä¸Šï¼Œç”¨ç›®æ ‡ä»»åŠ¡æ•°æ®å¾®è°ƒï¼Œä½¿å…¶é€‚é…ç‰¹å®šä»»åŠ¡ï¼ˆå¦‚æœºå™¨äººæ§åˆ¶ï¼‰

**Q: Post-training å’Œ Fine-tuning çš„åŒºåˆ«æ˜¯ä»€ä¹ˆï¼Ÿ**

A:
- **Fine-tuning**: ä½¿ç”¨äººç±»ç¤ºæ•™æ•°æ®ï¼Œå­¦ä¹ "æ€ä¹ˆåš"ï¼ˆæ¨¡ä»¿å­¦ä¹ ï¼‰
- **Post-training**: ä½¿ç”¨äº¤äº’æ”¶é›†çš„æˆåŠŸ+å¤±è´¥æ•°æ®ï¼Œå­¦ä¹ "æ€ä¹ˆåšå¾—æ›´å¥½"ï¼ˆå¼ºåŒ–å­¦ä¹ ï¼‰ï¼Œå¯ä»¥è¶…è¶Šäººç±»ç¤ºæ•™æ°´å¹³

**Q: ä¸ºä»€ä¹ˆéœ€è¦ Pre-trainingï¼Ÿ**

A: 
- æœºå™¨äººæ•°æ®ç¨€ç¼ºä¸”æ˜‚è´µï¼Œä»å¤´è®­ç»ƒéœ€è¦å¤§é‡æ•°æ®
- Pre-training è®©æ¨¡å‹å…·å¤‡é€šç”¨èƒ½åŠ›ï¼Œåªéœ€å°‘é‡æœºå™¨äººæ•°æ®å³å¯é€‚é…
- ç±»ä¼¼äººç±»å…ˆå­¦åŸºç¡€çŸ¥è¯†ï¼Œå†å­¦ä¸“ä¸šæŠ€èƒ½

### 5.6.8 å¸¸è§é—®é¢˜

**Q: ä¸ºä»€ä¹ˆ VLA é¦–é€‰ PaliGemma 3B è€Œä¸æ˜¯æ›´å¤§çš„ LLaVA?**

A: ä¸‰ä¸ªåŸå› :
1. **æ•ˆç‡**: 3B å‚æ•°å¯åœ¨å•å¡ (24GB) è®­ç»ƒ/æ¨ç†ï¼Œæ»¡è¶³æœºå™¨äººå®æ—¶æ€§è¦æ±‚
2. **SigLIP**: æ¯” CLIP æ›´å¥½çš„ç»†ç²’åº¦è§†è§‰ç†è§£
3. **æ¨¡å—åŒ–**: Vision/Language è§£è€¦ï¼Œæ–¹ä¾¿æ¥ Action Head

**Q: SigLIP å’Œ CLIP çš„åŒºåˆ«æ˜¯ä»€ä¹ˆï¼Ÿ**

A: 
- **æŸå¤±å‡½æ•°**: CLIP ä½¿ç”¨ Softmax + Cross-Entropy (InfoNCE)ï¼ŒSigLIP ä½¿ç”¨ Sigmoid + Binary CE
- **Batch ä¾èµ–**: CLIP çš„ Softmax éœ€è¦å¯¹æ¯” batch å†…æ‰€æœ‰æ ·æœ¬ï¼ŒSigLIP çš„ Sigmoid æ¯å¯¹ç‹¬ç«‹è®¡ç®—
- **æ‰©å±•æ€§**: SigLIP æ›´é€‚åˆå¤§ batch è®­ç»ƒï¼Œè´Ÿæ ·æœ¬åˆ©ç”¨æ›´é«˜æ•ˆ

**Q: å¦‚ä½•é€‰æ‹© Vision Encoder å’Œ LLM çš„ç»„åˆï¼Ÿ**

A:
- **è½»é‡çº§**: PaliGemma 3B (SigLIP + Gemma 2B)
- **å¹³è¡¡**: LLaVA (CLIP/ViT + Llama 2 7B)
- **è‡ªå®šä¹‰**: SigLIP (Vision) + ä»»æ„ LLM (Language)

**Q: ä¸­æ–‡ VLA ä»»åŠ¡åº”è¯¥é€‰æ‹©å“ªä¸ª VLMï¼Ÿ**

A: æ¨è **Qwen2.5-VL 7B**ï¼ˆğŸ†• 2025.03ï¼‰ï¼Œä¸­æ–‡æ”¯æŒæœ€å¥½ï¼Œæ•°å­¦æ¨ç†èƒ½åŠ›å¼ºï¼Œæ”¯æŒä»»æ„åˆ†è¾¨ç‡å’Œé•¿è§†é¢‘ã€‚å¦‚æœèµ„æºå—é™ï¼Œå¯é€‰æ‹© **Qwen2.5-VL 3B** ç‰ˆæœ¬ã€‚

**Q: æœ‰å“ªäº› 2025 å¹´æœ€æ–°çš„ VLM æ›´æ–°å€¼å¾—å…³æ³¨ï¼Ÿ**

A: 
- **Qwen2.5-VL** (2025.03): é˜¿é‡Œå·´å·´æœ€æ–°ç‰ˆæœ¬ï¼Œ**2025 SOTA**ï¼Œæ•°å­¦æ¨ç†å¼ºï¼Œæ”¯æŒä»»æ„åˆ†è¾¨ç‡
- **Eagle 2.5** (2025.04): NVIDIA å‘å¸ƒï¼Œé•¿ä¸Šä¸‹æ–‡å¤šæ¨¡æ€ï¼ŒVideo-MME 72.4%
- **Seed 1.5-VL** (2025.05): å­—èŠ‚è·³åŠ¨å‘å¸ƒï¼Œåª²ç¾ Gemini 2.5 Proï¼ŒGUI äº¤äº’å¼º
- **GLM-4.5V** (2025): æ™ºè°±AIï¼ŒMoE æ¶æ„ï¼Œ3D ç©ºé—´æ¨ç†
- **Llama 4** (2025.04): Meta å‘å¸ƒï¼Œ10M token ä¸Šä¸‹æ–‡ï¼Œå¤šæ¨¡æ€ MoE æ¶æ„
- **PLM** (2025.05): Meta å¼€æºè§†è§‰è¯­è¨€æ¨¡å‹

**Q: 2025å¹´é—­æº API æ¨¡å‹æœ‰å“ªäº›æ›´æ–°ï¼Ÿ**

A:
- **Gemini 2.5 Pro** (2025.03): Google å‘å¸ƒï¼Œæ’è¡Œæ¦œç¬¬ä¸€ï¼Œå†…ç½®æ€è€ƒåŠŸèƒ½
- **Claude 3.7 Vision** (2025.02): Anthropic å‘å¸ƒï¼Œé«˜ç²¾åº¦ OCR å’Œå›¾è¡¨è§£æ

---

## 6. æŠ•å½±å±‚è®¾è®¡ (Projector Design)

å°†è§†è§‰ç‰¹å¾æ˜ å°„åˆ°è¯­è¨€ç©ºé—´æ˜¯ VLA çš„å…³é”®ã€‚

### 6.1 ç®€å• MLP

```python
class MLPProjector(nn.Module):
    def __init__(self, vision_dim, language_dim):
        self.proj = nn.Sequential(
            nn.Linear(vision_dim, language_dim),
            nn.GELU(),
            nn.Linear(language_dim, language_dim)
        )
    
    def forward(self, vision_feat):
        return self.proj(vision_feat)
```

### 6.2 Perceiver Resampler (Flamingo)

```python
class PerceiverResampler(nn.Module):
    """å°†å¯å˜æ•°é‡çš„è§†è§‰ Token å‹ç¼©ä¸ºå›ºå®šæ•°é‡"""
    def __init__(self, num_latents=64):
        self.latents = nn.Parameter(torch.randn(num_latents, hidden_dim))
        self.cross_attn = nn.MultiheadAttention(hidden_dim, num_heads)
        
    def forward(self, vision_tokens):
        # vision_tokens: [B, N_patches, D] (N_patches å¯å˜)
        # è¾“å‡º: [B, num_latents, D] (å›ºå®š)
        
        latents = self.latents.unsqueeze(0).expand(B, -1, -1)
        output, _ = self.cross_attn(
            query=latents,
            key=vision_tokens,
            value=vision_tokens
        )
        return output  # [B, 64, D]
```

**ä¼˜åŠ¿**: æ§åˆ¶è§†è§‰ Token æ•°é‡ï¼Œå‡å°‘ LLM çš„è®¡ç®—è´Ÿæ‹…

### 6.3 Q-Former (BLIP-2)

ä½¿ç”¨å¯å­¦ä¹ çš„ Query ä»è§†è§‰ç¼–ç å™¨ä¸­æå–ä¸ä»»åŠ¡ç›¸å…³çš„ç‰¹å¾ã€‚

## 7. å®æˆ˜ï¼šæ„å»ºç®€å•çš„å¤šæ¨¡æ€ VLA

```python
import torch
import torch.nn as nn
from transformers import AutoModel, AutoTokenizer

class SimpleMultimodalVLA(nn.Module):
    def __init__(
        self,
        vision_encoder_name="google/siglip-base-patch16-224",
        language_model_name="meta-llama/Llama-2-7b-hf",
        action_dim=7,
        chunk_size=16
    ):
        super().__init__()
        
        # è§†è§‰ç¼–ç å™¨ (å†»ç»“)
        self.vision_encoder = AutoModel.from_pretrained(vision_encoder_name)
        for param in self.vision_encoder.parameters():
            param.requires_grad = False
        
        # æŠ•å½±å±‚ (å¯è®­ç»ƒ)
        vision_dim = self.vision_encoder.config.hidden_size
        language_dim = 4096  # Llama 2 hidden dim
        self.vision_projector = nn.Sequential(
            nn.Linear(vision_dim, language_dim),
            nn.GELU(),
            nn.Linear(language_dim, language_dim)
        )
        
        # è¯­è¨€æ¨¡å‹ (LoRA å¾®è°ƒ)
        self.language_model = AutoModel.from_pretrained(
            language_model_name,
            load_in_4bit=True  # QLoRA
        )
        
        # åŠ¨ä½œå¤´ (å¯è®­ç»ƒ)
        self.action_head = nn.Sequential(
            nn.Linear(language_dim, language_dim // 2),
            nn.ReLU(),
            nn.Linear(language_dim // 2, action_dim * chunk_size)
        )
        
        self.chunk_size = chunk_size
        self.action_dim = action_dim
    
    def forward(self, images, input_ids, attention_mask):
        """
        images: [B, C, H, W]
        input_ids: [B, L]
        attention_mask: [B, L]
        """
        batch_size = images.shape[0]
        
        # 1. è§†è§‰ç¼–ç 
        with torch.no_grad():
            vision_outputs = self.vision_encoder(images)
            vision_features = vision_outputs.last_hidden_state  # [B, N_patches, D_v]
        
        # 2. æŠ•å½±åˆ°è¯­è¨€ç©ºé—´
        vision_tokens = self.vision_projector(vision_features)  # [B, N_patches, D_l]
        
        # 3. è·å–è¯­è¨€åµŒå…¥
        text_embeds = self.language_model.get_input_embeddings()(input_ids)
        
        # 4. æ‹¼æ¥ [Vision Tokens | Text Tokens]
        inputs_embeds = torch.cat([vision_tokens, text_embeds], dim=1)
        
        # 5. é€šè¿‡è¯­è¨€æ¨¡å‹
        outputs = self.language_model(
            inputs_embeds=inputs_embeds,
            output_hidden_states=True
        )
        
        # 6. å–æœ€åä¸€ä¸ª hidden state ä½œä¸ºåŠ¨ä½œæ¡ä»¶
        last_hidden = outputs.hidden_states[-1][:, -1, :]  # [B, D_l]
        
        # 7. é¢„æµ‹åŠ¨ä½œ
        actions = self.action_head(last_hidden)  # [B, action_dim * chunk_size]
        actions = actions.view(batch_size, self.chunk_size, self.action_dim)
        
        return actions
```

## 8. é¢è¯•é«˜é¢‘é—®é¢˜ (Q&A)

**Q1: CLIP å’Œ SigLIP çš„åŒºåˆ«æ˜¯ä»€ä¹ˆï¼Ÿ**

A:
- **æŸå¤±å‡½æ•°**: CLIP ä½¿ç”¨ Softmax + Cross-Entropy (InfoNCE)ï¼ŒSigLIP ä½¿ç”¨ Sigmoid + Binary CE
- **batch ä¾èµ–**: CLIP çš„ Softmax éœ€è¦å¯¹æ¯” batch å†…æ‰€æœ‰æ ·æœ¬ï¼ŒSigLIP çš„ Sigmoid æ¯å¯¹ç‹¬ç«‹è®¡ç®—
- **æ‰©å±•æ€§**: SigLIP æ›´é€‚åˆå¤§ batch è®­ç»ƒï¼Œè´Ÿæ ·æœ¬åˆ©ç”¨æ›´é«˜æ•ˆ

**Q2: ä¸ºä»€ä¹ˆ VLA æ™®éé€‰æ‹© Decoder-only LLM è€Œä¸æ˜¯ BERTï¼Ÿ**

A:
- **ç”Ÿæˆèƒ½åŠ›**: Decoder-only å¤©ç„¶æ”¯æŒè‡ªå›å½’ç”Ÿæˆï¼ˆåŒ…æ‹¬åŠ¨ä½œ Tokenï¼‰
- **In-context Learning**: å¯ä»¥é€šè¿‡ Prompt å¼•å¯¼æ¨¡å‹ç†è§£æ–°ä»»åŠ¡
- **è§„æ¨¡æ•ˆåº”**: å¤§è§„æ¨¡ LLM (7B+) ä¸»è¦æ˜¯ Decoder-only æ¶æ„ï¼Œå¯ä»¥ç›´æ¥å¤ç”¨

**Q3: å¤šæ¨¡æ€èåˆä¸­ Early / Mid / Late Fusion å¦‚ä½•é€‰æ‹©ï¼Ÿ**

A:
- **Early Fusion**: æ•°æ®æ¨¡æ€ç›¸ä¼¼åº¦é«˜ï¼ˆå¦‚å¤šç›¸æœºå›¾åƒï¼‰
- **Mid Fusion (Cross-Attention)**: éœ€è¦åŠ¨æ€å»ºæ¨¡æ¨¡æ€é—´å…³ç³»ï¼ˆVLA é¦–é€‰ï¼‰
- **Late Fusion**: å„æ¨¡æ€ä»»åŠ¡ç‹¬ç«‹æ€§å¼ºï¼Œæˆ–éœ€è¦æ¨¡å—åŒ–è§£é‡Šæ€§

**Q4: è§†è§‰ Token æ•°é‡å¦‚ä½•é€‰æ‹©ï¼Ÿ**

A:
- **å¤šäº†**: LLM è®¡ç®—å¼€é”€å¤§ï¼Œé•¿åºåˆ— Attention å˜æ…¢
- **å°‘äº†**: ä¸¢å¤±ç©ºé—´ç»†èŠ‚ï¼Œå½±å“ç²¾ç»†æ“ä½œ
- **å¸¸è§é€‰æ‹©**: 256 tokens (16x16 patches @ 224px)ï¼Œæˆ–ä½¿ç”¨ Perceiver Resampler å‹ç¼©åˆ° 64

**Q5: ä¸ºä»€ä¹ˆè¦å†»ç»“è§†è§‰ç¼–ç å™¨ï¼Ÿ**

A:
- **é˜²æ­¢ç¾éš¾æ€§é—å¿˜**: è§†è§‰ç¼–ç å™¨çš„é¢„è®­ç»ƒç‰¹å¾å¾ˆé‡è¦
- **è®¡ç®—æ•ˆç‡**: å‡å°‘å¯è®­ç»ƒå‚æ•°
- **æ•°æ®æ•ˆç‡**: æœºå™¨äººæ•°æ®å°‘ï¼Œå…¨é‡è®­ç»ƒå®¹æ˜“è¿‡æ‹Ÿåˆ
- **ä¾‹å¤–**: å¦‚æœè§†è§‰ä»»åŠ¡å·®å¼‚å¤§ï¼ˆå¦‚ä» ImageNet è¿ç§»åˆ°å†…çª¥é•œï¼‰ï¼Œå¯èƒ½éœ€è¦å¾®è°ƒ

**Q6: å¦‚æœè§†è§‰æ¨¡å—è¯¯åˆ¤ï¼Œå¦‚ä½•é€šè¿‡è¯­è¨€çº é”™ï¼Ÿ**

A: è¿™æ˜¯å¤šæ¨¡æ€ VLA çš„æ ¸å¿ƒä¼˜åŠ¿ä¹‹ä¸€ï¼Œæœ‰ä»¥ä¸‹å‡ ç§æœºåˆ¶ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   è§†è§‰è¯¯åˆ¤ â†’ è¯­è¨€çº é”™æœºåˆ¶                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚   åœºæ™¯: è§†è§‰æ¨¡å—è¯¯åˆ¤ "çº¢è‰²æ¯å­" ä¸º "æ©™è‰²æ¯å­"                    â”‚
â”‚                                                                 â”‚
â”‚   æ–¹æ¡ˆ 1: é—­ç¯è¯­è¨€åé¦ˆ (Human-in-the-Loop)                      â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚  ç”¨æˆ·: "ä¸å¯¹ï¼Œæ˜¯çº¢è‰²çš„é‚£ä¸ª"                               â”‚   â”‚
â”‚   â”‚  VLA: é‡æ–°å®šä½ â†’ ä¿®æ­£ç›®æ ‡                                â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                 â”‚
â”‚   æ–¹æ¡ˆ 2: Chain-of-Thought è‡ªæ£€                                 â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚  VLA è¾“å‡º: "æˆ‘çœ‹åˆ°ä¸€ä¸ªæ©™è‰²ç‰©ä½“..."                        â”‚   â”‚
â”‚   â”‚  ç”¨æˆ·æŒ‡ä»¤: "æŠ“çº¢è‰²æ¯å­"                                   â”‚   â”‚
â”‚   â”‚  CoT æ¨ç†: "æŒ‡ä»¤è¯´çº¢è‰²ï¼Œä½†æˆ‘è¯†åˆ«ä¸ºæ©™è‰²ï¼Œå¯èƒ½æœ‰è¯¯"          â”‚   â”‚
â”‚   â”‚  åŠ¨ä½œ: è¯·æ±‚ç¡®è®¤ æˆ– é‡æ–°æ„ŸçŸ¥                              â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                 â”‚
â”‚   æ–¹æ¡ˆ 3: å¤šæ¨¡æ€ä¸€è‡´æ€§æ£€æŸ¥                                      â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚  è®¡ç®—: sim(è¯­è¨€æè¿° Embedding, è§†è§‰ç‰¹å¾ Embedding)        â”‚   â”‚
â”‚   â”‚  å¦‚æœ sim < threshold: è§¦å‘é‡æ–°æ„ŸçŸ¥/è¯¢é—®                  â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                 â”‚
â”‚   æ–¹æ¡ˆ 4: ä¸»åŠ¨è¯¢é—® (Uncertainty-aware)                          â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚  VLA: "ä½ æ˜¯æŒ‡è¿™ä¸ªå—ï¼Ÿ" (æ˜¾ç¤ºå€™é€‰ç‰©ä½“)                     â”‚   â”‚
â”‚   â”‚  ç”¨æˆ·: "æ˜¯çš„" / "ä¸æ˜¯ï¼Œæ˜¯å·¦è¾¹é‚£ä¸ª"                        â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**å®ç°è¦ç‚¹**:
1. **è¯­ä¹‰æ¥åœ° (Grounding)**: è¯­è¨€æŒ‡ä»¤å¿…é¡»ä¸è§†è§‰æ£€æµ‹ç»“æœç»‘å®šï¼Œè€Œéç‹¬ç«‹å¤„ç†
2. **ç½®ä¿¡åº¦è¾“å‡º**: è§†è§‰æ¨¡å—è¾“å‡ºæ£€æµ‹ç½®ä¿¡åº¦ï¼Œä½ç½®ä¿¡åº¦æ—¶è§¦å‘çº é”™æœºåˆ¶
3. **å¤šè½®å¯¹è¯**: VLA éœ€è¦æ”¯æŒå¤šè½®äº¤äº’ï¼Œè€Œéå•æ¬¡æŒ‡ä»¤æ‰§è¡Œ
4. **CoT æ¨ç†**: æ˜¾å¼è¾“å‡ºæ¨ç†è¿‡ç¨‹ï¼Œä¾¿äºå‘ç°çŸ›ç›¾ (å‚è§ [chain_of_thought.md](./chain_of_thought.md))

## 9. å‚è€ƒèµ„æº (References)

- **CLIP**: [Learning Transferable Visual Models From Natural Language Supervision](https://arxiv.org/abs/2103.00020)
- **LLaVA**: [Visual Instruction Tuning](https://arxiv.org/abs/2304.08485)
- **Flamingo**: [A Visual Language Model for Few-Shot Learning](https://arxiv.org/abs/2204.14198)
- **SigLIP**: [Sigmoid Loss for Language Image Pre-Training](https://arxiv.org/abs/2303.15343)

---


\newpage

# ç¬¬4ç«  VLA æ¶æ„æ€»è§ˆ


æœ¬ç« èŠ‚æ·±å…¥è§£æ Vision-Language-Action (VLA) æ¨¡å‹çš„æ ¸å¿ƒæ¶æ„æ¼”è¿›ï¼Œä» Google çš„ RT ç³»åˆ—åˆ°å¼€æºçš„ OpenVLAï¼Œå†åˆ°æœ€æ–°çš„ Physical Intelligence (Pi) æ¨¡å‹ã€‚

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    VLA æ¶æ„æ¼”è¿›è·¯çº¿å›¾                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚   RT-1 (2022)              RT-2 (2023)              Ï€0 (2024)   â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚   â”‚EffNet   â”‚              â”‚ PaLI-X  â”‚              â”‚ Gemma   â”‚ â”‚
â”‚   â”‚   +     â”‚   â”€â”€â”€â”€â–¶      â”‚  55B    â”‚   â”€â”€â”€â”€â–¶      â”‚  +Flow  â”‚ â”‚
â”‚   â”‚Tokenize â”‚              â”‚ VLM+Act â”‚              â”‚ Matchingâ”‚ â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚     å°æ¨¡å‹                   å¤§VLM                    é«˜æ•ˆæ¨ç†   â”‚
â”‚     æœºå™¨äººæ•°æ®               +äº’è”ç½‘æ•°æ®               +ç²¾ç»†æ§åˆ¶  â”‚
â”‚                                                                 â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚                    é€šç”¨ VLA æ¶æ„æ¨¡æ¿                     â”‚   â”‚
â”‚   â”‚                                                         â”‚   â”‚
â”‚   â”‚    ğŸ“· Image          ğŸ“ Language                        â”‚   â”‚
â”‚   â”‚       â”‚                  â”‚                              â”‚   â”‚
â”‚   â”‚       â–¼                  â–¼                              â”‚   â”‚
â”‚   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚   â”‚
â”‚   â”‚  â”‚ Vision  â”‚       â”‚ Language  â”‚                        â”‚   â”‚
â”‚   â”‚  â”‚ Encoder â”‚       â”‚ Encoder   â”‚                        â”‚   â”‚
â”‚   â”‚  â”‚(ViT/CNN)â”‚       â”‚(LLM/BERT) â”‚                        â”‚   â”‚
â”‚   â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                        â”‚   â”‚
â”‚   â”‚       â”‚                  â”‚                              â”‚   â”‚
â”‚   â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                              â”‚   â”‚
â”‚   â”‚                â”‚ Fusion                                 â”‚   â”‚
â”‚   â”‚                â–¼                                        â”‚   â”‚
â”‚   â”‚       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                               â”‚   â”‚
â”‚   â”‚       â”‚  Transformer    â”‚                               â”‚   â”‚
â”‚   â”‚       â”‚    Backbone     â”‚                               â”‚   â”‚
â”‚   â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                               â”‚   â”‚
â”‚   â”‚                â”‚                                        â”‚   â”‚
â”‚   â”‚                â–¼                                        â”‚   â”‚
â”‚   â”‚       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                               â”‚   â”‚
â”‚   â”‚       â”‚   Action Head   â”‚                               â”‚   â”‚
â”‚   â”‚       â”‚ Token/Diff/Flow â”‚                               â”‚   â”‚
â”‚   â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                               â”‚   â”‚
â”‚   â”‚                â”‚                                        â”‚   â”‚
â”‚   â”‚                â–¼                                        â”‚   â”‚
â”‚   â”‚          ğŸ¦¾ Robot Action                                â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## 1. RT-1 (Robotics Transformer 1)
> **æ ¸å¿ƒæ€æƒ³**: å°†æœºå™¨äººæ§åˆ¶å»ºæ¨¡ä¸º Token ç”Ÿæˆé—®é¢˜ï¼Œä½¿ç”¨ Transformer å¤„ç†å¤šæ¨¡æ€è¾“å…¥ã€‚

- **æ¶æ„**: EfficientNet (Vision) + FiLM (Language conditioning) + TokenLearner + Transformer.
- **Action Tokenization**:
    - å°†è¿ç»­çš„åŠ¨ä½œç©ºé—´ (x, y, z, roll, pitch, yaw, gripper) ç¦»æ•£åŒ–ä¸º 256 ä¸ª binsã€‚
    - è¾“å‡ºæ˜¯ä¸€ä¸ªç¦»æ•£çš„ Token åºåˆ—ï¼Œä»£è¡¨åŠ¨ä½œç»´åº¦ã€‚
- **å…³é”®ç‚¹**:
    - **TokenLearner**: æ˜¾è‘—å‡å°‘äº†è§†è§‰ Token çš„æ•°é‡ (e.g., 81 -> 8)ï¼Œæé«˜äº†æ¨ç†é€Ÿåº¦ã€‚
    - **æ•°æ®è§„æ¨¡**: 130k episodes (17 months of data).
    - **å±€é™æ€§**: æ³›åŒ–èƒ½åŠ›æœ‰é™ï¼Œä¸»è¦ä¾èµ–äºå¤§è§„æ¨¡æ”¶é›†çš„æœºå™¨äººæ•°æ®ï¼Œç¼ºä¹äº’è”ç½‘çŸ¥è¯†çš„è¿ç§»ã€‚

## 2. RT-2 (Robotics Transformer 2)
> **æ ¸å¿ƒæ€æƒ³**: VLA = VLM + Action Tokens. ç›´æ¥å¾®è°ƒé¢„è®­ç»ƒçš„ VLM (å¦‚ PaLI-X, PaLM-E) ç”¨äºæœºå™¨äººæ§åˆ¶ã€‚

- **æ¶æ„**: åŸºäºå¤§è§„æ¨¡ VLM (Vision-Language Model) å¾®è°ƒã€‚
- **Co-fine-tuning**:
    - æ··åˆè®­ç»ƒï¼šäº’è”ç½‘ VQA æ•°æ® + æœºå™¨äººæ“ä½œæ•°æ®ã€‚
    - æœºå™¨äººåŠ¨ä½œè¢«è¡¨ç¤ºä¸ºç‰¹æ®Šçš„æ–‡æœ¬ Token (e.g., "1 128 90 ...")ï¼Œä¸è‡ªç„¶è¯­è¨€ Token å…±äº«è¯è¡¨ã€‚
- **å…³é”®ç‚¹**:
    - **æ¶Œç°èƒ½åŠ› (Emergent Capabilities)**: èƒ½å¤Ÿç†è§£æœªè§è¿‡çš„æŒ‡ä»¤ (e.g., "pick up the extinct animal" -> æŠ“æé¾™ç©å…·)ï¼Œå¾—ç›Šäº VLM çš„è¯­ä¹‰ç†è§£èƒ½åŠ›ã€‚
    - **Chain-of-Thought**: æ”¯æŒç®€å•çš„æ¨ç†æ­¥éª¤ã€‚
    - **å±€é™æ€§**: æ¨ç†é€Ÿåº¦æ…¢ (å¤§æ¨¡å‹)ï¼Œéš¾ä»¥åœ¨è¾¹ç¼˜ç«¯å®æ—¶è¿è¡Œã€‚

## 3. OpenVLA / Octo
> **æ ¸å¿ƒæ€æƒ³**: å¼€æºã€é«˜æ•ˆã€åŸºäº Diffusion æˆ– Llama çš„ VLA ç­–ç•¥ã€‚

### Octo
- **æ¶æ„**: åŸºäº Diffusion Policy çš„ Transformer æ¶æ„ã€‚
- **ç‰¹ç‚¹**: æ”¯æŒå¤šç§è§‚å¯Ÿç©ºé—´ (Proprioception, Images) å’ŒåŠ¨ä½œç©ºé—´ã€‚
- **è®­ç»ƒ**: åœ¨ Open X-Embodiment (OXE) æ•°æ®é›†ä¸Šè®­ç»ƒã€‚

### OpenVLA
- **æ¶æ„**: åŸºäº Llama 2 (7B) + DINOv2 / SigLIP (Vision Encoder)ã€‚
- **Action Head**:
    - å¹¶æ²¡æœ‰ç›´æ¥è¾“å‡ºæ–‡æœ¬ Tokenï¼Œè€Œæ˜¯ä½¿ç”¨ä¸“é—¨çš„ Action Head (Linear Layer) é¢„æµ‹å»ç¦»æ•£åŒ–çš„åŠ¨ä½œ Tokenã€‚
    - ä½¿ç”¨ **Action Detokenization** è¿˜åŸä¸ºè¿ç»­åŠ¨ä½œã€‚
- **ä¼˜åŒ–**: æ”¯æŒ 4-bit é‡åŒ– (QLoRA) è®­ç»ƒå’Œæ¨ç†ï¼Œé€‚åˆæ¶ˆè´¹çº§æ˜¾å¡ã€‚

## 4. Physical Intelligence (Pi) Models
> **æ ¸å¿ƒæ€æƒ³**: é€šç”¨æœºå™¨äººåŸºç¡€æ¨¡å‹ (Generalist Robot Foundation Models)ï¼Œå¼ºè°ƒè·¨å½¢æ€ (Cross-Embodiment) å’Œç‰©ç†ä¸–ç•Œçš„ç†è§£ã€‚

### Ï€0 (Pi-Zero)
- **å®šä½**: åŸºç¡€ VLA æ¨¡å‹ï¼Œæ—¨åœ¨è§£å†³é€šç”¨çš„ç‰©ç†æ“ä½œé—®é¢˜ã€‚**å·²å¼€æº (Open Weights)**ã€‚
- **æ¶æ„ç‰¹ç‚¹**:
    - ç±»ä¼¼äº RT ç³»åˆ—ï¼Œä½†æ›´å¼ºè°ƒå¯¹ç‰©ç†åŠ¨åŠ›å­¦çš„ç†è§£ã€‚
    - å¯èƒ½é‡‡ç”¨äº†æ›´é«˜æ•ˆçš„ Action Tokenizerï¼Œä»¥é€‚åº”é«˜é¢‘æ§åˆ¶éœ€æ±‚ã€‚
- **æ•°æ®**: æ··åˆäº†å¤šç§æœºå™¨äººçš„æ•°æ® (Arms, Quadrupeds, Humanoids)ã€‚

### Ï€0.5 (Pi-Zero-Point-Five) - April 2025
> **[Deep Dive: Pi0.5 æ¨¡å‹è§£å‰–](./pi0_5_dissection.md)**

- **æ ¸å¿ƒå‡çº§**: **Open-world Generalization** (å¼€æ”¾ä¸–ç•Œæ³›åŒ–) ä¸ **Hierarchical Inference** (åˆ†å±‚æ¨ç†)ã€‚
- **æ¶æ„ç‰¹ç‚¹**:
    - **ç»Ÿä¸€æ¨¡å‹ (Unified Model)**: åŒæ—¶è´Ÿè´£é«˜å±‚è¯­ä¹‰è§„åˆ’ (Subtask Prediction) å’Œåº•å±‚ç”µæœºæ§åˆ¶ (Motor Control)ã€‚æ¨¡å‹"è‡ªè¨€è‡ªè¯­"ä¸‹ä¸€æ­¥è¦åšä»€ä¹ˆï¼Œç„¶åæ‰§è¡Œã€‚
    - **å¼‚æ„æ•°æ®è®­ç»ƒ**: å¼•å…¥äº†å¤§é‡çš„äº’è”ç½‘è§†é¢‘æ•°æ® (YouTube) å’Œæ¨¡æ‹Ÿæ•°æ®ï¼Œé€šè¿‡ Co-training å®ç°å¯¹æ–°ç¯å¢ƒ (å¦‚ä»æœªè§è¿‡çš„å¨æˆ¿) çš„é€‚åº”ã€‚
    - **æ··åˆæ¶æ„**: é¢„è®­ç»ƒé˜¶æ®µå¯èƒ½ä½¿ç”¨ç¦»æ•£ Token (FAST tokenizer) ä»¥æé«˜æ•ˆç‡ï¼Œæ¨ç†é˜¶æ®µä½¿ç”¨ Flow Matching ç”Ÿæˆè¿ç»­åŠ¨ä½œã€‚

### Ï€0.6 & Ï€*0.6 (Pi-Star) - November 2025
> **[Deep Dive: Pi0.6 æ¨¡å‹è§£å‰–](./pi0_6_dissection.md)**

- **æ ¸å¿ƒå‡çº§**: **RL (Reinforcement Learning) å¼ºåŒ–** ä¸ **Recap ç®—æ³•**ã€‚
- **Backbone**: å‡çº§ä¸º **5B Parameter VLM**ï¼Œå¢å¼ºäº†å¯¹å¤æ‚æŒ‡ä»¤å’Œç¯å¢ƒçš„ç†è§£ã€‚
- **Ï€*0.6 (Pi-Star)**:
    - **Recap ç®—æ³•**: ä¸€ç§ Offline RL æ–¹æ³•ã€‚æ¨¡å‹é€šè¿‡"å¤ç›˜" (Recap) è¿‡å»çš„æˆåŠŸä¸å¤±è´¥ç»éªŒè¿›è¡Œè‡ªæˆ‘æå‡ï¼Œè€Œä¸ä»…ä»…æ˜¯æ¨¡ä»¿ (BC)ã€‚
    - **æ€§èƒ½é£è·ƒ**: åœ¨é•¿åºåˆ—ä»»åŠ¡ (å¦‚æŠ˜å è¡£ç‰©ã€ç»„è£…çº¸ç®±) ä¸Šï¼Œååé‡ç¿»å€ï¼Œå¤±è´¥ç‡é™ä½ 2xã€‚
    - **Self-Improvement**: å…·å¤‡åœ¨çœŸæœºè¿è¡Œä¸­æŒç»­å­¦ä¹ çš„èƒ½åŠ›ã€‚
- **Action Expert**: å¼•å…¥äº†ä¸“é—¨çš„åŠ¨ä½œä¸“å®¶æ¨¡å—ï¼Œä¸“é—¨å¤„ç†ç²¾ç»†æ“ä½œï¼Œè§£å†³äº†å¤§è¯­è¨€æ¨¡å‹åœ¨ç²¾ç»†è¿åŠ¨æ§åˆ¶ä¸Šçš„"æ‰‹ç¬¨"é—®é¢˜ã€‚

## 5. æ¨¡å‹å¯¹æ¯”æ€»ç»“ (Model Comparison)

| æ¨¡å‹ | åŸºç¡€æ¶æ„ | Action è¾“å‡º | è®­ç»ƒæ•°æ® | ä¼˜åŠ¿ | åŠ£åŠ¿ |
| :--- | :--- | :--- | :--- | :--- | :--- |
| **RT-1** | EfficientNet + Transformer | Discrete Tokens | Robot Data Only | æ¨ç†å¿«ï¼Œç¨³å®šæ€§é«˜ | æ³›åŒ–å·®ï¼Œæ— è¯­ä¹‰æ¨ç† |
| **RT-2** | PaLI-X / PaLM-E | Text Tokens | Web + Robot Data | è¯­ä¹‰ç†è§£å¼ºï¼ŒZero-shot | æ¨ç†æ…¢ï¼Œé—­æº |
| **OpenVLA** | Llama 2 + SigLIP | Action Head | OXE Dataset | å¼€æºï¼Œæ”¯æŒé‡åŒ–ï¼Œæ˜“éƒ¨ç½² | æ€§èƒ½ç•¥é€Šäºé—­æº SOTA |
| **WALL-OSS** | Qwen2.5 VLMoE | **Dual Branches** (Flow + FAST) | Cross-Embodiment | **COT æ¨ç†**ï¼ŒåŒåˆ†æ”¯ï¼Œ**å·²å¼€æº** | è®­ç»ƒèµ„æºéœ€æ±‚é«˜ |
| **Ï€0.6** | Gemma 3 + Action Expert | Specialized | Cross-Embodiment + RL | æ³›åŒ–å¼ºï¼Œç²¾ç»†æ“ä½œå¥½ï¼Œ**å·²å¼€æº** | è®­ç»ƒæå…¶æ˜‚è´µ |

## é¢è¯•é«˜é¢‘è€ƒç‚¹
1. **Action Tokenization**: ä¸ºä»€ä¹ˆè¦ç¦»æ•£åŒ–ï¼Ÿè¿ç»­å›å½’ (Regression) æœ‰ä»€ä¹ˆé—®é¢˜ï¼Ÿ(ç­”: å¤šæ¨¡æ€åˆ†å¸ƒå¤„ç†èƒ½åŠ›)
2. **Co-fine-tuning**: ä¸ºä»€ä¹ˆè¦æ··åˆäº’è”ç½‘æ•°æ®ï¼Ÿ(ç­”: ä¿æŒ VLM çš„è¯­ä¹‰èƒ½åŠ›ï¼Œé˜²æ­¢ç¾éš¾æ€§é—å¿˜)
3. **Sim-to-Real**: OpenVLA å¦‚ä½•åœ¨çœŸæœºä¸Šéƒ¨ç½²ï¼Ÿ(ç­”: é‡åŒ–ï¼ŒVLM è’¸é¦)


---

\newpage

# ç¬¬äºŒéƒ¨åˆ†ï¼šç­–ç•¥ç”Ÿæˆä¸åŠ¨ä½œè¡¨ç¤º


\newpage

# ç¬¬5ç«  åŠ¨ä½œè¡¨ç¤ºæ–¹æ³•


åœ¨ VLA æ¨¡å‹ä¸­ï¼Œ"å¦‚ä½•è¾“å‡ºåŠ¨ä½œ" æ˜¯ä¸€ä¸ªæ ¸å¿ƒè®¾è®¡é€‰æ‹©ã€‚æœ¬ç« è¯¦ç»†å¯¹æ¯”ä¸‰ç§ä¸»æµçš„åŠ¨ä½œç”ŸæˆèŒƒå¼ï¼š**ç¦»æ•£åŒ– (Discrete Tokenization)**ã€**æ‰©æ•£ç­–ç•¥ (Diffusion Policy)** å’Œ **æµåŒ¹é… (Flow Matching)**ã€‚

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              ä¸‰ç§åŠ¨ä½œç”ŸæˆèŒƒå¼å¯¹æ¯” (Action Generation)            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  1. ç¦»æ•£åŒ– Tokenization (RT-1, RT-2)                            â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚     â”‚ è¿ç»­åŠ¨ä½œ â”€â”€â–¶ ç¦»æ•£ Bins â”€â”€â–¶ Token é¢„æµ‹   â”‚                 â”‚
â”‚     â”‚  0.234   â”€â”€â–¶  [0-255]  â”€â”€â–¶   Token 60   â”‚                 â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚     âš¡ å¿«é€Ÿ (1æ­¥)  |  ğŸ“‰ ç²¾åº¦æŸå¤±  |  âœ… å¤šæ¨¡æ€                  â”‚
â”‚                                                                 â”‚
â”‚  2. æ‰©æ•£ç­–ç•¥ Diffusion (Octo)                                   â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚     â”‚ å™ªå£° â•â•â•â•â–¶ å»å™ª â•â•â•â•â–¶ å»å™ª â•â•â•â•â–¶ åŠ¨ä½œ   â”‚                 â”‚
â”‚     â”‚  x_T  â”€â”€â–¶  x_{T-1} â”€â”€â–¶ ... â”€â”€â–¶  x_0    â”‚                 â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚     ğŸ¢ æ…¢ (50-100æ­¥)  |  ğŸ¯ é«˜ç²¾åº¦  |  âœ… å¤šæ¨¡æ€                 â”‚
â”‚                                                                 â”‚
â”‚  3. æµåŒ¹é… Flow Matching (Ï€0)                                   â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚     â”‚ å™ªå£° â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â–¶ åŠ¨ä½œ â”‚                 â”‚
â”‚     â”‚  x_T  â”€â”€â”€â”€â”€â”€ ç›´çº¿ ODE â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶  x_0  â”‚                 â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚     âš¡ æå¿« (1-10æ­¥)  |  ğŸ¯ é«˜ç²¾åº¦  |  âœ… å¤šæ¨¡æ€                 â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## 1. ç¦»æ•£åŒ– (Discrete Tokenization)
> **ä»£è¡¨æ¨¡å‹**: **RT-1**, **RT-2**, **Gato**

### æ ¸å¿ƒæ€æƒ³
å°†è¿ç»­çš„ç‰©ç†åŠ¨ä½œ (å¦‚å…³èŠ‚è§’åº¦ã€æœ«ç«¯åæ ‡) ç¦»æ•£åŒ–ä¸ºæ•´æ•° Tokenï¼Œä»è€Œå¯ä»¥ä½¿ç”¨æ ‡å‡†çš„ Transformer (åˆ†ç±»ä»»åŠ¡) è¿›è¡Œé¢„æµ‹ã€‚

### æ•°å­¦å…¬å¼
å‡è®¾åŠ¨ä½œ $a \in [min, max]$ï¼Œæˆ‘ä»¬å°†å…¶åˆ’åˆ†ä¸º $N$ ä¸ªåŒºé—´ (Bins)ã€‚

$$
Token = \text{round}\left( \frac{a - min}{max - min} \times (N - 1) \right)
$$

- **RT-1**: ä½¿ç”¨ $N=256$ã€‚
- **é¢„æµ‹**: æ¨¡å‹è¾“å‡ºä¸€ä¸ª Logits å‘é‡ $z \in \mathbb{R}^N$ï¼Œé€šè¿‡ Softmax å¾—åˆ°æ¦‚ç‡åˆ†å¸ƒï¼š

$$
P(Token = i) = \frac{e^{z_i}}{\sum_{j=0}^{N-1} e^{z_j}}
$$


### ä¼˜ç¼ºç‚¹
- **ä¼˜ç‚¹**:
    - **å¤šæ¨¡æ€åˆ†å¸ƒ (Multimodal)**: å¯ä»¥å¾ˆå¥½åœ°å»ºæ¨¡"å‘å·¦èµ°æˆ–å‘å³èµ°" (åŒå³°åˆ†å¸ƒ)ï¼Œè€Œä¸ä¼šè¾“å‡ºä¸­é—´çš„å¹³å‡å€¼ (æ’å¢™)ã€‚
    - **æ¶æ„ç»Ÿä¸€**: å¯ä»¥ç›´æ¥å¤ç”¨ LLM çš„ Cross-Entropy Lossã€‚
- **ç¼ºç‚¹**:
    - **ç²¾åº¦æŸå¤±**: ä¸¢å¤±äº† Bin å†…éƒ¨çš„ç²¾åº¦ã€‚å¯¹äºé«˜ç²¾åº¦è£…é…ä»»åŠ¡ï¼Œ256 ä¸ª Bin å¯èƒ½ä¸å¤Ÿã€‚
    - **é«˜é¢‘æŠ–åŠ¨**: é¢„æµ‹ç»“æœåœ¨ç›¸é‚» Bin ä¹‹é—´è·³å˜ä¼šå¯¼è‡´åŠ¨ä½œä¸å¹³æ»‘ã€‚

---

## 2. æ‰©æ•£ç­–ç•¥ (Diffusion Policy)
> **å‰ç½®é˜…è¯»**: [ä¼ ç»ŸåŠ¨ä½œç”Ÿæˆæ–¹æ³• (MSE/GMM)](./traditional_action_generation.md) - äº†è§£ä¸ºä»€ä¹ˆ MSE ä¼šå¯¼è‡´"æ’å¢™"ï¼Œä»¥åŠ GMM çš„å±€é™æ€§ã€‚

> **ä»£è¡¨æ¨¡å‹**: **Octo**, **MimicGen**, **Toyota HPT**

### æ ¸å¿ƒæ€æƒ³
å°†åŠ¨ä½œç”Ÿæˆå»ºæ¨¡ä¸ºä»é«˜æ–¯å™ªå£°ä¸­ **å»å™ª (Denoising)** çš„è¿‡ç¨‹ã€‚

### æ•°å­¦å…¬å¼
- **å‰å‘è¿‡ç¨‹ (åŠ å™ª)**:

$$
q(x_t | x_0) = \mathcal{N}(x_t; \sqrt{\bar{\alpha}_t} x_0, (1 - \bar{\alpha}_t) I)
$$

- **é€†å‘è¿‡ç¨‹ (å»å™ª)**:
æ¨¡å‹ $\epsilon_\theta(x_t, t, \text{cond})$ é¢„æµ‹å™ªå£°ï¼Œä»è€Œé€æ­¥è¿˜åŸåŠ¨ä½œï¼š

$$
x_{t-1} = \frac{1}{\sqrt{\alpha_t}} \left( x_t - \frac{1 - \alpha_t}{\sqrt{1 - \bar{\alpha}_t}} \epsilon_\theta(x_t, t, \text{cond}) \right) + \sigma_t z
$$


### ä¼˜ç¼ºç‚¹
- **ä¼˜ç‚¹**:
    - **é«˜ç²¾åº¦**: è¾“å‡ºæ˜¯è¿ç»­å€¼ï¼Œæ²¡æœ‰ç¦»æ•£åŒ–è¯¯å·®ã€‚
    - **å¤šæ¨¡æ€**: å¤©ç„¶æ”¯æŒå¤šè§£åˆ†å¸ƒ (Multimodal Distribution)ã€‚
    - **ç¨³å®šæ€§**: ç›¸æ¯” GANï¼Œè®­ç»ƒæ›´ç¨³å®šã€‚
- **ç¼ºç‚¹**:
    - **æ¨ç†æ…¢**: éœ€è¦è¿­ä»£å»å™ª (é€šå¸¸ 50-100 æ­¥)ï¼Œå¯¼è‡´æ¨ç†å»¶è¿Ÿé«˜ (Latency)ï¼Œéš¾ä»¥ç”¨äºé«˜é¢‘æ§åˆ¶ (å¦‚ >50Hz)ã€‚

---

## 3. æµåŒ¹é… (Flow Matching)
> **ä»£è¡¨æ¨¡å‹**: **Pi0 (Physical Intelligence)**

### æ ¸å¿ƒæ€æƒ³
å­¦ä¹ ä¸€ä¸ª **ç¡®å®šæ€§çš„å‘é‡åœº (Vector Field)**ï¼Œå°†å™ªå£°åˆ†å¸ƒå¹³æ»‘åœ°å˜æ¢ä¸ºæ•°æ®åˆ†å¸ƒã€‚

### ä¸ Diffusion çš„å¯¹æ¯”
- **Diffusion**: èµ°çš„æ˜¯éšæœºæ¸¸èµ° (Stochastic) çš„å»å™ªè·¯å¾„ã€‚
- **Flow Matching**: èµ°çš„æ˜¯ **ç›´çº¿ (Straight)** è·¯å¾„ (Optimal Transport)ã€‚

### ä¼˜ç¼ºç‚¹
- **ä¼˜ç‚¹**:
    - **æé€Ÿæ¨ç†**: ç”±äºè½¨è¿¹æ˜¯ç›´çš„ï¼ŒODE æ±‚è§£å™¨åªéœ€è¦å¾ˆå°‘çš„æ­¥æ•° (e.g., 1-10 æ­¥) å°±èƒ½å¾—åˆ°é«˜è´¨é‡ç»“æœã€‚
    - **é«˜é¢‘æ§åˆ¶**: ä½¿å¾—å¤§æ¨¡å‹ä¹Ÿèƒ½è·‘åœ¨ 50Hz+ çš„æ§åˆ¶é¢‘ç‡ä¸Šã€‚
- **ç¼ºç‚¹**:
    - **è®­ç»ƒå¤æ‚**: æ•°å­¦ç†è®ºç›¸å¯¹è¾ƒæ–°ï¼Œè®­ç»ƒç¨³å®šæ€§éœ€è¦æŠ€å·§ã€‚

---

## æ€»ç»“å¯¹æ¯” (Comparison)

| èŒƒå¼ | ä»£è¡¨æ¨¡å‹ | è¾“å‡ºç±»å‹ | æ¨ç†é€Ÿåº¦ | ç²¾åº¦ | å¤šæ¨¡æ€æ”¯æŒ |
| :--- | :--- | :--- | :--- | :--- | :--- |
| **Discrete Tokenization** | RT-1, RT-2 | æ•´æ•° Token | å¿« (1æ­¥) | ä½ (å—é™äº Bin) | æ”¯æŒ |
| **Diffusion Policy** | Octo | è¿ç»­æµ®ç‚¹æ•° | æ…¢ (50+æ­¥) | é«˜ | æ”¯æŒ |
| **Flow Matching** | Pi0 | è¿ç»­æµ®ç‚¹æ•° | æå¿« (1-10æ­¥) | é«˜ | æ”¯æŒ |

> **é¢è¯• Tip**: å¦‚æœé¢è¯•å®˜é—® "ä¸ºä»€ä¹ˆç°åœ¨çš„ VLA æ¨¡å‹å¼€å§‹ä» Tokenization è½¬å‘ Diffusion/Flow?"
> **ç­”**: ä¸ºäº†è¿½æ±‚**é«˜ç²¾åº¦æ“ä½œ** (å¦‚ç©¿é’ˆã€è£…é…)ã€‚Tokenization åœ¨å¤„ç†è¿™ç§ä»»åŠ¡æ—¶ï¼Œé‡åŒ–è¯¯å·®æ˜¯è‡´å‘½çš„ï¼Œè€Œ Diffusion/Flow æä¾›äº†è¿ç»­ç©ºé—´çš„ç²¾ç»†æ§åˆ¶èƒ½åŠ›ã€‚


---

\newpage

# ç¬¬6ç«  Diffusion Policy


> **æ ¸å¿ƒè®ºæ–‡**: [Diffusion Policy: Visuomotor Policy Learning via Action Diffusion](https://arxiv.org/abs/2303.04137) (Cheng Chi et al., RSS 2023)
> **ä»£è¡¨æ¨¡å‹**: **Octo**, **MimicGen**, **Toyota HPT**

## 0. ä¸»è¦æ•¸å­¸æ€æƒ³ (Main Mathematical Idea)

> **ç¬¬ä¸€æ€§åŸç†**: **Constructing Structure from Chaos (ä»æ··æ²Œä¸­æ„å»ºç§©åº)**

ç‰©ç†ä¸–ç•Œä¸­ï¼Œç†µå¢ï¼ˆæœ‰åºå˜æ— åºï¼‰æ˜¯è‡ªç„¶è¶‹åŠ¿ï¼Œå¦‚å¢¨æ°´åœ¨æ°´ä¸­æ‰©æ•£ã€‚Diffusion Model è¯•å›¾åœ¨æ•°å­¦ä¸Š**é€†è½¬**è¿™ä¸€æ—¶é—´è¿‡ç¨‹ã€‚

- **æ ¸å¿ƒæ•°å­¦å·¥å…·**: **Langevin Dynamics (æœ—ä¹‹ä¸‡åŠ¨åŠ›å­¦)** ä¸ **Score Matching**ã€‚
- **è§£é¢˜é€»è¾‘**:
    1.  **é€†å‘æ€ç»´**: å¦‚æœæˆ‘ä»¬çŸ¥é“æ•°æ®æ˜¯å¦‚ä½•ä¸€æ­¥æ­¥å˜æˆå™ªå£°çš„ï¼ˆå‰å‘è¿‡ç¨‹ï¼‰ï¼Œé‚£ä¹ˆåªè¦å­¦ä¼šæ¯ä¸€æ­¥çš„"é€†æ“ä½œ"ï¼ˆå»å™ªï¼‰ï¼Œå°±èƒ½ä»çº¯å™ªå£°ä¸­æ¢å¤å‡ºæ•°æ®ã€‚
    2.  **æ¢¯åº¦æŒ‡å¼•**: å­¦ä¹ æ•°æ®åˆ†å¸ƒçš„æ¢¯åº¦åœºï¼ˆScore Functionï¼Œ$\nabla_x \log p(x)$ï¼‰ã€‚è¿™å°±åƒåœ¨è¿·é›¾ï¼ˆå™ªå£°ï¼‰ä¸­ï¼Œæ¯ä¸€æ­¥éƒ½æ²¿ç€"æ•°æ®å¯†åº¦æ›´é«˜"çš„æ–¹å‘èµ°ä¸€å°æ­¥ï¼Œæœ€ç»ˆå¿…ç„¶ä¼šèµ°åˆ°æ•°æ®æµå½¢ä¸Šï¼ˆç”Ÿæˆåˆç†çš„åŠ¨ä½œï¼‰ã€‚
    3.  **å¤šæ¨¡æ€**: ä¸åƒå›å½’æ¨¡å‹å¯»æ‰¾"å¹³å‡å€¼"ï¼Œæ‰©æ•£æ¨¡å‹å­¦ä¹ çš„æ˜¯æ•´ä¸ªåœ°å½¢ï¼ˆLandscapeï¼‰ï¼Œå› æ­¤å¯ä»¥ä»åŒä¸€ä¸ªå™ªå£°èµ·ç‚¹èµ°åˆ°ä¸åŒçš„ç»ˆç‚¹ï¼ˆè§£å†³å¤šè§£é—®é¢˜ï¼‰ã€‚

## 1. ä¸ºä»€ä¹ˆéœ€è¦ Diffusion Policy? (Why?)

åœ¨ VLA å‡ºç°ä¹‹å‰ï¼Œä¸»æµçš„åŠ¨ä½œç”Ÿæˆæ–¹å¼æ˜¯ **MSE Regression** (å‡æ–¹è¯¯å·®å›å½’) æˆ– **GMM** (é«˜æ–¯æ··åˆæ¨¡å‹)ã€‚

### 1.1 å¤šæ¨¡æ€åˆ†å¸ƒé—®é¢˜ (The Multimodality Problem)
æœºå™¨äººç»å¸¸é¢ä¸´"å¤šè§£"æƒ…å†µã€‚ä¾‹å¦‚ï¼Œç»•è¿‡éšœç¢ç‰©å¯ä»¥**ä»å·¦ç»•**ä¹Ÿå¯ä»¥**ä»å³ç»•**ã€‚
- **MSE (å‡å€¼å›å½’)**: ä¼šé¢„æµ‹å‡ºå·¦å’Œå³çš„å¹³å‡å€¼ -> **ç›´ç›´æ’å‘éšœç¢ç‰©**ã€‚
- **Diffusion**: å¯ä»¥å®Œç¾æ‹ŸåˆåŒå³°åˆ†å¸ƒï¼Œéšæœºé‡‡æ ·å‡º"å·¦"æˆ–"å³"çš„ä¸€æ¡å®Œæ•´è½¨è¿¹ï¼Œè€Œä¸ä¼šå–å¹³å‡ã€‚
    - **Energy-Based Model (EBM) è§†è§’**: æˆ‘ä»¬å¯ä»¥æŠŠ Diffusion çœ‹ä½œæ˜¯åœ¨å­¦ä¹ ä¸€ä¸ªèƒ½é‡å‡½æ•° $E(x)$ã€‚çœŸå®æ•°æ®çš„èƒ½é‡ä½ï¼Œå™ªå£°çš„èƒ½é‡é«˜ã€‚
    - MSE è¯•å›¾æœ€å°åŒ–å•ä¸€æ¨¡æ€çš„è¯¯å·®ï¼Œç›¸å½“äºåœ¨ä¸¤ä¸ªä½è°·ä¹‹é—´å¼ºè¡Œæ‰¾ä¸€ä¸ª"å¹³å‡ä½è°·" (å¾€å¾€æ˜¯èƒ½é‡å¾ˆé«˜çš„é«˜åœ°)ã€‚
    - Diffusion åˆ™æ˜¯å­¦ä¹ æ•´ä¸ªåœ°è²Œ (Landscape)ï¼Œå…è®¸å­˜åœ¨å¤šä¸ªåˆ†ç¦»çš„ä½è°· (Modes)ã€‚

### 1.2 è¿ç»­ç©ºé—´çš„é«˜ç²¾åº¦ (High Precision)
ç›¸æ¯”äº Tokenization (RT-1) å°†åŠ¨ä½œç¦»æ•£åŒ–ä¸º 256 ä¸ªæ¡¶ï¼ŒDiffusion ç›´æ¥åœ¨è¿ç»­ç©ºé—´ç”Ÿæˆæµ®ç‚¹æ•°ï¼Œç²¾åº¦ç†è®ºä¸Šæ— é™ï¼Œéå¸¸é€‚åˆ**ç©¿é’ˆå¼•çº¿ã€ç²¾å¯†è£…é…**ç­‰ä»»åŠ¡ã€‚

## 2. æ•°å­¦åŸç† (Mathematical Formulation)

Diffusion Policy å°†åŠ¨ä½œç”Ÿæˆå»ºæ¨¡ä¸ºä¸€ä¸ª **æ¡ä»¶å»å™ªè¿‡ç¨‹ (Conditional Denoising Process)**ã€‚

### 2.1 å‰å‘è¿‡ç¨‹ (Forward Process / Diffusion)
å°†çœŸå®çš„åŠ¨ä½œè½¨è¿¹ $x_0$ é€æ­¥åŠ å™ªï¼Œå˜æˆçº¯é«˜æ–¯å™ªå£° $x_T$ã€‚

$$
q(x_t | x_{t-1}) = \mathcal{N}(x_t; \sqrt{1 - \beta_t} x_{t-1}, \beta_t I)
$$

ç»è¿‡ $t$ æ­¥åï¼Œå¯ä»¥ç›´æ¥å†™å‡º $x_t$ ä¸ $x_0$ çš„å…³ç³»ï¼š
$$
q(x_t | x_0) = \mathcal{N}(x_t; \sqrt{\bar{\alpha}_t} x_0, (1 - \bar{\alpha}_t) I)
$$

å…¶ä¸­ $\alpha_t = 1 - \beta_t$, $\bar{\alpha}_t = \prod_{i=1}^t \alpha_i$ã€‚

### 2.2 å™ªå£°è°ƒåº¦å™¨ (Noise Scheduler)
$\beta_t$ çš„é€‰æ‹©è‡³å…³é‡è¦ï¼Œé€šå¸¸æœ‰ä¸¤ç§ç­–ç•¥ï¼š
- **Linear Schedule**: $\beta_t$ ä» $\beta_{min}=10^{-4}$ çº¿æ€§å¢åŠ åˆ° $\beta_{max}=0.02$ã€‚
    - $\beta_t = \beta_{min} + \frac{t}{T}(\beta_{max} - \beta_{min})$
- **Cosine Schedule**: $\beta_t$ éšä½™å¼¦å‡½æ•°å˜åŒ–ï¼Œèƒ½æ›´å¥½åœ°ä¿ç•™ä¸­é—´æ—¶åˆ»çš„ä¿¡æ¯ï¼Œé˜²æ­¢å™ªå£°è¿‡æ—©"æ·¹æ²¡"ä¿¡å·ã€‚
    - $\bar{\alpha}_t = \frac{f(t)}{f(0)}, \quad f(t) = \cos^2 \left( \frac{t/T + s}{1+s} \cdot \frac{\pi}{2} \right)$
    - è¿™ç§è°ƒåº¦åœ¨ $t$ è¾ƒå°æ—¶å™ªå£°å¢åŠ å¾—å¾ˆæ…¢ï¼Œä¿ç•™äº†æ›´å¤šåŸå§‹ä¿¡å·ï¼Œå¯¹å¾®å°åŠ¨ä½œçš„ç”Ÿæˆæ›´æœ‰åˆ©ã€‚

### 2.3 é€†å‘è¿‡ç¨‹ (Reverse Process / Denoising)
è®­ç»ƒä¸€ä¸ªç¥ç»ç½‘ç»œ $\epsilon_\theta(x_t, t, \text{Obs})$ æ¥é¢„æµ‹å™ªå£°ã€‚
- **è¾“å…¥**: å½“å‰å¸¦å™ªåŠ¨ä½œ $x_t$ï¼Œæ—¶é—´æ­¥ $t$ï¼Œè§‚æµ‹æ¡ä»¶ $\text{Obs}$ (å›¾åƒ/è¯­è¨€)ã€‚
- **è¾“å‡º**: é¢„æµ‹çš„å™ªå£° $\hat{\epsilon}$ã€‚

å»å™ªå…¬å¼ (DDPM):

$$
x_{t-1} = \frac{1}{\sqrt{\alpha_t}} \left( x_t - \frac{1 - \alpha_t}{\sqrt{1 - \bar{\alpha}_t}} \epsilon_\theta(x_t, t, \text{Obs}) \right) + \sigma_t z
$$

å…¶ä¸­ $z \sim \mathcal{N}(0, I)$ æ˜¯éšæœºå™ªå£° (ä½†åœ¨æœ€åä¸€æ­¥ $t=0$ æ—¶è®¾ä¸º 0)ã€‚$\sigma_t$ æ˜¯æ–¹å·®é¡¹ï¼Œé€šå¸¸å– $\sqrt{\beta_t}$ æˆ– $\tilde{\beta}_t$ã€‚

### 2.4 æŸå¤±å‡½æ•° (Loss Function)
éå¸¸ç®€å•ï¼Œå°±æ˜¯é¢„æµ‹å™ªå£°ä¸çœŸå®å™ªå£°çš„ MSEï¼š

$$
\mathcal{L} = \mathbb{E}_{t, x_0, \epsilon} \left[ \| \epsilon - \epsilon_\theta(\sqrt{\bar{\alpha}_t} x_0 + \sqrt{1 - \bar{\alpha}_t} \epsilon, t, \text{Obs}) \|^2 \right]
$$


## 3. ç½‘ç»œæ¶æ„ (Network Architecture)

Diffusion Policy çš„æ ¸å¿ƒæ˜¯é‚£ä¸ªé¢„æµ‹å™ªå£°çš„ç½‘ç»œ $\epsilon_\theta$ã€‚ä¸»è¦æœ‰ä¸¤ç§æµæ´¾ï¼š

### 3.1 CNN-based (1D Temporal CNN / U-Net)
- **åŸç†**: å°†åŠ¨ä½œè½¨è¿¹çœ‹ä½œæ˜¯ä¸€ä¸ª 1D çš„æ—¶é—´åºåˆ— (Sequence Length = $T_p$, Action Dim = $D_a$)ã€‚
- **ç»“æ„**: ä½¿ç”¨ç±»ä¼¼äº U-Net çš„ç»“æ„ï¼Œä½†åœ¨æ—¶é—´ç»´åº¦ä¸Šè¿›è¡Œä¸‹é‡‡æ ·å’Œä¸Šé‡‡æ · (Downsample/Upsample)ã€‚
    - **Conditioning**: å›¾åƒç‰¹å¾ (ResNet/ViT) å’Œ è¯­è¨€ç‰¹å¾ (CLIP) é€šå¸¸é€šè¿‡ **FiLM (Feature-wise Linear Modulation)** å±‚æ³¨å…¥åˆ° U-Net çš„æ¯ä¸ª Residual Block ä¸­ã€‚
    - **Downsample**: Conv1d + GroupNorm + Mish
    - **Upsample**: ConvTranspose1d
    - **Skip Connection**: å°† Encoder çš„ç‰¹å¾æ‹¼æ¥åˆ° Decoderï¼Œä¿ç•™é«˜é¢‘ç»†èŠ‚ã€‚
- **ç‰¹ç‚¹**: è®¡ç®—æ•ˆç‡é«˜ï¼Œé€‚åˆå¤„ç†çŸ­æ—¶åºä¾èµ–ï¼Œæ˜¯ Diffusion Policy è®ºæ–‡ä¸­çš„é»˜è®¤é€‰æ‹©ã€‚

### 3.2 Transformer-based (DiT / Octo)
- **åŸç†**: å°†åŠ¨ä½œè½¨è¿¹åˆ‡æˆ Patchï¼Œæˆ–è€…ç›´æ¥ä½œä¸º Token è¾“å…¥ Transformerã€‚
- **ç»“æ„**: æ ‡å‡†çš„ Transformer Encoder/Decoder (å¦‚ DiT - Diffusion Transformer)ã€‚
- **ç‰¹ç‚¹**: 
    - èƒ½å¤Ÿå¤„ç†æ›´é•¿çš„æ—¶é—´ä¾èµ–ã€‚
    - **å¤šæ¨¡æ€èåˆ**: å¯ä»¥ç›´æ¥ Cross-Attention å›¾åƒ Patch å’Œ è¯­è¨€ Tokenã€‚
    - **Scalability**: å‚æ•°é‡å¯ä»¥åšå¾—å¾ˆå¤§ (e.g., Octo-Base 93M, Octo-Small 27M)ï¼Œé€‚åˆä½œä¸º Foundation Modelã€‚

## 4. æ¨ç†åŠ é€Ÿ (Inference Acceleration)

Diffusion çš„æœ€å¤§ç¼ºç‚¹æ˜¯æ…¢ã€‚DDPM éœ€è¦ 100 æ­¥å»å™ªï¼Œæ¨ç†ä¸€æ¬¡å¯èƒ½è¦å‡ ç™¾æ¯«ç§’ï¼Œæ— æ³•æ»¡è¶³æœºå™¨äºº 50Hz çš„æ§åˆ¶è¦æ±‚ã€‚

### 4.1 DDIM (Denoising Diffusion Implicit Models)
- **åŸç†**: å°†éšæœºæ¸¸èµ°è¿‡ç¨‹å˜ä¸ºç¡®å®šæ€§è¿‡ç¨‹ (Deterministic)ï¼Œè·³è¿‡ä¸­é—´æ­¥éª¤ã€‚DDIM é‡æ–°å®šä¹‰äº†å‰å‘è¿‡ç¨‹ï¼Œä½¿å¾—å®ƒæ˜¯ä¸€ä¸ªéé©¬å°”å¯å¤«è¿‡ç¨‹ï¼Œä»è€Œå…è®¸æ›´å¤§çš„æ­¥é•¿ã€‚
- **å…¬å¼**:

$$
x_{t-1} = \sqrt{\bar{\alpha}_{t-1}} \underbrace{\left( \frac{x_t - \sqrt{1 - \bar{\alpha}_t} \epsilon_\theta}{\sqrt{\bar{\alpha}_t}} \right)}_{\text{predicted } x_0} + \underbrace{\sqrt{1 - \bar{\alpha}_{t-1} - \sigma_t^2} \epsilon_\theta}_{\text{direction pointing to } x_t} + \sigma_t \epsilon_t
$$

- **æ•ˆæœ**: å¯ä»¥å°†æ­¥æ•°ä» 100 æ­¥å‹ç¼©åˆ° **10-15 æ­¥**ï¼ŒåŒæ—¶ä¿æŒè¾ƒé«˜çš„ç”Ÿæˆè´¨é‡ã€‚

### 4.2 Receding Horizon Control (RHC)
- **åŸç†**: æ¨¡å‹ä¸€æ¬¡é¢„æµ‹æœªæ¥ $H$ æ­¥çš„åŠ¨ä½œ (Action Chunk)ï¼Œä½†æœºå™¨äººåªæ‰§è¡Œå‰ $M$ æ­¥ (ä¾‹å¦‚ $M=8$)ï¼Œç„¶åé‡æ–°æ¨ç†ã€‚
- **ä¼˜åŠ¿**: æ©ç›–äº†æ¨ç†å»¶è¿Ÿï¼Œä¿è¯åŠ¨ä½œçš„è¿è´¯æ€§ã€‚

## 5. é¢è¯•å¸¸è§é—®é¢˜ (Q&A)

**Q: Diffusion Policy å’Œ GAN æœ‰ä»€ä¹ˆåŒºåˆ«?**
A: GAN å®¹æ˜“æ¨¡å¼åå¡Œ (Mode Collapse)ï¼Œå³åªå­¦ä¼šä¸€ç§è§£ï¼›Diffusion è®­ç»ƒæ›´ç¨³å®šï¼Œèƒ½è¦†ç›–æ‰€æœ‰æ¨¡æ€ (Mode Coverage)ã€‚

**Q: ä¸ºä»€ä¹ˆ Diffusion æ¨ç†æ…¢? å¦‚ä½•è§£å†³?**
A: å› ä¸ºå®ƒæ˜¯è¿­ä»£å»å™ªã€‚è§£å†³æ–¹æ³•åŒ…æ‹¬ä½¿ç”¨ DDIM å‡å°‘æ­¥æ•°ï¼Œæˆ–è€…ä½¿ç”¨ Consistency Distillation (ä¸€è‡´æ€§è’¸é¦) å°†æ­¥æ•°å‹ç¼©åˆ° 1 æ­¥ã€‚

**Q: ä»€ä¹ˆæ˜¯ Action Chunking?**
A: ä¸€æ¬¡é¢„æµ‹ä¸€æ®µæœªæ¥çš„åŠ¨ä½œåºåˆ—ï¼Œè€Œä¸æ˜¯åªé¢„æµ‹ä¸‹ä¸€æ­¥ã€‚è¿™åˆ©ç”¨äº†åŠ¨ä½œçš„æ—¶é—´ç›¸å…³æ€§ï¼Œæé«˜äº†å¹³æ»‘åº¦ã€‚


---

\newpage

# ç¬¬7ç«  Action Chunking Transformer (ACT)


> **æ ¸å¿ƒè®ºæ–‡**: [Learning Fine-Grained Bimanual Manipulation with Low-Cost Hardware](https://arxiv.org/abs/2304.13705) (Tony Z. Zhao et al., RSS 2023)
> **ä»£è¡¨é¡¹ç›®**: **ALOHA**, **Mobile ALOHA**, **ACT++**

## 0. ä¸»è¦æ•¸å­¸æ€æƒ³ (Main Mathematical Idea)

> **ç¬¬ä¸€æ€§åŸç†**: **Compression of Intent (æ„å›¾çš„å‹ç¼©)**

é«˜ç»´çš„åŠ¨ä½œç©ºé—´ï¼ˆè‚Œè‚‰çº¤ç»´/ç”µæœºæ§åˆ¶ï¼‰å¾€å¾€æ˜¯ç”±ä½ç»´çš„"æ„å›¾"ï¼ˆGrab cupï¼‰é©±åŠ¨çš„ã€‚

- **æ ¸å¿ƒæ•°å­¦å·¥å…·**: **Variational Inference (å˜åˆ†æ¨æ–­ / CVAE)**ã€‚
- **è§£é¢˜é€»è¾‘**:
    1.  **éšå˜é‡å‡è®¾**: å‡è®¾å¤æ‚çš„åŠ¨ä½œåºåˆ— $a$ æ˜¯ç”±ä¸€ä¸ªä¸å¯è§‚æµ‹çš„ä½ç»´å˜é‡ $z$ï¼ˆæ„å›¾/é£æ ¼ï¼‰ç”Ÿæˆçš„ã€‚
    2.  **å¹³è¡¡**: æˆ‘ä»¬å¸Œæœ›æ‰¾åˆ°è¿™ä¸ª $z$ã€‚ELBO (Evidence Lower Bound) æŸå¤±å‡½æ•°åœ¨ä¸¤ä»¶äº‹ä¹‹é—´å¯»æ‰¾å¹³è¡¡ï¼š
        - **é‡å»º (Reconstruction)**: $z$ å¿…é¡»åŒ…å«è¶³å¤Ÿçš„ä¿¡æ¯æ¥è¿˜åŸå‡ºç²¾ç¡®çš„åŠ¨ä½œï¼ˆè¦æŠŠæ´»å¹²å¥½ï¼‰ã€‚
        - **æ­£åˆ™ (Regularization)**: $z$ çš„åˆ†å¸ƒåº”è¯¥å°½å¯èƒ½ç®€å•ï¼ˆå¦‚æ ‡å‡†æ­£æ€åˆ†å¸ƒï¼‰ï¼Œä»¥ä¾¿äºæˆ‘ä»¬åœ¨æ¨ç†æ—¶å¯ä»¥éšæ„é‡‡æ ·ï¼ˆé€šç”¨æ€§/ç”Ÿæˆèƒ½åŠ›ï¼‰ã€‚
    3.  **å¤šæ¨¡æ€**: ä¸åŒçš„ $z$ ä»£è¡¨ä¸åŒçš„æ„å›¾ï¼Œä»è€Œç”Ÿæˆä¸åŒçš„åˆç†åŠ¨ä½œåºåˆ—ï¼Œè§£å†³äº†"å¹³å‡åŒ–"é—®é¢˜ã€‚

## 1. ä¸ºä»€ä¹ˆéœ€è¦ ACT? (Why?)

ä¼ ç»Ÿçš„è¡Œä¸ºå…‹éš† (Behavior Cloning, BC) æ–¹æ³•é€šå¸¸é‡‡ç”¨**å•æ­¥é¢„æµ‹**ï¼šæ¯æ¬¡åªé¢„æµ‹ä¸‹ä¸€æ—¶åˆ»çš„åŠ¨ä½œã€‚è¿™ç§æ–¹å¼å­˜åœ¨ä¸¥é‡çš„**è¯¯å·®ç´¯ç§¯ (Compounding Error)** é—®é¢˜ã€‚

### 1.1 å•æ­¥é¢„æµ‹çš„è‡´å‘½ç¼ºé™·

```
å•æ­¥é¢„æµ‹æµç¨‹:
è§‚æµ‹ o_t â†’ ç­–ç•¥ Ï€(o_t) â†’ åŠ¨ä½œ a_t â†’ æ‰§è¡Œ â†’ è§‚æµ‹ o_{t+1} â†’ ...
```

**é—®é¢˜**:
- **è¯¯å·®ç´¯ç§¯**: æ¯ä¸€æ­¥çš„é¢„æµ‹è¯¯å·®ä¼šä¼ é€’åˆ°ä¸‹ä¸€æ­¥ã€‚å¦‚æœæ¯æ­¥æœ‰ 1% çš„è¯¯å·®ï¼Œ100 æ­¥åè¯¯å·®å¯èƒ½è¾¾åˆ° 100%ã€‚
- **åˆ†å¸ƒåç§» (Distribution Shift)**: è®­ç»ƒæ•°æ®æ¥è‡ªä¸“å®¶è½¨è¿¹ï¼Œä½†æ‰§è¡Œæ—¶çš„çŠ¶æ€åˆ†å¸ƒå¯èƒ½åç¦»ä¸“å®¶ï¼Œå¯¼è‡´"è¶Šé”™è¶Šç¦»è°±"ã€‚
- **é«˜é¢‘é—­ç¯å‹åŠ›**: éœ€è¦æ¯ä¸€å¸§éƒ½ç²¾ç¡®é¢„æµ‹ï¼Œå¯¹æ¨¡å‹è¦æ±‚æé«˜ã€‚

### 1.2 ACT çš„è§£å†³æ€è·¯

ACT æå‡ºäº†ä¸€ä¸ªç®€å•è€Œæœ‰æ•ˆçš„æƒ³æ³•ï¼š**ä¸€æ¬¡é¢„æµ‹ä¸€æ®µæœªæ¥çš„åŠ¨ä½œåºåˆ— (Action Chunk)**ï¼Œè€Œä¸æ˜¯åªé¢„æµ‹ä¸‹ä¸€æ­¥ã€‚


$$
\text{å•æ­¥ BC}: \pi(o_t) \rightarrow a_t
$$



$$
\text{ACT}: \pi(o_t) \rightarrow [a_t, a_{t+1}, ..., a_{t+k-1}]
$$


**æ ¸å¿ƒä¼˜åŠ¿**:
- **å‡å°‘å†³ç­–ç‚¹**: å¦‚æœ chunk å¤§å° $k=100$ï¼Œå†³ç­–é¢‘ç‡ä» 50Hz é™åˆ° 0.5Hzï¼Œå¤§å¤§é™ä½äº†è¯¯å·®ç´¯ç§¯çš„æœºä¼šã€‚
- **éšå¼ä»»åŠ¡åˆ†è§£**: é¢„æµ‹ä¸€æ•´æ®µåŠ¨ä½œï¼Œæ¨¡å‹éœ€è¦"ç†è§£"æ•´ä¸ªå­ä»»åŠ¡çš„ç»“æ„ (å¦‚"ä¼¸æ‰‹â†’æŠ“æ¡â†’æŠ¬èµ·")ï¼Œè€Œä¸åªæ˜¯ç›²ç›®æ¨¡ä»¿ä¸‹ä¸€å¸§ã€‚
- **å¹³æ»‘è½¨è¿¹**: ä¸€æ¬¡ç”Ÿæˆçš„è½¨è¿¹å¤©ç„¶è¿è´¯ï¼Œé¿å…äº†å•æ­¥é¢„æµ‹çš„æŠ–åŠ¨ã€‚

## 2. æ ¸å¿ƒæŠ€æœ¯ (Core Techniques)

### 2.1 åŠ¨ä½œåˆ†å— (Action Chunking)

**å®šä¹‰**: å°†è¿ç»­çš„åŠ¨ä½œåºåˆ—åˆ†æˆå›ºå®šé•¿åº¦ $k$ çš„"å—"ï¼Œæ¨¡å‹ä¸€æ¬¡é¢„æµ‹ä¸€æ•´ä¸ªå—ã€‚

**æ•°å­¦è¡¨ç¤º**:
- è¾“å…¥: å½“å‰è§‚æµ‹ $o_t$ (å›¾åƒ + æœ¬ä½“æ„ŸçŸ¥ + è¯­è¨€æŒ‡ä»¤)
- è¾“å‡º: åŠ¨ä½œåºåˆ— $\mathbf{a} = [a_t, a_{t+1}, ..., a_{t+k-1}] \in \mathbb{R}^{k \times D_a}$
- å…¶ä¸­ $D_a$ æ˜¯åŠ¨ä½œç»´åº¦ (å¦‚ 7-DoF æœºæ¢°è‡‚ + 1 å¤¹çˆª = 8)

**å…¸å‹å‚æ•°**:
- **ALOHA**: $k = 100$ (åœ¨ 50Hz æ§åˆ¶ä¸‹ï¼Œå¯¹åº” 2 ç§’çš„åŠ¨ä½œ)
- **Mobile ALOHA**: $k = 50$ (å¯¹åº” 1 ç§’)

### 2.2 æ—¶é—´é›†æˆ (Temporal Ensemble)

ä»…ç”¨ Action Chunking è¿˜ä¸å¤Ÿã€‚å¦‚æœåœ¨ $t=0$ æ—¶é¢„æµ‹äº† $[a_0, ..., a_{99}]$ï¼Œç„¶ååœ¨ $t=100$ æ—¶å†é¢„æµ‹ $[a_{100}, ..., a_{199}]$ï¼Œä¸¤æ®µè½¨è¿¹çš„äº¤ç•Œå¤„å¯èƒ½ä¸è¿ç»­ã€‚

**è§£å†³æ–¹æ¡ˆ**: **é‡å é¢„æµ‹ + æŒ‡æ•°åŠ æƒå¹³å‡**

```
æ—¶é—´æ­¥ t=0:   é¢„æµ‹ [a_0, a_1, ..., a_99]
æ—¶é—´æ­¥ t=1:   é¢„æµ‹ [a_1', a_2', ..., a_100']
æ—¶é—´æ­¥ t=2:   é¢„æµ‹ [a_2'', a_3'', ..., a_101'']
...

æ‰§è¡Œ a_t æ—¶ï¼Œèåˆæ‰€æœ‰å¯¹ a_t çš„é¢„æµ‹:
a_t^{final} = Î£ w_i * a_t^{(i)}
```

**æŒ‡æ•°åŠ æƒå…¬å¼**:

$$
w_i = \exp(-m \cdot i)
$$


å…¶ä¸­ $m$ æ˜¯è¡°å‡ç³»æ•° (é€šå¸¸ $m=0.01$)ï¼Œ$i$ æ˜¯é¢„æµ‹çš„"å¹´é¾„"(è¶Šæ–°çš„é¢„æµ‹æƒé‡è¶Šå¤§)ã€‚

**æ•ˆæœ**:
- **å¹³æ»‘è¿‡æ¸¡**: æ–°æ—§é¢„æµ‹çš„èåˆæ¶ˆé™¤äº†ä¸è¿ç»­ã€‚
- **é²æ£’æ€§**: å³ä½¿æŸæ¬¡é¢„æµ‹æœ‰è¯¯ï¼Œä¹Ÿä¼šè¢«å…¶ä»–é¢„æµ‹"ç¨€é‡Š"ã€‚

### 2.3 CVAE æ¶æ„ (Conditional Variational Autoencoder)

ACT çš„å¦ä¸€ä¸ªæ ¸å¿ƒåˆ›æ–°æ˜¯ä½¿ç”¨ **CVAE** æ¥å¤„ç†åŠ¨ä½œçš„**å¤šæ¨¡æ€åˆ†å¸ƒ**ã€‚

#### 2.3.1 ä¸ºä»€ä¹ˆéœ€è¦ CVAE?

ä¸ Diffusion Policy ç±»ä¼¼ï¼Œæœºå™¨äººåŠ¨ä½œå­˜åœ¨**å¤šè§£**é—®é¢˜ (å¦‚ç»•éšœç¢ç‰©å¯ä»¥ä»å·¦ç»•æˆ–ä»å³ç»•)ã€‚

- **MSE å›å½’**: ä¼šé¢„æµ‹å·¦å³çš„å¹³å‡å€¼ â†’ æ’å‘éšœç¢ç‰©ã€‚
- **CVAE**: å­¦ä¹ åŠ¨ä½œåˆ†å¸ƒçš„**éšå˜é‡è¡¨ç¤º**ï¼Œé‡‡æ ·ä¸åŒçš„ $z$ å¯ä»¥ç”Ÿæˆä¸åŒçš„åˆç†è½¨è¿¹ã€‚

#### 2.3.2 CVAE æ•°å­¦åŸç†

**è®­ç»ƒæ—¶ (æœ‰çœŸå®åŠ¨ä½œ)**:
1. **ç¼–ç å™¨ (Encoder)** $q_\phi(z | o, a)$: å°†è§‚æµ‹ $o$ å’ŒçœŸå®åŠ¨ä½œåºåˆ— $a$ ç¼–ç ä¸ºéšå˜é‡ $z$ çš„åˆ†å¸ƒ (å‡å€¼ $\mu$, æ–¹å·® $\sigma^2$)ã€‚
2. **è§£ç å™¨ (Decoder)** $p_\theta(a | o, z)$: ä»éšå˜é‡ $z$ å’Œè§‚æµ‹ $o$ é‡å»ºåŠ¨ä½œåºåˆ—ã€‚

**æŸå¤±å‡½æ•°**:

$$
\mathcal{L} = \underbrace{\| a - \hat{a} \|^2}_{\text{é‡å»ºæŸå¤±}} + \beta \cdot \underbrace{D_{KL}(q_\phi(z|o,a) \| \mathcal{N}(0, I))}_{\text{KL æ•£åº¦}}
$$


- **é‡å»ºæŸå¤±**: è®©è§£ç å™¨è¾“å‡ºæ¥è¿‘çœŸå®åŠ¨ä½œã€‚
- **KL æ•£åº¦**: è®©éšå˜é‡åˆ†å¸ƒæ¥è¿‘æ ‡å‡†æ­£æ€åˆ†å¸ƒï¼Œä¾¿äºæ¨ç†æ—¶é‡‡æ ·ã€‚
- **$\beta$**: æƒé‡ç³»æ•° (ACT ä¸­é€šå¸¸ $\beta = 10$)ã€‚

**æ¨ç†æ—¶ (æ— çœŸå®åŠ¨ä½œ)**:
1. ä»æ ‡å‡†æ­£æ€åˆ†å¸ƒé‡‡æ · $z \sim \mathcal{N}(0, I)$ã€‚
2. è§£ç å™¨æ ¹æ® $o$ å’Œ $z$ ç”ŸæˆåŠ¨ä½œåºåˆ—ã€‚

```python
## è®­ç»ƒæ—¶
z_mu, z_logvar = encoder(obs, gt_actions)  # ç¼–ç çœŸå®åŠ¨ä½œ
z = reparameterize(z_mu, z_logvar)         # é‡å‚æ•°åŒ–é‡‡æ ·
pred_actions = decoder(obs, z)             # è§£ç 

recon_loss = mse(pred_actions, gt_actions)
kl_loss = -0.5 * (1 + z_logvar - z_mu**2 - z_logvar.exp()).sum()
loss = recon_loss + beta * kl_loss

## æ¨ç†æ—¶
z = torch.randn(batch_size, z_dim)         # ç›´æ¥ä»æ ‡å‡†æ­£æ€é‡‡æ ·
pred_actions = decoder(obs, z)             # è§£ç 
```

## 3. ç½‘ç»œæ¶æ„ (Network Architecture)

ACT ä½¿ç”¨ **Transformer** ä½œä¸ºéª¨å¹²ç½‘ç»œï¼Œå…·ä½“åŒ…æ‹¬:

### 3.1 è§‚æµ‹ç¼–ç å™¨ (Observation Encoder)

```
è¾“å…¥:
- å›¾åƒ: [B, T, C, H, W] (å¯ä»¥æ˜¯å¤šç›¸æœº)
- æœ¬ä½“æ„ŸçŸ¥: [B, D_p] (å…³èŠ‚è§’åº¦ã€æœ«ç«¯ä½ç½®ç­‰)

å¤„ç†:
- å›¾åƒ â†’ ResNet-18 / ViT â†’ ç‰¹å¾å‘é‡ [B, T, D_v]
- æœ¬ä½“æ„ŸçŸ¥ â†’ Linear â†’ ç‰¹å¾å‘é‡ [B, D_p']
- æ‹¼æ¥ â†’ [B, T+1, D]
```

### 3.2 CVAE ç¼–ç å™¨ (ä»…è®­ç»ƒæ—¶)

```
è¾“å…¥:
- è§‚æµ‹ç‰¹å¾: [B, T+1, D]
- çœŸå®åŠ¨ä½œ: [B, k, D_a] (ç»è¿‡ Linear æ˜ å°„)

ç»“æ„:
- Transformer Encoder (4 å±‚)
- è¾“å‡º: z_mu, z_logvar âˆˆ R^{D_z} (é€šå¸¸ D_z = 32)
```

### 3.3 åŠ¨ä½œè§£ç å™¨ (Action Decoder)

```
è¾“å…¥:
- è§‚æµ‹ç‰¹å¾: [B, T+1, D] (ä½œä¸º Cross-Attention çš„ Key/Value)
- éšå˜é‡ z: [B, D_z] (æ‹¼æ¥åˆ°æ¯ä¸ª Query Token)
- å¯å­¦ä¹ çš„ Action Query: [B, k, D] (k ä¸ªä½ç½®ç¼–ç )

ç»“æ„:
- Transformer Decoder (7 å±‚)
- Cross-Attention: Query å…³æ³¨ è§‚æµ‹ç‰¹å¾
- è¾“å‡º: [B, k, D_a] (k æ­¥åŠ¨ä½œ)
```

### 3.4 å®Œæ•´æ¶æ„å›¾

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚            CVAE Encoder                 â”‚
                    â”‚  (obs_feat, gt_actions) â†’ z_mu, z_var   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â”‚ z (é‡å‚æ•°åŒ–é‡‡æ ·)
                                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Images     â”‚â”€â”€â”€â–¶â”‚                                         â”‚
â”‚  (å¤šç›¸æœº)    â”‚    â”‚         Observation Encoder             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”‚  ResNet-18 / ViT + Positional Emb       â”‚
â”‚  Proprio     â”‚â”€â”€â”€â–¶â”‚                                         â”‚
â”‚  (æœ¬ä½“æ„ŸçŸ¥)  â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚ obs_feat [B, T+1, D]
                                       â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚          Action Decoder                 â”‚
                    â”‚  (Action Query + z) Ã— obs_feat          â”‚
                    â”‚      Transformer Decoder                â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â”‚
                                       â–¼
                              Action Chunk [B, k, D_a]
```

## 4. ä¸å…¶ä»–æ–¹æ³•çš„å¯¹æ¯” (Comparison)

| æ–¹æ³• | é¢„æµ‹æ–¹å¼ | å¤šæ¨¡æ€å¤„ç† | æ¨ç†é€Ÿåº¦ | é€‚ç”¨åœºæ™¯ |
| :--- | :--- | :--- | :--- | :--- |
| **å•æ­¥ BC** | å•å¸§ | æ—  (MSE) | æœ€å¿« | ç®€å•ä»»åŠ¡ |
| **ACT (CVAE)** | Chunk ($k$ æ­¥) | CVAE é‡‡æ · | **å¿«** | é«˜é¢‘ã€ç²¾ç»†æ“ä½œ |
| **Diffusion Policy** | Chunk ($k$ æ­¥) | æ‰©æ•£é‡‡æ · | æ…¢ (å¤šæ­¥å»å™ª) | å¤šæ¨¡æ€å¤æ‚ä»»åŠ¡ |
| **Flow Matching (Ï€0)** | Chunk ($k$ æ­¥) | ODE é‡‡æ · | ä¸­ç­‰ | é€šç”¨åŸºç¡€æ¨¡å‹ |

**ACT çš„ä¼˜åŠ¿**:
- **æ¨ç†é€Ÿåº¦å¿«**: CVAE åªéœ€ä¸€æ¬¡å‰å‘ä¼ æ’­ï¼ŒDiffusion éœ€è¦ 10-100 æ­¥å»å™ªã€‚
- **ç®€å•æ˜“å®ç°**: æ ‡å‡† Transformer + VAEï¼Œæ— éœ€å¤æ‚çš„å™ªå£°è°ƒåº¦å™¨ã€‚
- **æ•°æ®æ•ˆç‡é«˜**: åœ¨ ALOHA é¡¹ç›®ä¸­ï¼Œä»… 50 æ¡æ¼”ç¤ºå°±èƒ½å­¦ä¼šåŒè‡‚ç²¾ç»†æ“ä½œã€‚

**ACT çš„åŠ£åŠ¿**:
- **åˆ†å¸ƒè¦†ç›–æœ‰é™**: CVAE çš„éšç©ºé—´å®¹é‡æœ‰é™ï¼Œå¯èƒ½æ— æ³•è¦†ç›–æ‰€æœ‰åŠ¨ä½œæ¨¡æ€ã€‚
- **KL åå¡Œé£é™©**: å¦‚æœ $\beta$ è®¾ç½®ä¸å½“ï¼Œæ¨¡å‹å¯èƒ½å¿½ç•¥éšå˜é‡ $z$ã€‚

## 5. å®æˆ˜ä»£ç ç¤ºä¾‹ (Code Example)

```python
import torch
import torch.nn as nn
from torch.nn import TransformerEncoder, TransformerDecoder

class ACTPolicy(nn.Module):
    def __init__(
        self,
        obs_dim: int,
        action_dim: int,
        chunk_size: int = 100,
        z_dim: int = 32,
        hidden_dim: int = 512,
        num_encoder_layers: int = 4,
        num_decoder_layers: int = 7,
    ):
        super().__init__()
        self.chunk_size = chunk_size
        self.z_dim = z_dim
        
        # Observation Encoder
        self.obs_encoder = nn.Linear(obs_dim, hidden_dim)
        
        # CVAE Encoder (ç”¨äºè®­ç»ƒ)
        self.cvae_encoder = TransformerEncoder(
            nn.TransformerEncoderLayer(d_model=hidden_dim, nhead=8),
            num_layers=num_encoder_layers
        )
        self.z_mu = nn.Linear(hidden_dim, z_dim)
        self.z_logvar = nn.Linear(hidden_dim, z_dim)
        
        # Action Decoder
        self.action_queries = nn.Parameter(torch.randn(chunk_size, hidden_dim))
        self.z_proj = nn.Linear(z_dim, hidden_dim)
        self.action_decoder = TransformerDecoder(
            nn.TransformerDecoderLayer(d_model=hidden_dim, nhead=8),
            num_layers=num_decoder_layers
        )
        self.action_head = nn.Linear(hidden_dim, action_dim)
        
        # Action embedding for CVAE encoder
        self.action_embed = nn.Linear(action_dim, hidden_dim)
    
    def encode(self, obs_feat, actions):
        """CVAE ç¼–ç å™¨: ç¼–ç è§‚æµ‹å’ŒåŠ¨ä½œåˆ°éšç©ºé—´"""
        # actions: [B, k, action_dim]
        action_feat = self.action_embed(actions)  # [B, k, hidden_dim]
        
        # æ‹¼æ¥è§‚æµ‹å’ŒåŠ¨ä½œ
        combined = torch.cat([obs_feat, action_feat], dim=1)  # [B, T+1+k, D]
        combined = combined.permute(1, 0, 2)  # [T+1+k, B, D]
        
        encoded = self.cvae_encoder(combined)
        pooled = encoded.mean(dim=0)  # [B, D]
        
        return self.z_mu(pooled), self.z_logvar(pooled)
    
    def reparameterize(self, mu, logvar):
        """é‡å‚æ•°åŒ–æŠ€å·§"""
        std = torch.exp(0.5 * logvar)
        eps = torch.randn_like(std)
        return mu + eps * std
    
    def decode(self, obs_feat, z):
        """åŠ¨ä½œè§£ç å™¨: ä»è§‚æµ‹å’Œéšå˜é‡ç”ŸæˆåŠ¨ä½œåºåˆ—"""
        batch_size = obs_feat.shape[0]
        
        # Action queries + z
        queries = self.action_queries.unsqueeze(0).expand(batch_size, -1, -1)
        z_expanded = self.z_proj(z).unsqueeze(1)  # [B, 1, D]
        queries = queries + z_expanded  # å¹¿æ’­åŠ æ³•
        
        queries = queries.permute(1, 0, 2)  # [k, B, D]
        obs_feat = obs_feat.permute(1, 0, 2)  # [T+1, B, D]
        
        decoded = self.action_decoder(queries, obs_feat)
        decoded = decoded.permute(1, 0, 2)  # [B, k, D]
        
        return self.action_head(decoded)
    
    def forward(self, obs, actions=None):
        """
        è®­ç»ƒæ—¶: obs + actions â†’ z â†’ pred_actions
        æ¨ç†æ—¶: obs â†’ sample z â†’ pred_actions
        """
        obs_feat = self.obs_encoder(obs).unsqueeze(1)  # [B, 1, D]
        
        if actions is not None:  # è®­ç»ƒæ¨¡å¼
            z_mu, z_logvar = self.encode(obs_feat, actions)
            z = self.reparameterize(z_mu, z_logvar)
            pred_actions = self.decode(obs_feat, z)
            return pred_actions, z_mu, z_logvar
        else:  # æ¨ç†æ¨¡å¼
            z = torch.randn(obs.shape[0], self.z_dim, device=obs.device)
            pred_actions = self.decode(obs_feat, z)
            return pred_actions


def compute_loss(pred_actions, gt_actions, z_mu, z_logvar, beta=10.0):
    """ACT æŸå¤±å‡½æ•°: é‡å»ºæŸå¤± + Î² * KL æ•£åº¦"""
    recon_loss = nn.functional.mse_loss(pred_actions, gt_actions)
    kl_loss = -0.5 * torch.mean(1 + z_logvar - z_mu.pow(2) - z_logvar.exp())
    return recon_loss + beta * kl_loss, recon_loss, kl_loss
```

## 6. æ—¶é—´é›†æˆçš„å®ç° (Temporal Ensemble)

```python
class TemporalEnsemble:
    def __init__(self, chunk_size, action_dim, decay=0.01):
        self.chunk_size = chunk_size
        self.decay = decay
        self.action_buffer = []  # å­˜å‚¨å†å²é¢„æµ‹
        self.weights = []        # å­˜å‚¨å¯¹åº”æƒé‡
    
    def update(self, new_chunk):
        """æ·»åŠ æ–°é¢„æµ‹çš„ chunk"""
        # new_chunk: [k, action_dim]
        self.action_buffer.append(new_chunk)
        self.weights.append(1.0)
        
        # è¡°å‡æ—§æƒé‡
        self.weights = [w * (1 - self.decay) for w in self.weights]
        
        # ç§»é™¤è¿‡æœŸçš„é¢„æµ‹
        while len(self.action_buffer) > self.chunk_size:
            self.action_buffer.pop(0)
            self.weights.pop(0)
    
    def get_action(self, t):
        """è·å–æ—¶åˆ» t çš„é›†æˆåŠ¨ä½œ"""
        weighted_sum = 0
        total_weight = 0
        
        for i, (chunk, w) in enumerate(zip(self.action_buffer, self.weights)):
            # è®¡ç®—è¯¥ chunk å¯¹æ—¶åˆ» t çš„é¢„æµ‹
            chunk_start_time = t - len(self.action_buffer) + i + 1
            local_idx = t - chunk_start_time
            
            if 0 <= local_idx < len(chunk):
                weighted_sum += w * chunk[local_idx]
                total_weight += w
        
        return weighted_sum / total_weight if total_weight > 0 else None
```

## 7. é¢è¯•å¸¸è§é—®é¢˜ (Q&A)

**Q1: ACT å’Œ Diffusion Policy çš„æ ¸å¿ƒåŒºåˆ«æ˜¯ä»€ä¹ˆ?**

A: 
- **ç”Ÿæˆæœºåˆ¶**: ACT ä½¿ç”¨ **CVAE** (ä¸€æ¬¡å‰å‘ä¼ æ’­)ï¼ŒDiffusion ä½¿ç”¨**è¿­ä»£å»å™ª** (10-100 æ­¥)ã€‚
- **é€Ÿåº¦**: ACT æ¨ç†æ›´å¿«ï¼Œé€‚åˆé«˜é¢‘æ§åˆ¶ (50Hz)ï¼›Diffusion æ…¢ä½†åˆ†å¸ƒè¦†ç›–æ›´å…¨ã€‚
- **å®ç°å¤æ‚åº¦**: ACT æ›´ç®€å• (æ ‡å‡† VAE)ï¼›Diffusion éœ€è¦å™ªå£°è°ƒåº¦å™¨ã€‚

**Q2: ä¸ºä»€ä¹ˆ Action Chunking èƒ½å‡å°‘è¯¯å·®ç´¯ç§¯?**

A:
- å‡å°‘äº†**å†³ç­–ç‚¹æ•°é‡**ï¼šchunk=100 æ—¶ï¼ŒåŸæœ¬ 100 æ¬¡å†³ç­–å˜ä¸º 1 æ¬¡ã€‚
- æ¨¡å‹éœ€è¦**è§„åˆ’æ•´ä¸ªå­ä»»åŠ¡**ï¼Œè€Œéç›²ç›®æ¨¡ä»¿ï¼Œéšå¼å­¦åˆ°äº†ä»»åŠ¡ç»“æ„ã€‚
- é…åˆ**æ—¶é—´é›†æˆ**ï¼Œå•æ¬¡é¢„æµ‹è¯¯å·®è¢«å¤šæ¬¡é¢„æµ‹å¹³å‡æ‰ã€‚

**Q3: CVAE ä¸­çš„ Î² å‚æ•°å¦‚ä½•è°ƒæ•´?**

A:
- **Î² è¿‡å¤§**: KL æ•£åº¦è¢«è¿‡åº¦æƒ©ç½šï¼Œéšå˜é‡ $z$ è¶‹è¿‘äºæ ‡å‡†æ­£æ€ï¼Œæ¨¡å‹é€€åŒ–ä¸ºç¡®å®šæ€§è¾“å‡º (**KL åå¡Œ**)ã€‚
- **Î² è¿‡å°**: éšç©ºé—´ä¸è§„æ•´ï¼Œæ¨ç†æ—¶é‡‡æ ·çš„ $z$ å¯èƒ½è½åœ¨"ç©ºç™½åŒº"ï¼Œç”Ÿæˆä¸åˆç†çš„åŠ¨ä½œã€‚
- **ç»éªŒå€¼**: ALOHA é¡¹ç›®ä¸­ $\beta = 10$ æ•ˆæœæœ€ä½³ï¼›å¯ä»¥ä½¿ç”¨ **Î²-VAE é€€ç«** (ä»å°åˆ°å¤§é€æ¸å¢åŠ )ã€‚

**Q4: æ—¶é—´é›†æˆ (Temporal Ensemble) çš„ä½œç”¨æ˜¯ä»€ä¹ˆ?**

A:
- **å¹³æ»‘è½¨è¿¹**: æ¶ˆé™¤ç›¸é‚» chunk ä¹‹é—´çš„ä¸è¿ç»­ã€‚
- **æé«˜é²æ£’æ€§**: å•æ¬¡é¢„æµ‹çš„é”™è¯¯è¢«å†å²é¢„æµ‹"ç¨€é‡Š"ã€‚
- **æƒè¡¡å»¶è¿Ÿ vs å¹³æ»‘**: è¡°å‡ç³»æ•° $m$ è¶Šå¤§ï¼Œå“åº”è¶Šå¿«ä½†è¶Šä¸å¹³æ»‘ã€‚

**Q5: ACT ä¸ºä»€ä¹ˆåœ¨ ALOHA é¡¹ç›®ä¸­è¡¨ç°å‡ºè‰²?**

A:
- **é«˜é¢‘åŒè‡‚åè°ƒ**: åŒè‡‚æ“ä½œéœ€è¦ 50Hz ç²¾ç»†æ§åˆ¶ï¼ŒACT çš„å¿«é€Ÿæ¨ç†è‡³å…³é‡è¦ã€‚
- **æ•°æ®æ•ˆç‡**: CVAE çš„éšç©ºé—´æä¾›äº†è‰¯å¥½çš„å½’çº³åç½®ï¼Œ50 æ¡æ¼”ç¤ºå³å¯æ³›åŒ–ã€‚
- **ç¡¬ä»¶å‹å¥½**: ç®€å•æ¶æ„æ˜“äºéƒ¨ç½²åˆ°è¾¹ç¼˜è®¾å¤‡ã€‚

## 8. å‚è€ƒèµ„æº (References)

- **è®ºæ–‡**: [Learning Fine-Grained Bimanual Manipulation with Low-Cost Hardware](https://arxiv.org/abs/2304.13705)
- **GitHub**: [ALOHA](https://github.com/tonyzhaozh/aloha)
- **é¡¹ç›®ä¸»é¡µ**: [Mobile ALOHA](https://mobile-aloha.github.io/)
- **è§†é¢‘æ•™ç¨‹**: [ACT è®ºæ–‡ç²¾è¯»](https://www.bilibili.com/video/BV1xxx) (B ç«™)

---


\newpage

# ç¬¬8ç«  Flow Matching


> **æ³¨æ„**: Pi0 å·²äº 2025 å¹´ 2 æœˆå¼€æº (OpenPI / LeRobot)ã€‚ä»¥ä¸‹ä»£ç åŸºäº Flow Matching åŸç†å’Œ VLA æ¶æ„é€šè¯†è¿›è¡Œçš„ **æ ¸å¿ƒé€»è¾‘è§£æ„**ï¼Œæ–¹ä¾¿ç†è§£å…¶æ•°å­¦è¿‡ç¨‹ã€‚

## 0. ä¸»è¦æ•¸å­¸æ€æƒ³ (Main Mathematical Idea)

> **ç¬¬ä¸€æ€§åŸç†**: **The Shortest Path (æœ€çŸ­è·¯å¾„ / Optimal Transport)**

Diffusion å°±åƒä¸€ä¸ªé†‰æ±‰ï¼ˆéšæœºæ¸¸èµ°ï¼‰è·Œè·Œæ’æ’åœ°ä»å™ªå£°èµ°å›æ•°æ®ï¼Œè·¯å¾„æ›²æŠ˜ä¸”ä½æ•ˆã€‚Flow Matching è¯•å›¾æ„å»ºä¸€æ¡**ç›´è¾¾**çš„è·¯å¾„ã€‚

- **æ ¸å¿ƒæ•°å­¦å·¥å…·**: **ODE (å¸¸å¾®åˆ†æ–¹ç¨‹)** ä¸ **Optimal Transport (æœ€ä¼˜ä¼ è¾“)**ã€‚
- **è§£é¢˜é€»è¾‘**:
    1.  **æ‹‰ç›´**: åœ¨æ¦‚ç‡åˆ†å¸ƒç©ºé—´ä¸­ï¼Œä¸¤ç‚¹ä¹‹é—´ï¼ˆå™ªå£°åˆ†å¸ƒ vs æ•°æ®åˆ†å¸ƒï¼‰æœ€çŸ­çš„è·¯å¾„æ˜¯ç›´çº¿ï¼ˆGeodesicï¼‰ã€‚
    2.  **å‘é‡åœº**: å¦‚æœæˆ‘ä»¬èƒ½ç›´æ¥å­¦ä¹ åˆ°è¿™æ¡ç›´çº¿ä¸Šçš„"é€Ÿåº¦å‘é‡"ï¼ˆVector Fieldï¼‰ï¼Œé‚£ä¹ˆæ¨ç†æ—¶åªéœ€è¦æ²¿ç€é€Ÿåº¦æ–¹å‘èµ°å‡ æ­¥ï¼ˆEulerç§¯åˆ†ï¼‰å°±èƒ½åˆ°è¾¾ç»ˆç‚¹ã€‚
    3.  **ç¡®å®šæ€§**: ä»éšæœºçš„å¸ƒæœ—è¿åŠ¨ï¼ˆDiffusionï¼‰è½¬å˜ä¸ºç¡®å®šæ€§çš„æµä½“è¿åŠ¨ï¼ˆFlowï¼‰ï¼Œæå¤§åœ°å‡å°‘äº†æ¨ç†æ­¥æ•°ï¼ˆ100æ­¥ -> 10æ­¥ï¼‰ã€‚

## 1. æ ¸å¿ƒæ€æƒ³ï¼šä»å™ªå£°æµå‘åŠ¨ä½œ (The Math behind Flow)

### 1.1 ä»€ä¹ˆæ˜¯ Flow Matching?
ä¸åŒäº Diffusion Model å­¦ä¹ å»å™ªè¿‡ç¨‹ (Denoising Score Matching)ï¼ŒFlow Matching ç›´æ¥å­¦ä¹ ä¸€ä¸ª **ç¡®å®šæ€§çš„å¸¸å¾®åˆ†æ–¹ç¨‹ (ODE)**ï¼Œå®šä¹‰äº†æ¦‚ç‡å¯†åº¦è·¯å¾„ $p_t(x)$ å¦‚ä½•éšæ—¶é—´ $t$ æ¼”å˜ã€‚

æˆ‘ä»¬å®šä¹‰ä¸€ä¸ª **å‘é‡åœº (Vector Field)** $v_t(x)$ï¼Œå®ƒæè¿°äº†æ ·æœ¬åœ¨æ—¶é—´ $t$ çš„ç§»åŠ¨é€Ÿåº¦å’Œæ–¹å‘ã€‚


$$
\frac{dx}{dt} = v_t(x)
$$


- $x_0$: çœŸå®æ•°æ®åˆ†å¸ƒ (Real Data, e.g., æœºå™¨äººçš„æ­£ç¡®åŠ¨ä½œ)ã€‚
- $x_1$: æ ‡å‡†é«˜æ–¯å™ªå£°åˆ†å¸ƒ (Noise, $\mathcal{N}(0, I)$)ã€‚
- **ç›®æ ‡**: æ‰¾åˆ°ä¸€ä¸ªå‘é‡åœº $v_t$ï¼Œä½¿å¾—å½“æˆ‘ä»¬ä»å™ªå£° $x_1$ å‡ºå‘ï¼Œæ²¿ç€è¿™ä¸ªåœºé€†æµè€Œä¸Š (æˆ–é¡ºæµè€Œä¸‹ï¼Œå–å†³äºå®šä¹‰) ç§¯åˆ†åˆ° $t=0$ æ—¶ï¼Œèƒ½å¤Ÿç²¾ç¡®åœ°å˜å› $x_0$ã€‚

### 1.2 ä¸ºä»€ä¹ˆæ¯” Diffusion å¥½?
- **Diffusion**: è½¨è¿¹æ˜¯éšæœºçš„ (Stochastic)ï¼Œåƒå¸ƒæœ—è¿åŠ¨ä¸€æ ·è·Œè·Œæ’æ’åœ°å»å™ªã€‚æ¨ç†æ­¥æ•°å¤š (50-100æ­¥)ã€‚
- **Flow Matching**: æˆ‘ä»¬å¯ä»¥å¼ºåˆ¶æ¨¡å‹å­¦ä¹ ä¸€æ¡ **"ç›´çš„" (Straight)** è½¨è¿¹ã€‚
    - **Optimal Transport (æœ€ä¼˜ä¼ è¾“)**: ç‚¹å¯¹ç‚¹ä¹‹é—´ç›´çº¿æœ€çŸ­ã€‚Flow Matching å¯ä»¥å­¦ä¹ è¿™ç§ç›´çº¿è·¯å¾„ï¼Œä½¿å¾—æ¨ç†æå…¶é«˜æ•ˆ (10æ­¥ä»¥å†…)ã€‚
    - **ç¡®å®šæ€§ä¸ç¨³å®šæ€§**: ç›¸æ¯”äºéšæœºé‡‡æ ·ï¼ŒODE çš„ç¡®å®šæ€§ä½¿å¾—åŠ¨ä½œç”Ÿæˆæ›´åŠ å¹³æ»‘ï¼Œå‡å°‘äº†é«˜é¢‘æŠ–åŠ¨ (Jitter)ï¼Œè¿™å¯¹æœºæ¢°è‡‚æ§åˆ¶è‡³å…³é‡è¦ã€‚

![Flow Matching vs Diffusion](../assets/flow_matching_vs_diffusion.png)
*å›¾ç¤º: Diffusion çš„éšæœºè½¨è¿¹ (å·¦) vs Flow Matching çš„ç›´çº¿è½¨è¿¹ (å³)*

## 2. æ ¸å¿ƒå…¬å¼è¯¦è§£ (Key Formulas)

### 2.1 çº¿æ€§æ’å€¼è·¯å¾„ (Conditional Flow)
ä¸ºäº†è®­ç»ƒæ¨¡å‹ï¼Œæˆ‘ä»¬éœ€è¦æ„é€ ä¸€ä¸ª"æ­£ç¡®ç­”æ¡ˆ"ã€‚å‡è®¾æˆ‘ä»¬å·²çŸ¥ä¸€ä¸ªçœŸå®æ ·æœ¬ $x_0$ å’Œä¸€ä¸ªé‡‡æ ·å™ªå£° $x_1$ï¼Œæˆ‘ä»¬å®šä¹‰ä¸€æ¡è¿æ¥å®ƒä»¬çš„ç›´çº¿è·¯å¾„ï¼š


$$
x_t = (1 - t)x_0 + t x_1, \quad t \in [0, 1]
$$


- å½“ $t=0$ æ—¶ï¼Œ $x_t = x_0$ (æ•°æ®)ã€‚
- å½“ $t=1$ æ—¶ï¼Œ $x_t = x_1$ (å™ªå£°)ã€‚

### 2.2 ç›®æ ‡é€Ÿåº¦ (Target Velocity)
å¯¹ä¸Šé¢çš„è·¯å¾„ $x_t$ å¯¹æ—¶é—´ $t$ æ±‚å¯¼ï¼Œå¾—åˆ°è¯¥è·¯å¾„ä¸Šçš„ç†æƒ³é€Ÿåº¦ $u_t(x|x_1)$ï¼š


$$
\frac{d}{dt} x_t = \frac{d}{dt} \left( (1 - t)x_0 + t x_1 \right) = x_1 - x_0
$$


- **ç‰©ç†å«ä¹‰**: ç›®æ ‡é€Ÿåº¦æ˜¯ä¸€ä¸ªæ’å®šå‘é‡ï¼Œæ–¹å‘ä» $x_0$ æŒ‡å‘ $x_1$ã€‚è¿™éå¸¸ç›´è§‚ï¼šè¦ä»æ•°æ®å˜åˆ°å™ªå£°ï¼Œå°±ä¸€ç›´å¾€å™ªå£°æ–¹å‘èµ°ï¼›åä¹‹äº¦ç„¶ã€‚

### 2.3 æŸå¤±å‡½æ•° (Loss Function)
æˆ‘ä»¬è®­ç»ƒä¸€ä¸ªç¥ç»ç½‘ç»œ $v_\theta(x_t, t, \text{cond})$ æ¥æ‹Ÿåˆè¿™ä¸ªç›®æ ‡é€Ÿåº¦ã€‚è¿™å°±æ˜¯ **Conditional Flow Matching (CFM)** lossï¼š


$$
\mathcal{L}(\theta) = \mathbb{E}_{t, x_0, x_1} \left[ \Vert v_\theta(x_t, t, \text{cond}) - (x_1 - x_0) \Vert^2 \right]
$$


- **è¾“å…¥**:
    - $x_t$: å½“å‰æ—¶åˆ»çš„æ’å€¼çŠ¶æ€ (æ··åˆäº†æ•°æ®å’Œå™ªå£°)ã€‚
    - $t$: å½“å‰æ—¶é—´æ­¥ã€‚
    - $\text{cond}$: å›¾åƒ/è¯­è¨€ç‰¹å¾ (VLM embedding)ã€‚
- **æ ‡ç­¾ (Target)**: $x_1 - x_0$ (å¸¸æ•°å‘é‡)ã€‚
- **ç›´è§‚è§£é‡Š**: æ— è®ºä½ åœ¨è·¯å¾„çš„å“ªä¸ªä½ç½®ï¼Œç½‘ç»œéƒ½åº”è¯¥å‘Šè¯‰ä½ ï¼š"å¾€é‚£ä¸ªæ–¹å‘èµ°ï¼Œå°±èƒ½åˆ°è¾¾ç»ˆç‚¹"ã€‚

## 3. æ¨¡å‹æ¶æ„ (Pseudo-Code)

### 2.1 VLM Backbone (Conditioning)
ä½¿ç”¨ PaliGemma æˆ–ç±»ä¼¼ VLM æå–å¤šæ¨¡æ€ç‰¹å¾ã€‚

```python
class Pi0VLMBackbone(nn.Module):
    def __init__(self, base_vlm):
        super().__init__()
        self.vlm = base_vlm # e.g., PaliGemma-3B
        
    def forward(self, images, text):
        # 1. æå–å›¾åƒå’Œæ–‡æœ¬ç‰¹å¾
        # output: [batch, seq_len, hidden_dim]
        features = self.vlm.extract_features(images, text)
        
        # 2. Pooling æˆ–æå–ç‰¹å®š Token ä½œä¸º Condition
        # å‡è®¾æˆ‘ä»¬å–æœ€åä¸€ä¸ª Token çš„ embedding ä½œä¸ºå…¨å±€ä¸Šä¸‹æ–‡
        global_cond = features[:, -1, :] 
        return global_cond
```

### 2.2 Flow Matching Policy Head
è¿™æ˜¯ä¸€ä¸ª MLP æˆ– Transformerï¼Œé¢„æµ‹â€œé€Ÿåº¦åœºâ€ã€‚

```python
class FlowMatchingPolicy(nn.Module):
    def __init__(self, action_dim, cond_dim, hidden_dim=1024):
        super().__init__()
        # Time Embedding: å°†æ ‡é‡ t æ˜ å°„ä¸ºé«˜ç»´å‘é‡ï¼Œæ•æ‰ç»†ç²’åº¦çš„æ—¶é—´ä¿¡æ¯
        self.time_mlp = nn.Sequential(
            SinusoidalPositionEmbeddings(dim=256),
            nn.Linear(256, 256),
            nn.SiLU()
        )
        
        # è¾“å…¥: å™ªå£°åŠ¨ä½œ(action_dim) + æ—¶é—´embedding(256) + æ¡ä»¶(cond_dim)
        self.net = nn.Sequential(
            nn.Linear(action_dim + 256 + cond_dim, hidden_dim),
            nn.SiLU(), # Swish/SiLU é€šå¸¸æ¯” ReLU æ•ˆæœæ›´å¥½
            nn.Linear(hidden_dim, hidden_dim),
            nn.SiLU(),
            nn.Linear(hidden_dim, hidden_dim),
            nn.SiLU(),
            nn.Linear(hidden_dim, action_dim) # è¾“å‡º dx/dt
        )

    def forward(self, x_t, t, condition):
        # 1. å¤„ç†æ—¶é—´ t
        # t: [batch_size, 1] -> t_emb: [batch_size, 256]
        t_emb = self.time_mlp(t)
        
        # 2. æ‹¼æ¥è¾“å…¥
        # ç®€å•çš„ Concat ç­–ç•¥ï¼Œæ›´é«˜çº§çš„å¯ä»¥ç”¨ AdaLN (Adaptive Layer Norm) æ³¨å…¥æ¡ä»¶
        input_feat = torch.cat([x_t, t_emb, condition], dim=-1)
        
        # 3. é¢„æµ‹å‘é‡åœº (Velocity)
        velocity = self.net(input_feat)
        return velocity
```

## 3. æ¨ç†è¿‡ç¨‹ (Inference / Sampling)
ä½¿ç”¨ ODE Solver (å¦‚ Euler æ–¹æ³•) ä»å™ªå£°ç”ŸæˆåŠ¨ä½œã€‚

```python
@torch.no_grad()
def generate_action(policy, vlm_cond, action_dim, steps=10, cfg_scale=1.0):
    """
    ä»é«˜æ–¯å™ªå£°ç”ŸæˆåŠ¨ä½œï¼Œæ”¯æŒ Classifier-Free Guidance (CFG)
    """
    batch_size = vlm_cond.shape[0]
    
    # 1. é‡‡æ ·åˆå§‹å™ªå£° x_1 ~ N(0, I)
    x_t = torch.randn(batch_size, action_dim, device=device)
    
    # 2. å®šä¹‰æ—¶é—´æ­¥ (ä» 1 åˆ° 0)
    dt = -1.0 / steps 
    times = torch.linspace(1.0, 0.0, steps + 1, device=device)
    
    # 3. ODE Solver å¾ªç¯ (Euler Method)
    for i in range(steps):
        t_curr = times[i]
        
        # é¢„æµ‹å½“å‰ä½ç½®çš„é€Ÿåº¦å‘é‡ v_t
        # CFG: åŒæ—¶è®¡ç®—æœ‰æ¡ä»¶å’Œæ— æ¡ä»¶çš„é€Ÿåº¦
        if cfg_scale > 1.0:
            # æ„é€ æ— æ¡ä»¶è¾“å…¥ (ç©ºæŒ‡ä»¤/ç©ºå›¾åƒ)
            null_cond = torch.zeros_like(vlm_cond) 
            # æ‰¹é‡é¢„æµ‹
            input_cond = torch.cat([vlm_cond, null_cond])
            input_x = torch.cat([x_t, x_t])
            input_t = torch.cat([t_curr, t_curr])
            
            v_cond, v_uncond = policy(input_x, input_t, input_cond).chunk(2)
            
            # ç»„åˆé€Ÿåº¦å‘é‡
            velocity = v_uncond + cfg_scale * (v_cond - v_uncond)
        else:
            velocity = policy(x_t, t_curr, vlm_cond)
        
        # æ›´æ–°ä½ç½®: x_{t+dt} = x_t + v_t * dt
        x_t = x_t + velocity * dt
        
    return x_t
```

## 4. è®­ç»ƒè¿‡ç¨‹ (Training)
Flow Matching çš„ Loss éå¸¸ç›´è§‚ï¼š**å›å½’ç›®æ ‡é€Ÿåº¦**ã€‚
ç›®æ ‡é€Ÿåº¦å°±æ˜¯ä»å™ªå£° $x_1$ æŒ‡å‘çœŸå®æ•°æ® $x_0$ çš„æ–¹å‘ã€‚

```python
def compute_loss(policy, vlm_cond, real_action):
    batch_size = real_action.shape[0]
    
    # 1. é‡‡æ ·æ—¶é—´ t ~ U[0, 1]
    t = torch.rand(batch_size, 1, device=device)
    
    # 2. é‡‡æ ·å™ªå£° x_1 ~ N(0, I)
    noise = torch.randn_like(real_action)
    
    # 3. æ„å»ºä¸­é—´çŠ¶æ€ x_t (Linear Interpolation / Optimal Transport Path)
    # x_t = (1 - t) * x_0 + t * x_1
    # æ³¨æ„: è¿™é‡Œå®šä¹‰ t=0 æ˜¯æ•°æ®, t=1 æ˜¯å™ªå£°
    x_t = (1 - t) * real_action + t * noise
    
    # 4. è®¡ç®—ç›®æ ‡é€Ÿåº¦ (Target Velocity)
    # ä¹Ÿå°±æ˜¯ x_1 - x_0 (æŒ‡å‘å™ªå£°çš„æ–¹å‘? æˆ–è€…åè¿‡æ¥ï¼Œå–å†³äºå®šä¹‰)
    # åœ¨ Conditional Flow Matching (CFM) ä¸­ï¼Œé€šå¸¸ v_target = x_1 - x_0
    target_velocity = noise - real_action 
    
    # 5. æ¨¡å‹é¢„æµ‹é€Ÿåº¦
    pred_velocity = policy(x_t, t, vlm_cond)
    
    # 6. MSE Loss
    loss = F.mse_loss(pred_velocity, target_velocity)
    return loss
```

## 6. ä¸ºä»€ä¹ˆ Pi0 é€‰æ‹© Flow Matching? (Deep Dive)

### 6.1 è¿ç»­æ€§ vs ç¦»æ•£æ€§ (Continuous vs Discrete)
- **RT-1/RT-2 (Discrete)**: å°†åŠ¨ä½œç©ºé—´åˆ‡åˆ†ä¸º 256 ä¸ªæ ¼å­ã€‚
    - *é—®é¢˜*: ä¸¢å¤±ç²¾åº¦ã€‚å¯¹äºçµå·§æ‰‹è¿™ç§éœ€è¦å¾®ç±³çº§æ§åˆ¶çš„ä»»åŠ¡ï¼Œç¦»æ•£åŒ–ä¼šå¯¼è‡´åŠ¨ä½œ"ä¸€å¡ä¸€å¡çš„" (Jitter)ã€‚
- **Pi0 (Continuous)**: ç›´æ¥è¾“å‡ºæµ®ç‚¹æ•°é€Ÿåº¦å‘é‡ã€‚
    - *ä¼˜åŠ¿*: ç†è®ºä¸Šç²¾åº¦æ— é™ï¼ŒåŠ¨ä½œå¹³æ»‘ï¼Œæ›´ç¬¦åˆç‰©ç†ä¸–ç•Œçš„æœ¬è´¨ã€‚

### 6.2 é«˜é¢‘æ§åˆ¶çš„æ•°å­¦åŸºç¡€
- æœºå™¨äººæ§åˆ¶å›è·¯é€šå¸¸æ˜¯ 500Hzã€‚å¦‚æœæ¨¡å‹æ¨ç†éœ€è¦ 100ms (10Hz)ï¼Œä¸­é—´ 490ms éƒ½åœ¨"ç›²è·‘"ã€‚
- Flow Matching çš„ **ODE æ±‚è§£å™¨** ç‰¹æ€§å…è®¸æˆ‘ä»¬åœ¨æ¨ç†æ—¶è¿›è¡Œ **æ—¶é—´æ­¥ç¼©æ”¾ (Time-step Scaling)**ã€‚
    - æˆ‘ä»¬å¯ä»¥åªè·‘ ODE çš„ 1 æ­¥ (Euler Step)ï¼Œè™½ç„¶ç²¾åº¦ç•¥ä½ï¼Œä½†é€Ÿåº¦æå¿«ï¼Œå¯ä»¥å®ç°é«˜é¢‘å“åº”ã€‚
    - ä¹Ÿå¯ä»¥è·‘ 10 æ­¥ï¼Œè·å¾—é«˜ç²¾åº¦åŠ¨ä½œã€‚
    - è¿™ç§ **Compute-Accuracy Trade-off** æ˜¯ Transformer åšä¸åˆ°çš„ã€‚

### 6.3 ä¸ºä»€ä¹ˆæ˜¯ç›´çº¿? (Optimal Transport)
- **Wasserstein Distance**: åœ¨æ¦‚ç‡åˆ†å¸ƒç©ºé—´ä¸­ï¼Œå°†ä¸€ä¸ªåˆ†å¸ƒæ¬è¿åˆ°å¦ä¸€ä¸ªåˆ†å¸ƒçš„"æœ€å°ä»£ä»·"è·¯å¾„å°±æ˜¯ç›´çº¿ (Geodesic)ã€‚
- **OT-CFM**: æˆ‘ä»¬æ„é€ çš„ $x_t = (1-t)x_0 + t x_1$ æ­£æ˜¯ Optimal Transport çš„ä½ç§»æ’å€¼ (Displacement Interpolation)ã€‚
- **Rectified Flow**: è¿™ä¸ Stable Diffusion 3 ä½¿ç”¨çš„ Rectified Flow æ€æƒ³ä¸€è‡´ï¼Œæ—¨åœ¨å°†å¼¯æ›²çš„æ‰©æ•£è·¯å¾„"æ‹‰ç›´"ï¼Œä»è€Œå…è®¸æå°‘æ­¥æ•°çš„æ¨ç† (1-step generation)ã€‚

### 6.4 ODE Solver çš„é€‰æ‹©
- **Euler (1st order)**: æœ€ç®€å•ï¼Œä¸€æ­¥èµ°åˆ°åº•ã€‚$x_{t+dt} = x_t + v_t dt$ã€‚é€Ÿåº¦æœ€å¿«ï¼Œä½†è¯¯å·®æœ€å¤§ã€‚
- **Midpoint / Heun (2nd order)**: å…ˆè¯•æ¢æ€§èµ°åŠæ­¥ï¼Œçœ‹æ–œç‡ï¼Œå†ä¿®æ­£ã€‚ç²¾åº¦æ›´é«˜ï¼Œä½†éœ€è¦ 2 å€çš„ NFE (Number of Function Evaluations)ã€‚
- **RK4 (4th order)**: ç»å…¸çš„é«˜ç²¾åº¦æ±‚è§£å™¨ï¼Œéœ€è¦ 4 å€ NFEã€‚
- **ç»“è®º**: åœ¨æœºå™¨äººæ§åˆ¶ä¸­ï¼Œé€šå¸¸ä½¿ç”¨ **Euler** (è¿½æ±‚æé€Ÿ) æˆ– **Heun** (è¿½æ±‚å¹³è¡¡)ã€‚ç”±äº Flow Matching è®­ç»ƒå‡ºçš„å‘é‡åœºéå¸¸å¹³æ»‘ (ç›´çº¿)ï¼ŒEuler æ–¹æ³•é€šå¸¸å·²ç»è¶³å¤Ÿå¥½ç”¨ã€‚



---

\newpage

# ç¬¬9ç«  FAST åŠ¨ä½œåºåˆ—ç¼–ç 


> [!IMPORTANT]
> **FAST** (Frequency-space Action Sequence Tokenizationï¼Œé¢‘åŸŸåŠ¨ä½œåºåˆ— Token åŒ–) æ˜¯ **Physical Intelligence** å¼€å‘çš„ä¸€ç§é«˜æ•ˆåŠ¨ä½œ Token åŒ–æ–¹æ³•ï¼Œä¸“ä¸ºè§£å†³ VLA æ¨¡å‹ä¸­è¿ç»­åŠ¨ä½œè½¬æ¢ä¸ºç¦»æ•£ token çš„éš¾é¢˜è€Œè®¾è®¡ã€‚

## 1. æ¦‚è¿°
åœ¨ VLA æ¨¡å‹ä¸­ï¼ŒåŠ¨ä½œçš„è¡¨ç¤ºæ–¹å¼è‡³å…³é‡è¦ã€‚ä¼ ç»Ÿçš„ç¦»æ•£åŒ–æ–¹æ³•ï¼ˆå¦‚ç®€å•åˆ†æ¡¶ï¼‰åœ¨å¤„ç†é«˜é¢‘ã€çµå·§çš„æœºå™¨äººæ“ä½œæ—¶æ•ˆæœä¸ä½³ã€‚FAST é€šè¿‡**ç¦»æ•£ä½™å¼¦å˜æ¢ (DCT)** å’Œ**å­—èŠ‚å¯¹ç¼–ç  (BPE)** çš„ç»„åˆï¼Œå®ç°äº†é«˜æ•ˆçš„åŠ¨ä½œå‹ç¼©å’Œ token åŒ–ã€‚

-   **å¼€å‘è€…**: Physical Intelligence
-   **è®ºæ–‡**: [FAST: Efficient Action Tokenization for VLA Models (arXiv:2501.09747)](https://arxiv.org/abs/2501.09747)
-   **æ ¸å¿ƒç›®æ ‡**: å°†è¿ç»­çš„æœºå™¨äººåŠ¨ä½œåºåˆ—å‹ç¼©ä¸ºç´§å‡‘çš„ç¦»æ•£ tokenï¼ŒåŒæ—¶ä¿æŒé«˜é¢‘åŠ¨ä½œçš„ç²¾åº¦ã€‚
-   **åº”ç”¨**: å·²æˆåŠŸé›†æˆåˆ° **OpenVLA** ä¸­ï¼Œæ˜¾è‘—æå‡è®­ç»ƒé€Ÿåº¦ï¼ˆ**æœ€é«˜ 5 å€åŠ é€Ÿ**ï¼‰ã€‚

## 2. æ ¸å¿ƒé—®é¢˜ï¼šä¸ºä»€ä¹ˆéœ€è¦ FASTï¼Ÿ
ä¼ ç»Ÿ VLA æ¨¡å‹ä¸­çš„åŠ¨ä½œ Token åŒ–é¢ä¸´å‡ ä¸ªæŒ‘æˆ˜ï¼š

### 2.1. ç®€å•åˆ†æ¡¶çš„å±€é™æ€§
-   **Token æ•°é‡çˆ†ç‚¸**: å¯¹äº 7-DoF æœºæ¢°è‡‚ï¼Œå¦‚æœæ¯ä¸ªå…³èŠ‚åˆ†æˆ 256 ä¸ª binï¼Œæ€» token æ•°å¯è¾¾ 256^7ï¼Œå¯¼è‡´éš¾ä»¥å­¦ä¹ ã€‚
-   **é«˜é¢‘åŠ¨ä½œä¸¢å¤±**: ç®€å•åˆ†æ¡¶æ— æ³•æ•æ‰å¹³æ»‘ã€é«˜é¢‘çš„è½¨è¿¹å˜åŒ–ï¼ˆå¦‚å¿«é€ŸæŠ˜å è¡£ç‰©ã€ç²¾ç»†æŠ“å–ï¼‰ã€‚

### 2.2. è¿ç»­åŠ¨ä½œçš„è‡ªç›¸å…³æ€§
-   æœºå™¨äººåŠ¨ä½œåœ¨æ—¶é—´ä¸Šé«˜åº¦è‡ªç›¸å…³ï¼ˆt å’Œ t+1 çš„åŠ¨ä½œéå¸¸ç›¸ä¼¼ï¼‰ã€‚
-   è‡ªå›å½’æ¨¡å‹ï¼ˆå¦‚ Transformerï¼‰åœ¨å¤„ç†è¿™ç§é«˜ç›¸å…³æ€§æ•°æ®æ—¶æ•ˆç‡ä½ä¸‹ã€‚

FAST é€šè¿‡**é¢‘åŸŸå˜æ¢**è§£å†³äº†è¿™äº›é—®é¢˜ã€‚

## 3. FAST çš„æ ¸å¿ƒæŠ€æœ¯

### 3.1. ç¦»æ•£ä½™å¼¦å˜æ¢ (DCT)
FAST å€Ÿé‰´äº† **JPEG å›¾åƒå‹ç¼©**çš„æ€æƒ³ï¼Œä½¿ç”¨ DCT å°†æ—¶åŸŸçš„åŠ¨ä½œåºåˆ—è½¬æ¢åˆ°é¢‘åŸŸã€‚

#### 3.1.1. ä¸ºä»€ä¹ˆéœ€è¦ DCTï¼Ÿ
æœºå™¨äººåŠ¨ä½œåºåˆ—æœ‰ä¸¤ä¸ªå…³é”®ç‰¹æ€§ï¼š
1.  **æ—¶é—´å¹³æ»‘æ€§**: ç›¸é‚»æ—¶åˆ»çš„å…³èŠ‚è§’åº¦å˜åŒ–å¾ˆå°ï¼ˆé«˜è‡ªç›¸å…³æ€§ï¼‰ã€‚
2.  **èƒ½é‡é›†ä¸­**: å¤§éƒ¨åˆ†"ä¿¡æ¯"é›†ä¸­åœ¨ä½é¢‘å˜åŒ–ï¼ˆç¼“æ…¢ç§»åŠ¨ï¼‰ï¼Œé«˜é¢‘æŠ–åŠ¨æ˜¯å™ªå£°ã€‚

**ç›´æ¥ Token åŒ–çš„é—®é¢˜**:
-   å¦‚æœç›´æ¥å¯¹æ¯ä¸ªæ—¶é—´æ­¥çš„æ¯ä¸ªå…³èŠ‚åˆ†æ¡¶ï¼Œä¼šäº§ç”Ÿå¤§é‡**å†—ä½™ token**ï¼ˆå› ä¸ºè¿ç»­æ—¶åˆ»éå¸¸ç›¸ä¼¼ï¼‰ã€‚
-   è‡ªå›å½’æ¨¡å‹ï¼ˆTransformerï¼‰éœ€è¦é€ä¸ªé¢„æµ‹è¿™äº›é«˜åº¦ç›¸å…³çš„ tokenï¼Œ**æå…¶ä½æ•ˆ**ã€‚

**DCT çš„è§£å†³æ–¹æ¡ˆ**:
-   å°†æ—¶é—´åºåˆ—ä»**æ—¶åŸŸ**è½¬æ¢åˆ°**é¢‘åŸŸ**ï¼Œåˆ†ç¦»å‡ºä½é¢‘ï¼ˆä¸»è¦ä¿¡æ¯ï¼‰å’Œé«˜é¢‘ï¼ˆå™ªå£°ï¼‰ã€‚
-   åªä¿ç•™**ä½é¢‘ç³»æ•°**ï¼Œå¤§å¹…å‡å°‘æ•°æ®é‡ï¼ŒåŒæ—¶ä¿ç•™åŠ¨ä½œçš„æœ¬è´¨ç‰¹å¾ã€‚

#### 3.1.2. DCT å·¥ä½œåŸç†
**è¾“å…¥**: ä¸€æ®µåŠ¨ä½œåºåˆ—ï¼Œä¾‹å¦‚ 10 ä¸ªæ—¶é—´æ­¥çš„ 7-DoF å…³èŠ‚è§’åº¦ï¼š
```
[ [Î¸1_t0, Î¸2_t0, ..., Î¸7_t0],
  [Î¸1_t1, Î¸2_t1, ..., Î¸7_t1],
  ...
  [Î¸1_t9, Î¸2_t9, ..., Î¸7_t9] ]  # å½¢çŠ¶: [10, 7]
```

**æ­¥éª¤**:
1.  **å¯¹æ¯ä¸ªå…³èŠ‚ç»´åº¦ç‹¬ç«‹åº”ç”¨ DCT**:
    -   DCT å°† 10 ä¸ªæ—¶é—´æ­¥çš„å…³èŠ‚è§’åº¦åˆ†è§£ä¸º 10 ä¸ªé¢‘ç‡åˆ†é‡ã€‚
    -   å…¬å¼: `X_k = Î£(x_n * cos(Ï€/10 * (n + 0.5) * k))`, k=0,1,...,9
    -   `X_0` æ˜¯ DC åˆ†é‡ï¼ˆå¹³å‡å€¼ï¼‰ï¼Œ`X_1, X_2` æ˜¯ä½é¢‘ï¼Œ`X_8, X_9` æ˜¯é«˜é¢‘ã€‚

2.  **ä½é¢‘ä¿ç•™**:
    -   ç”±äºåŠ¨ä½œå¹³æ»‘ï¼Œèƒ½é‡ä¸»è¦åœ¨å‰ K ä¸ªç³»æ•°ï¼ˆä¾‹å¦‚ K=4ï¼‰ã€‚
    -   ä¸¢å¼ƒå 6 ä¸ªé«˜é¢‘ç³»æ•°ï¼Œ**å‹ç¼©æ¯” 2.5:1**ï¼ˆ10 â†’ 4ï¼‰ã€‚

3.  **é‡åŒ–**:
    -   å°†æµ®ç‚¹ DCT ç³»æ•°é‡åŒ–ä¸ºæ•´æ•°ï¼ˆä¾‹å¦‚ 0-255ï¼‰ï¼Œæ–¹ä¾¿åç»­ token åŒ–ã€‚

**ç±»æ¯” JPEG**:
-   **JPEG å‹ç¼©å›¾åƒ**: å¯¹ 8Ã—8 åƒç´ å—åš 2D DCTï¼Œä¿ç•™ä½é¢‘ï¼Œä¸¢å¼ƒé«˜é¢‘ï¼ˆäººçœ¼ä¸æ•æ„Ÿçš„ç»†èŠ‚ï¼‰ã€‚
-   **FAST å‹ç¼©åŠ¨ä½œ**: å¯¹æ—¶é—´åºåˆ—åš 1D DCTï¼Œä¿ç•™ä½é¢‘ï¼ˆç¼“æ…¢ç§»åŠ¨ï¼‰ï¼Œä¸¢å¼ƒé«˜é¢‘ï¼ˆæŠ–åŠ¨å™ªå£°ï¼‰ã€‚
-   **æœ¬è´¨**: éƒ½æ˜¯åˆ©ç”¨**ä¿¡å·çš„é¢‘åŸŸç¨€ç–æ€§**è¿›è¡Œå‹ç¼©ã€‚

#### 3.1.3. ä¸ºä»€ä¹ˆ DCT è€Œä¸æ˜¯ FFTï¼Ÿ
-   **DCT åªæœ‰å®æ•°**: æ›´é€‚åˆå®å€¼ä¿¡å·ï¼ˆå…³èŠ‚è§’åº¦ï¼‰ï¼ŒFFT ä¼šäº§ç”Ÿå¤æ•°ã€‚
-   **è¾¹ç•Œå‹å¥½**: DCT å‡è®¾ä¿¡å·å¯¹ç§°å»¶æ‹“ï¼Œé¿å…è¾¹ç•Œä¸è¿ç»­å¯¼è‡´çš„é«˜é¢‘ä¼ªå½±ã€‚
-   **å‹ç¼©æ•ˆç‡**: DCT çš„èƒ½é‡é›†ä¸­æ€§æ¯” FFT æ›´å¥½ï¼ˆè¿™ä¹Ÿæ˜¯ JPEG é€‰æ‹© DCT çš„åŸå› ï¼‰ã€‚

### 3.2. å­—èŠ‚å¯¹ç¼–ç  (BPE)
ç»è¿‡ DCT é‡åŒ–åï¼Œæˆ‘ä»¬å¾—åˆ°ä¸€ä¸ªæ•´æ•°åºåˆ—ï¼Œä¾‹å¦‚ï¼š
```
[42, 15, 3, 1, 0, 0, 0]  # 7-DoFï¼Œæ¯ä¸ªå…³èŠ‚çš„å‰ K=4 ä¸ª DCT ç³»æ•°
```
å¯¹äº 10 ä¸ªæ—¶é—´æ­¥ï¼Œä¼šæœ‰ `10 Ã— 7 Ã— 4 = 280` ä¸ªæ•´æ•°å€¼ã€‚è¿™ä»ç„¶å¤ªå¤šï¼

#### 3.2.1. ä¸ºä»€ä¹ˆéœ€è¦ BPEï¼Ÿ
-   **ç»Ÿè®¡æ¨¡å¼**: DCT ç³»æ•°çš„åˆ†å¸ƒä¸æ˜¯å‡åŒ€çš„ï¼ŒæŸäº›**ç³»æ•°ç»„åˆ**ä¼šé¢‘ç¹å‡ºç°ã€‚
-   **å‡å°‘ token æ•°**: BPE èƒ½å°†å¸¸è§çš„ç³»æ•°å¯¹åˆå¹¶ä¸ºå•ä¸ª tokenï¼Œå¤§å¹…å‡å°‘åºåˆ—é•¿åº¦ã€‚

#### 3.2.2. BPE å·¥ä½œåŸç†
**åˆå§‹åŒ–**:
-   è¯æ±‡è¡¨ = `{0, 1, 2, ..., 255}` ï¼ˆæ‰€æœ‰å¯èƒ½çš„é‡åŒ– DCT ç³»æ•°ï¼‰ã€‚

**è¿­ä»£åˆå¹¶**:
1.  **ç»Ÿè®¡**: åœ¨è®­ç»ƒæ•°æ®ä¸­ï¼Œç»Ÿè®¡æ‰€æœ‰ç›¸é‚»ç³»æ•°å¯¹çš„é¢‘ç‡ã€‚
    -   ä¾‹å¦‚ï¼Œ`[42, 15]` è¿™ä¸ªç»„åˆå‡ºç°äº† 10000 æ¬¡ï¼ˆæœ€é«˜é¢‘ï¼‰ã€‚
2.  **åˆå¹¶**: å°† `[42, 15]` åˆå¹¶ä¸ºä¸€ä¸ªæ–° token `token_256`ã€‚
    -   è¯æ±‡è¡¨æ›´æ–°: `{0, 1, ..., 255, 256=[42,15]}`
3.  **é‡å¤**: ä¸æ–­æ‰¾æœ€é«˜é¢‘çš„å¯¹ï¼Œåˆå¹¶ï¼Œç›´åˆ°è¯æ±‡è¡¨è¾¾åˆ°ç›®æ ‡å¤§å°ï¼ˆä¾‹å¦‚ 8000ï¼‰ã€‚

**æ•ˆæœ**:
-   åŸå§‹åºåˆ—: `[42, 15, 3, 1, 0, 0, 0]` (7 ä¸ª token)
-   BPE å: `[token_256, token_512, 0]` (3 ä¸ª token)
-   **å‹ç¼©æ¯”**: 2.3:1

**ç±»æ¯” GPT çš„ BPE**:
-   **GPT æ–‡æœ¬ BPE**: å°†å¸¸è§çš„å­—æ¯ç»„åˆï¼ˆå¦‚ "ing", "the"ï¼‰åˆå¹¶ä¸ºå•ä¸ª tokenï¼Œå‡å°‘åºåˆ—é•¿åº¦ã€‚
    -   ä¾‹: "running" â†’ `["run", "ning"]` è€Œä¸æ˜¯ 7 ä¸ªå­—æ¯ã€‚
-   **FAST åŠ¨ä½œ BPE**: å°†å¸¸è§çš„ DCT ç³»æ•°ç»„åˆåˆå¹¶ä¸ºå•ä¸ª tokenï¼Œå‡å°‘åŠ¨ä½œåºåˆ—é•¿åº¦ã€‚
    -   ä¾‹: `[42, 15]` â†’ `token_256`
-   **æœ¬è´¨**: éƒ½æ˜¯åŸºäº**ç»Ÿè®¡é¢‘ç‡**çš„æ•°æ®å‹ç¼©ï¼Œåˆ©ç”¨æ•°æ®çš„**å±€éƒ¨ç›¸å…³æ€§**ã€‚

#### 3.2.3. ä¸ºä»€ä¹ˆ BPE æœ‰æ•ˆï¼Ÿ
-   **æœºå™¨äººåŠ¨ä½œçš„æ¨¡å¼**: æŸäº›åŠ¨ä½œæ¨¡å¼ï¼ˆå¦‚ "æŠ“å–+æèµ·"ï¼‰çš„ DCT ç³»æ•°æ¨¡å¼ä¼šé‡å¤å‡ºç°ã€‚
-   **å‡å°‘å†—ä½™**: BPE èƒ½è‡ªåŠ¨å‘ç°è¿™äº›æ¨¡å¼ï¼Œå¹¶ç”¨å•ä¸ª token è¡¨ç¤ºï¼Œ**é¿å…é‡å¤ç¼–ç **ã€‚
-   **ä¿æŒè¯­ä¹‰**: é«˜é¢‘çš„ç³»æ•°ç»„åˆé€šå¸¸å¯¹åº”æœ‰æ„ä¹‰çš„åŠ¨ä½œç‰‡æ®µï¼ŒBPE ä¿ç•™äº†è¿™ç§è¯­ä¹‰ç»“æ„ã€‚

### 3.3. FAST+ (Universal Tokenizer)
FAST+ æ˜¯åœ¨ **100 ä¸‡+çœŸå®æœºå™¨äººåŠ¨ä½œåºåˆ—**ä¸Šé¢„è®­ç»ƒçš„é€šç”¨ token åŒ–å™¨ã€‚
-   **è·¨å¹³å°**: é€‚ç”¨äºä¸åŒçš„æœºå™¨äººï¼ˆæœºæ¢°è‡‚ã€äººå½¢æœºå™¨äººã€ç§»åŠ¨æœºå™¨äººï¼‰ã€‚
-   **è·¨é¢‘ç‡**: é€‚åº”ä¸åŒçš„æ§åˆ¶é¢‘ç‡ï¼ˆ10Hz åˆ° 100Hzï¼‰ã€‚
-   **å¼€ç®±å³ç”¨**: æ— éœ€ä¸ºæ¯ä¸ªæ–°ä»»åŠ¡é‡æ–°è®­ç»ƒ tokenizerã€‚

## 4. FAST çš„ä¼˜åŠ¿
| ç‰¹æ€§ | ç®€å•åˆ†æ¡¶ | FAST (DCT + BPE) |
| :--- | :--- | :--- |
| **Token æ•°é‡** | é«˜ï¼ˆ256^7ï¼‰| **ä½ï¼ˆ2-3 ä¸ª token/åºåˆ—ï¼‰** |
| **é«˜é¢‘ç²¾åº¦** | å·®ï¼ˆæŠ–åŠ¨ï¼‰| **å¼ºï¼ˆå¹³æ»‘ï¼‰** |
| **è®­ç»ƒé€Ÿåº¦** | æ…¢ | **å¿«ï¼ˆ5 å€åŠ é€Ÿï¼‰** |
| **æ³›åŒ–èƒ½åŠ›** | å¼± | **å¼ºï¼ˆFAST+ è·¨ä»»åŠ¡æ³›åŒ–ï¼‰** |

## 5. åœ¨ OpenVLA ä¸­çš„åº”ç”¨
FAST å·²è¢«é›†æˆåˆ° **OpenVLA** æ¡†æ¶ä¸­ï¼š
-   **è®­ç»ƒ**: ä½¿ç”¨ FAST tokenizer å°† Open X-Embodiment æ•°æ®é›†ä¸­çš„åŠ¨ä½œåºåˆ— token åŒ–ã€‚
-   **æ¨ç†**: ç”Ÿæˆçš„ token é€šè¿‡é€† DCT è½¬æ¢å›è¿ç»­åŠ¨ä½œã€‚
-   **æ•ˆæœ**: åœ¨æŠ˜å è¡£ç‰©ã€æ¸…ç†æ¡Œå­ç­‰é«˜é¢‘ä»»åŠ¡ä¸Šï¼ŒæˆåŠŸç‡æå‡ **30-50%**ã€‚

## 6. ä¸å…¶ä»–åŠ¨ä½œè¡¨ç¤ºçš„å¯¹æ¯”
| æ–¹æ³• | åŸç† | ä¼˜ç‚¹ | ç¼ºç‚¹ |
| :--- | :--- | :--- | :--- |
| **åˆ†æ¡¶ (Binning)** | å°†è¿ç»­å€¼åˆ†æˆç¦»æ•£åŒºé—´ | ç®€å• | Token çˆ†ç‚¸ï¼Œç²¾åº¦å·® |
| **æ‰©æ•£ (Diffusion)** | é€šè¿‡å»å™ªç”ŸæˆåŠ¨ä½œ | å¹³æ»‘ï¼Œé«˜ç²¾åº¦ | æ¨ç†æ…¢ï¼ˆå¤šæ­¥å»å™ªï¼‰|
| **æµåŒ¹é… (Flow Matching)** | ODE æ±‚è§£å™¨ç”Ÿæˆè½¨è¿¹ | å¿«é€Ÿï¼Œé«˜è´¨é‡ | éœ€è¦é¢å¤–è®­ç»ƒå¤´ |
| **FAST (DCT + BPE)** | é¢‘åŸŸå‹ç¼© + Token åŒ– | **å¿«é€Ÿï¼Œå…¼å®¹è‡ªå›å½’æ¨¡å‹** | éœ€è¦é¢„è®­ç»ƒ tokenizer |

## 7. é¢è¯•è¦ç‚¹
-   **DCT æ˜¯æ ¸å¿ƒ**: è®°ä½ "åƒ JPEG å‹ç¼©å›¾ç‰‡ä¸€æ ·å‹ç¼©åŠ¨ä½œè½¨è¿¹"ã€‚
-   **BPE è¿›ä¸€æ­¥å‹ç¼©**: ç±»ä¼¼ GPT çš„ token åŒ–ï¼Œå°† DCT ç³»æ•°å‹ç¼©ä¸ºå°‘é‡ tokenã€‚
-   **5 å€åŠ é€Ÿ**: FAST ä½¿ OpenVLA çš„è®­ç»ƒé€Ÿåº¦æå‡ 5 å€ã€‚
-   **FAST+ æ˜¯é€šç”¨ tokenizer**: åœ¨ 100 ä¸‡+çœŸå®æœºå™¨äººæ•°æ®ä¸Šé¢„è®­ç»ƒï¼Œè·¨å¹³å°æ³›åŒ–ã€‚
-   **é€‚åˆè‡ªå›å½’æ¨¡å‹**: FAST çš„ token è¾“å‡ºå¯ä»¥ç›´æ¥å–‚ç»™ Transformerï¼Œæ— éœ€ä¿®æ”¹æ¶æ„ã€‚

## 8. å‚è€ƒèµ„æº
-   **è®ºæ–‡**: [FAST: Efficient Action Tokenization for VLA Models (arXiv:2501.09747)](https://arxiv.org/abs/2501.09747)
-   **å®˜æ–¹åšå®¢**: [Physical Intelligence - FAST](https://physicalintelligence.company/blog/fast)
-   **GitHub**: [OpenVLA](https://github.com/openvla/openvla)
-   **Hugging Face**: [FAST+ Tokenizer](https://huggingface.co/pi0/FAST-plus)


\newpage

# ç¬¬ä¸‰éƒ¨åˆ†ï¼šè®­ç»ƒæŠ€æœ¯ä¸ä¼˜åŒ–


\newpage

# ç¬¬10ç«  å‚æ•°é«˜æ•ˆå¾®è°ƒ (PEFT/LoRA)


åœ¨ VLA æ—¶ä»£ï¼Œæˆ‘ä»¬é€šå¸¸åŸºäº 7B+ çš„å¤§æ¨¡å‹è¿›è¡Œå¾®è°ƒã€‚å…¨é‡å¾®è°ƒ (Full Fine-tuning) æå…¶æ˜‚è´µï¼Œå› æ­¤å‚æ•°é«˜æ•ˆå¾®è°ƒ (PEFT) æˆä¸ºäº†å¿…ä¿®è¯¾ã€‚

## 0. ä¸»è¦æ•¸å­¸æ€æƒ³ (Main Mathematical Idea)

> **ç¬¬ä¸€æ€§åŸç†**: **Redundancy of Information (ä¿¡æ¯çš„å†—ä½™ / Intrinsic Dimension)**

ä¸€ä¸ªæ‹¥æœ‰ 70 äº¿å‚æ•°çš„é€šç”¨æ¨¡å‹ï¼Œåœ¨å­¦ä¹ ä¸€ä¸ªç‰¹å®šæŠ€èƒ½ï¼ˆå¦‚"æ‹¿èµ·æ¯å­"ï¼‰æ—¶ï¼Œå¹¶ä¸éœ€è¦æ”¹å˜æ‰€æœ‰ 70 äº¿ä¸ªè‡ªç”±åº¦ã€‚ä»»åŠ¡çš„æœ¬è´¨å˜åŒ–é€šå¸¸å‘ç”Ÿåœ¨æä½ç»´çš„å­ç©ºé—´ä¸­ã€‚

- **æ ¸å¿ƒæ•°å­¦å·¥å…·**: **Low-Rank Matrix Decomposition (ä½ç§©çŸ©é˜µåˆ†è§£ / SVD)**ã€‚
- **è§£é¢˜é€»è¾‘**:
    1.  **å‡è®¾**: æƒé‡çŸ©é˜µçš„å˜åŒ–é‡ $\Delta W$ æ˜¯ä½ç§©çš„ (Low Rank)ã€‚å³ $\text{rank}(\Delta W) \ll \min(d, k)$ã€‚
    2.  **åˆ†è§£**: ä»»ä½•ä½ç§©çŸ©é˜µéƒ½å¯ä»¥åˆ†è§£ä¸ºä¸¤ä¸ªå°çŸ©é˜µçš„ä¹˜ç§¯ ($B \times A$)ã€‚
    3.  **é«˜æ•ˆ**: æˆ‘ä»¬ä¸ç›´æ¥è®­ç»ƒå·¨å¤§çš„ $\Delta W$ ($d \times k$)ï¼Œè€Œæ˜¯è®­ç»ƒå¾®å°çš„ $A$ å’Œ $B$ ($r \times (d+k)$)ã€‚è¿™å°±åƒç”¨å‡ ä¸ªä¸»æˆåˆ†ï¼ˆPrincipal Componentsï¼‰æ¥è¿‘ä¼¼å¤æ‚çš„å˜æ¢ã€‚

## 1. LoRA (Low-Rank Adaptation)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    LoRA æ¶æ„ç¤ºæ„å›¾                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚         è¾“å…¥ x                                                  â”‚
â”‚           â”‚                                                     â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”                                               â”‚
â”‚     â”‚           â”‚                                               â”‚
â”‚     â–¼           â–¼                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”                                            â”‚
â”‚  â”‚  Wâ‚€  â”‚   â”‚  A   â”‚  â† ä½ç§©çŸ©é˜µ (r << d)                       â”‚
â”‚  â”‚      â”‚   â”‚ rÃ—k  â”‚    å¯è®­ç»ƒ                                  â”‚
â”‚  â”‚ dÃ—k  â”‚   â””â”€â”€â”¬â”€â”€â”€â”˜                                            â”‚
â”‚  â”‚      â”‚      â”‚                                                â”‚
â”‚  â”‚ å†»ç»“ â”‚      â–¼                                                â”‚
â”‚  â””â”€â”€â”¬â”€â”€â”€â”˜   â”Œâ”€â”€â”€â”€â”€â”€â”                                            â”‚
â”‚     â”‚       â”‚  B   â”‚  â† ä½ç§©çŸ©é˜µ                                â”‚
â”‚     â”‚       â”‚ dÃ—r  â”‚    å¯è®­ç»ƒ                                  â”‚
â”‚     â”‚       â””â”€â”€â”¬â”€â”€â”€â”˜                                            â”‚
â”‚     â”‚          â”‚                                                â”‚
â”‚     â”‚    Î”W = BÂ·A                                               â”‚
â”‚     â”‚          â”‚                                                â”‚
â”‚     â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                                                â”‚
â”‚          â”‚  W = Wâ‚€ + Î±Â·BA                                       â”‚
â”‚          â–¼                                                      â”‚
â”‚        è¾“å‡º h                                                   â”‚
â”‚                                                                 â”‚
â”‚  å‚æ•°é‡: dÃ—k (å†»ç»“) + rÃ—(d+k) (è®­ç»ƒ) â‰ˆ 0.1% ~ 1%                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.1. æ ¸å¿ƒæ€æƒ³
å¤§æ¨¡å‹çš„æƒé‡çŸ©é˜µ $W \in \mathbb{R}^{d \times k}$ è™½ç„¶å‚æ•°å¾ˆå¤šï¼Œä½†åœ¨ç‰¹å®šä»»åŠ¡ (å¦‚æœºå™¨äººæ§åˆ¶) ä¸Šï¼Œå…¶**å†…åœ¨ç»´åº¦ (Intrinsic Dimension)** å…¶å®å¾ˆä½ã€‚
æˆ‘ä»¬ä¸éœ€è¦æ›´æ–°æ•´ä¸ª $W$ï¼Œåªéœ€è¦å­¦ä¹ ä¸€ä¸ªä½ç§©çš„å¢é‡çŸ©é˜µ $\Delta W$ã€‚

### 1.2. æ•°å­¦åŸç†
å‡è®¾é¢„è®­ç»ƒæƒé‡ä¸º $W_0$ï¼Œå¾®è°ƒåçš„æƒé‡ä¸º $W_0 + \Delta W$ã€‚
æˆ‘ä»¬å°† $\Delta W$ åˆ†è§£ä¸ºä¸¤ä¸ªä½ç§©çŸ©é˜µ $A$ å’Œ $B$ çš„ä¹˜ç§¯ï¼š


$$
W = W_0 + \Delta W = W_0 + B A
$$

å…¶ä¸­ï¼š
- $B \in \mathbb{R}^{d \times r}, A \in \mathbb{R}^{r \times k}$
- $r \ll \min(d, k)$ æ˜¯ç§© (Rank)ï¼Œé€šå¸¸å– 8, 16, 32ã€‚
- **å‚æ•°é‡å¯¹æ¯”**: $d \times k$ (å…¨é‡) vs $r \times (d + k)$ (LoRA)ã€‚å¯¹äº 7B æ¨¡å‹ï¼ŒLoRA å‚æ•°é‡é€šå¸¸ä¸åˆ° 1%ã€‚

### 1.3. è®­ç»ƒä¸æ¨ç†
- **åˆå§‹åŒ–**: $A$ ä½¿ç”¨é«˜æ–¯åˆå§‹åŒ–ï¼Œ$B$ åˆå§‹åŒ–ä¸º 0ã€‚è¿™æ ·åˆå§‹çŠ¶æ€ä¸‹ $\Delta W = 0$ï¼Œæ¨¡å‹è¾“å‡ºä¸é¢„è®­ç»ƒæ¨¡å‹ä¸€è‡´ã€‚
- **è®­ç»ƒ**: å†»ç»“ $W_0$ï¼Œåªæ›´æ–° $A$ å’Œ $B$ã€‚
- **æ¨ç†**: å¯ä»¥å°† $BA$ åŠ å›åˆ° $W_0$ ä¸­ (Merge)ï¼Œæ¨ç†é€Ÿåº¦ä¸åŸæ¨¡å‹å®Œå…¨ä¸€è‡´ï¼Œæ— é¢å¤–å»¶è¿Ÿã€‚


$$
W_{merged} = W_0 + \alpha \cdot BA
$$


  ($\alpha$ æ˜¯ç¼©æ”¾ç³»æ•°ï¼Œé€šå¸¸ $\alpha/r$ ç”¨äºå½’ä¸€åŒ–)ã€‚

---

## 2. QLoRA (Quantized LoRA)

### 2.1. ç—›ç‚¹
LoRA è™½ç„¶å‡å°‘äº†å¯è®­ç»ƒå‚æ•°ï¼Œä½†**åŸºç¡€æ¨¡å‹ $W_0$ ä¾ç„¶éœ€è¦ä»¥ FP16 åŠ è½½åˆ°æ˜¾å­˜ä¸­**ã€‚å¯¹äº 65B çš„æ¨¡å‹ï¼Œå…‰åŠ è½½å°±éœ€è¦ 130GB æ˜¾å­˜ï¼Œå•å¡ 4090 æ ¹æœ¬è·‘ä¸åŠ¨ã€‚

### 2.2. æ ¸å¿ƒåˆ›æ–°
QLoRA ç»“åˆäº† **4-bit é‡åŒ–** å’Œ **LoRA**ï¼Œä½¿å¾— 65B æ¨¡å‹å¯ä»¥åœ¨ 48GB æ˜¾å­˜ä¸Šå¾®è°ƒã€‚

1.  **4-bit NormalFloat (NF4)**: ä¸€ç§ç†è®ºæœ€ä¼˜çš„ 4-bit é‡åŒ–æ•°æ®ç±»å‹ï¼Œä¸“é—¨é’ˆå¯¹æ­£æ€åˆ†å¸ƒçš„æƒé‡è®¾è®¡ã€‚
2.  **Double Quantization**: å¯¹é‡åŒ–å¸¸æ•° (Quantization Constants) å†è¿›è¡Œä¸€æ¬¡é‡åŒ–ï¼Œè¿›ä¸€æ­¥èŠ‚çœæ˜¾å­˜ (æ¯å‚æ•°å¹³å‡èŠ‚çœ 0.37 bit)ã€‚
3.  **Paged Optimizers**: åˆ©ç”¨ CPU å†…å­˜æ¥ç¼“å­˜ä¼˜åŒ–å™¨çŠ¶æ€ (Optimizer States)ï¼Œé˜²æ­¢æ˜¾å­˜ OOMã€‚

### 2.3. æ˜¾å­˜è®¡ç®— (7B Model)
- **Full Fine-tuning (Adam)**: ~112 GB (æƒé‡+æ¢¯åº¦+ä¼˜åŒ–å™¨çŠ¶æ€)
- **LoRA (FP16)**: ~16 GB (æƒé‡) + ~1 GB (LoRA) = ~17 GB
- **QLoRA (4-bit)**: ~4 GB (æƒé‡) + ~1 GB (LoRA) = ~5 GB (å¯ä»¥åœ¨ RTX 3060 ä¸Šè·‘ï¼)

---

## 3. å…¶ä»– PEFT æ–¹æ³•

### 3.1. Adapters (Houlsby et al.)
- åœ¨ Transformer çš„æ¯ä¸€å±‚ä¸­æ’å…¥å°çš„å…¨è¿æ¥ç½‘ç»œ (Adapter Layers)ã€‚
- **ç¼ºç‚¹**: å¢åŠ äº†æ¨ç†å»¶è¿Ÿ (å› ä¸ºæ˜¯ä¸²è¡Œçš„å±‚)ï¼Œæ— æ³•åƒ LoRA é‚£æ ·åˆå¹¶æƒé‡ã€‚

### 3.2. Prefix Tuning / P-Tuning
- åœ¨ Input Token å‰é¢æ‹¼æ¥ä¸€ç»„å¯å­¦ä¹ çš„ Virtual Tokensã€‚
- **ç¼ºç‚¹**: å ç”¨äº†å®è´µçš„ Context Window é•¿åº¦ã€‚

### 3.3. P-Tuning v2
- åœ¨æ¯ä¸€å±‚éƒ½åŠ å…¥å¯å­¦ä¹ çš„ Prefixï¼Œè€Œä¸ä»…ä»…æ˜¯è¾“å…¥å±‚ã€‚
- **ä¼˜ç‚¹**: æ¯” P-Tuning v1 æ•ˆæœæ›´å¥½ï¼Œæ¥è¿‘å…¨é‡å¾®è°ƒã€‚
- **ç¼ºç‚¹**: ä»ç„¶å ç”¨ Context Windowã€‚

---

## 4. PEFT æ–¹æ³•å¯¹æ¯” (Comparison)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PEFT æ–¹æ³•å¯¹æ¯”ä¸€è§ˆ                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚   æ–¹æ³•          åŸç†              æ¨ç†å»¶è¿Ÿ   å¯åˆå¹¶   å‚æ•°é‡     â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”‚
â”‚   LoRA          ä½ç§©åˆ†è§£ Î”W=BA    æ— é¢å¤–     âœ…       ~0.1-1%   â”‚
â”‚   Adapter       ä¸²è¡Œæ’å…¥ MLP      æœ‰é¢å¤–     âŒ       ~1-5%     â”‚
â”‚   P-Tuning      å¯å­¦ä¹  Prompt     å  Context âŒ       ~0.01%    â”‚
â”‚   Prefix-Tuning å¯å­¦ä¹  KV å‰ç¼€    å  Context âŒ       ~0.1%     â”‚
â”‚   P-Tuning v2   æ¯å±‚ Prefix       å  Context âŒ       ~0.1-1%   â”‚
â”‚                                                                 â”‚
â”‚   ğŸ’¡ VLA é¦–é€‰: LoRA (å¯åˆå¹¶ï¼Œæ— æ¨ç†å»¶è¿Ÿ)                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

| æ–¹æ³• | åŸç† | æ¨ç†å»¶è¿Ÿ | å¯åˆå¹¶æƒé‡ | å‚æ•°é‡ | æ•ˆæœ |
| :--- | :--- | :--- | :--- | :--- | :--- |
| **LoRA** | ä½ç§©åˆ†è§£ $\Delta W = BA$ | æ—  | âœ… | ~0.1-1% | â­â­â­â­ |
| **Adapter** | ä¸²è¡Œæ’å…¥ MLP | æœ‰ | âŒ | ~1-5% | â­â­â­ |
| **P-Tuning** | å¯å­¦ä¹  Soft Prompt | å  Context | âŒ | ~0.01% | â­â­ |
| **Prefix-Tuning** | å¯å­¦ä¹  KV å‰ç¼€ | å  Context | âŒ | ~0.1% | â­â­â­ |
| **P-Tuning v2** | æ¯å±‚ Prefix | å  Context | âŒ | ~0.1-1% | â­â­â­â­ |

### LoRA vs P-Tuning vs Adapter æ ¸å¿ƒå·®å¼‚

| å¯¹æ¯”ç»´åº¦ | LoRA | P-Tuning | Adapter |
| :--- | :--- | :--- | :--- |
| **ä¿®æ”¹ä½ç½®** | æƒé‡çŸ©é˜µ (W) | è¾“å…¥å±‚ / æ¯å±‚ | å±‚é—´æ’å…¥ |
| **æ¨ç†æ—¶** | å¯åˆå¹¶ï¼Œæ— å»¶è¿Ÿ | éœ€ä¿ç•™ Prompt | éœ€ä¿ç•™ Adapter |
| **Context å ç”¨** | æ—  | æœ‰ (å‡ å~å‡ ç™¾ Token) | æ—  |
| **é€‚ç”¨åœºæ™¯** | é€šç”¨é¦–é€‰ | å°æ¨¡å‹ / ç‰¹å®šä»»åŠ¡ | å¤šä»»åŠ¡åˆ‡æ¢ |

---

## 5. LoRA å‚æ•°é€‰æ‹©æŒ‡å— (Hyperparameter Guide)

### 5.1 Rank (ç§© $r$) çš„å½±å“

| $r$ å€¼ | å‚æ•°é‡ | é€‚ç”¨åœºæ™¯ | é£é™© |
| :--- | :--- | :--- | :--- |
| **4-8** | æœ€å°‘ | ç®€å•ä»»åŠ¡ (æŒ‡ä»¤è·Ÿéšã€é£æ ¼è¿ç§») | æ¬ æ‹Ÿåˆ |
| **16-32** | é€‚ä¸­ | é€šç”¨å¾®è°ƒ (VLA æ¨è) | å¹³è¡¡ |
| **64-128** | è¾ƒå¤š | å¤æ‚æ¨ç†ã€çŸ¥è¯†æ³¨å…¥ | è¿‡æ‹Ÿåˆ |
| **256+** | æ¥è¿‘å…¨é‡ | å‡ ä¹ç­‰ä»·äºå…¨é‡å¾®è°ƒ | å¤±å» LoRA ä¼˜åŠ¿ |

### 5.2 Alpha ($\alpha$) çš„å½±å“


$$
W = W_0 + \frac{\alpha}{r} \cdot BA
$$


- **$\alpha / r$ æ¯”å€¼**: æ§åˆ¶ LoRA æ›´æ–°çš„"å¼ºåº¦"
- **å¸¸è§è®¾ç½®**: $\alpha = 2r$ (å³ $\alpha/r = 2$)
- **$\alpha$ å¤§**: æ›´æ¿€è¿›çš„æ›´æ–°ï¼Œæ”¶æ•›å¿«ä½†å¯èƒ½ä¸ç¨³å®š
- **$\alpha$ å°**: æ›´ä¿å®ˆçš„æ›´æ–°ï¼Œç¨³å®šä½†æ”¶æ•›æ…¢

### 5.3 ç›®æ ‡å±‚é€‰æ‹©

| é…ç½® | ç›®æ ‡å±‚ | å‚æ•°é‡ | æ•ˆæœ |
| :--- | :--- | :--- | :--- |
| **æœ€å°é…ç½®** | `q_proj, v_proj` | ~0.1% | åŸºç¡€æ•ˆæœ |
| **æ¨èé…ç½®** | `q_proj, k_proj, v_proj, o_proj` | ~0.2% | è¾ƒå¥½æ•ˆæœ |
| **å®Œæ•´é…ç½®** | Attention + MLP å…¨éƒ¨ | ~1% | æœ€ä½³æ•ˆæœ |

```python
## PEFT é…ç½®ç¤ºä¾‹
from peft import LoraConfig

lora_config = LoraConfig(
    r=16,                    # ç§©
    lora_alpha=32,           # alpha = 2r
    target_modules=[
        "q_proj", "k_proj", "v_proj", "o_proj",  # Attention
        "gate_proj", "up_proj", "down_proj"       # MLP
    ],
    lora_dropout=0.05,
    bias="none",
    task_type="CAUSAL_LM"
)
```

---

## 6. é¢è¯•é«˜é¢‘è€ƒç‚¹

**Q: LoRA çš„åŸç†æ˜¯ä»€ä¹ˆï¼Ÿä¸ P-Tuningã€Adapter çš„å¼‚åŒç‚¹ï¼Ÿ**
A: 
- **LoRA**: å°†æƒé‡å¢é‡ $\Delta W$ åˆ†è§£ä¸ºä½ç§©çŸ©é˜µ $BA$ï¼Œå†»ç»“åŸå§‹æƒé‡åªè®­ç»ƒ $A, B$ã€‚æ¨ç†æ—¶å¯åˆå¹¶å›åŸæƒé‡ï¼Œæ— é¢å¤–å»¶è¿Ÿã€‚
- **P-Tuning**: åœ¨è¾“å…¥å‰åŠ å¯å­¦ä¹ çš„ Soft Promptï¼Œå ç”¨ Context Windowã€‚
- **Adapter**: åœ¨ Transformer å±‚é—´æ’å…¥å°å‹ MLPï¼Œæ¨ç†æ—¶æœ‰é¢å¤–å»¶è¿Ÿã€‚
- **æ ¸å¿ƒåŒºåˆ«**: LoRA ä¿®æ”¹æƒé‡æœ¬èº«ï¼ŒP-Tuning ä¿®æ”¹è¾“å…¥ï¼ŒAdapter ä¿®æ”¹ç»“æ„ã€‚LoRA æ˜¯å”¯ä¸€å¯ä»¥"æ— ç—•åˆå¹¶"çš„æ–¹æ³•ã€‚

**Q: LoRA çš„å‚æ•°é€‰æ‹©å¯¹æ¨¡å‹æ€§èƒ½æœ‰ä½•å½±å“ï¼Ÿ**
A:
- **Rank $r$**: æ§åˆ¶è¡¨è¾¾èƒ½åŠ›ã€‚$r$ å° (4-8) é€‚åˆç®€å•ä»»åŠ¡ï¼Œ$r$ å¤§ (64+) é€‚åˆå¤æ‚ä»»åŠ¡ä½†æ˜“è¿‡æ‹Ÿåˆã€‚
- **Alpha $\alpha$**: æ§åˆ¶æ›´æ–°å¼ºåº¦ã€‚é€šå¸¸ $\alpha = 2r$ã€‚
- **ç›®æ ‡å±‚**: åªè®­ç»ƒ `q_proj, v_proj` æ˜¯æœ€å°é…ç½®ï¼ŒåŠ ä¸Š MLP æ•ˆæœæ›´å¥½ã€‚

**Q: LoRA çš„ç§© $r$ è¶Šå¤§è¶Šå¥½å—ï¼Ÿ**
A: ä¸ä¸€å®šã€‚å¯¹äºç®€å•çš„ä»»åŠ¡ (å¦‚æŒ‡ä»¤è·Ÿéš)ï¼Œ$r=8$ è¶³çŸ£ã€‚å¯¹äºå¤æ‚çš„é€»è¾‘æ¨ç†æˆ–çŸ¥è¯†æ³¨å…¥ï¼Œ$r$ å¯èƒ½éœ€è¦è®¾å¤§ä¸€ç‚¹ (64 æˆ– 128)ã€‚ä½†è¿‡å¤§å®¹æ˜“è¿‡æ‹Ÿåˆï¼Œä¸”å¤±å»å‚æ•°é«˜æ•ˆçš„ä¼˜åŠ¿ã€‚

**Q: ä¸ºä»€ä¹ˆ QLoRA æ¯” LoRA æ…¢ï¼Ÿ**
A: å› ä¸º QLoRA åœ¨è®¡ç®—æ¢¯åº¦æ—¶ï¼Œéœ€è¦å°† 4-bit æƒé‡**åé‡åŒ– (Dequantize)** å› FP16/BF16 è¿›è¡Œè®¡ç®—ã€‚è¿™ä¸ªåé‡åŒ–è¿‡ç¨‹å¢åŠ äº†è®¡ç®—å¼€é”€ã€‚

**Q: VLA æ¨¡å‹å¾®è°ƒåº”è¯¥å¾®è°ƒå“ªäº›å±‚ï¼Ÿ**
A: é€šå¸¸å¾®è°ƒ **Attention (q_proj, v_proj)** å’Œ **MLP (gate_proj, up_proj, down_proj)** æ•ˆæœæœ€å¥½ã€‚åªå¾®è°ƒ Attention æœ‰æ—¶ä¸å¤Ÿã€‚

\newpage

# ç¬¬11ç«  å¼ºåŒ–å­¦ä¹ åŸºç¡€ä¸ RLHF


> **æ ¸å¿ƒæ¦‚å¿µ**: å¼ºåŒ–å­¦ä¹  (Reinforcement Learning, RL) æ˜¯ä¸€ç§é€šè¿‡ä¸ç¯å¢ƒäº¤äº’æ¥å­¦ä¹ æœ€ä¼˜ç­–ç•¥çš„æ–¹æ³•ã€‚æ™ºèƒ½ä½“é€šè¿‡**è¯•é”™** (Trial-and-Error) å’Œ**å¥–åŠ±åé¦ˆ** (Reward Feedback) ä¸æ–­æ”¹è¿›è¡Œä¸ºã€‚

## 0. ä¸»è¦æ•¸å­¸æ€æƒ³ (Main Mathematical Idea)

> **ç¬¬ä¸€æ€§åŸç†**: **Trial and Error with Feedback (è¯•é”™ä¸åé¦ˆ)**

åœ¨ç°å®ä¸–ç•Œä¸­ï¼Œæ™ºèƒ½ä½“ï¼ˆæ— è®ºæ˜¯ç”Ÿç‰©è¿˜æ˜¯æœºå™¨ï¼‰å¾€å¾€æ— æ³•è·å¾—"æ­£ç¡®ç­”æ¡ˆ"çš„ç›´æ¥æŒ‡å¯¼ï¼Œåªèƒ½é€šè¿‡ä½“éªŒè¡Œä¸ºçš„**åæœ**ï¼ˆå¥–åŠ±æˆ–æƒ©ç½šï¼‰æ¥å­¦ä¹ ã€‚

- **æ ¸å¿ƒæ•°å­¦å·¥å…·**: **åŠ¨æ€è§„åˆ’ (Dynamic Programming)** ä¸ **Bellman æœ€ä¼˜æ€§åŸç†**ã€‚
- **è§£é¢˜é€»è¾‘**:
    1.  **åˆ†è§£**: å°†å¤æ‚çš„é•¿æœŸå†³ç­–é—®é¢˜åˆ†è§£ä¸ºé€’å½’çš„å•æ­¥å†³ç­–å­é—®é¢˜ã€‚
    2.  **å‰ç»**: å½“å‰çš„æœ€ä¼˜é€‰æ‹©ä¸ä»…ä»…å–å†³äºçœ¼å‰çš„æ”¶ç›Šï¼Œè¿˜å¿…é¡»åŒ…å«å¯¹æœªæ¥æ‰€æœ‰å¯èƒ½æ”¶ç›Šçš„æœŸæœ›ï¼ˆå³ä»·å€¼å‡½æ•° $V$ æˆ– $Q$ï¼‰ã€‚
    3.  **è¿­ä»£**: é€šè¿‡ä¸æ–­æ›´æ–°ä»·å€¼ä¼°è®¡ï¼Œæœ€ç»ˆæ”¶æ•›åˆ°æœ€ä¼˜ç­–ç•¥ã€‚

## 1. ä¸ºä»€ä¹ˆ VLA éœ€è¦å¼ºåŒ–å­¦ä¹ ? (Why RL for VLA?)

### 1.1 è¡Œä¸ºå…‹éš† (BC) çš„å±€é™

ä¼ ç»Ÿ VLA ä¸»è¦ä¾èµ– **è¡Œä¸ºå…‹éš† (Behavior Cloning)**ï¼šæ¨¡ä»¿äººç±»æ¼”ç¤ºã€‚

| æ–¹æ³• | ä¼˜ç‚¹ | ç¼ºç‚¹ |
| :--- | :--- | :--- |
| **BC** | ç®€å•ï¼Œæ•°æ®æ•ˆç‡é«˜ | ä¸Šé™æ˜¯äººç±»æ°´å¹³ï¼Œæ— æ³•è¶…è¶Šæ¼”ç¤ºè€… |
| **RL** | å¯ä»¥è¶…è¶Šäººç±»ï¼Œè‡ªæˆ‘è¿›åŒ– | éœ€è¦å¤§é‡äº¤äº’ï¼Œç¨€ç–å¥–åŠ±éš¾ä¼˜åŒ– |

### 1.2 RL åœ¨ VLA ä¸­çš„ä»·å€¼

- **è¶…è¶Šäººç±»ç¤ºæ•™**: é€šè¿‡è‡ªæˆ‘åšå¼ˆ/æ¢ç´¢å‘ç°æ›´ä¼˜ç­–ç•¥
- **é•¿åºåˆ—ä¼˜åŒ–**: BC åªæ¨¡ä»¿æ¯æ­¥åŠ¨ä½œï¼ŒRL ä¼˜åŒ–æ•´ä¸ªè½¨è¿¹çš„ç´¯ç§¯å›æŠ¥
- **é€‚åº”æ€§å­¦ä¹ **: åœ¨çœŸæœºéƒ¨ç½²æ—¶æŒç»­è‡ªæˆ‘æ”¹è¿›
- **ç¨€ç–å¥–åŠ±ä»»åŠ¡**: åªæœ‰ä»»åŠ¡æˆåŠŸæ—¶ç»™å¥–åŠ±çš„åœºæ™¯ï¼ˆå¦‚ç»„è£…ï¼‰

### 1.3 VLA ä¸­çš„ RL åº”ç”¨æ¡ˆä¾‹

- **Ï€*0.6 (Pi-Star)**: ä½¿ç”¨ Recap ç®—æ³•ï¼ˆOffline RLï¼‰è¶…è¶Šäººç±»ç¤ºæ•™
- **RT-2**: ä½¿ç”¨ RL from Human Feedback (RLHF) æ”¹è¿›è¯­ä¹‰æ¨ç†
- **RoboCasa**: ä½¿ç”¨ PPO è®­ç»ƒå®¶åº­æ“ä½œç­–ç•¥

## 2. RL åŸºç¡€æ¦‚å¿µ (RL Fundamentals)

### 2.1 é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ (MDP)

```
MDP = (S, A, P, R, Î³)
```

- **S**: çŠ¶æ€ç©ºé—´ (State Space) - æœºå™¨äººè§‚æµ‹åˆ°çš„ä¸€åˆ‡
- **A**: åŠ¨ä½œç©ºé—´ (Action Space) - å¯æ‰§è¡Œçš„åŠ¨ä½œ
- **P(s'|s,a)**: çŠ¶æ€è½¬ç§»æ¦‚ç‡ - ç¯å¢ƒåŠ¨åŠ›å­¦
- **R(s,a)**: å¥–åŠ±å‡½æ•° - è¡Œä¸ºå¥½åçš„åé¦ˆ
- **Î³**: æŠ˜æ‰£å› å­ - æœªæ¥å¥–åŠ±çš„æƒé‡ (é€šå¸¸ 0.99)

### 2.2 é©¬å°”å¯å¤«æ€§ (Markov Property)

**å®šä¹‰**: ä¸‹ä¸€çŠ¶æ€åªä¾èµ–äºå½“å‰çŠ¶æ€å’ŒåŠ¨ä½œï¼Œä¸å†å²æ— å…³ã€‚

```
P(s_{t+1} | s_t, a_t, s_{t-1}, a_{t-1}, ...) = P(s_{t+1} | s_t, a_t)
```

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    é©¬å°”å¯å¤«æ€§å›¾è§£                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚   éé©¬å°”å¯å¤«:  sâ‚€ â†’ sâ‚ â†’ sâ‚‚ â†’ sâ‚ƒ â†’ sâ‚„                           â”‚
â”‚               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                            â”‚
â”‚                  æ‰€æœ‰å†å²éƒ½å½±å“æœªæ¥                               â”‚
â”‚                                                                 â”‚
â”‚   é©¬å°”å¯å¤«:    sâ‚€ â†’ sâ‚ â†’ sâ‚‚ â†’ sâ‚ƒ â†’ sâ‚„                           â”‚
â”‚                          â””â”€â”€â”€â”˜                                  â”‚
â”‚                    åªæœ‰ sâ‚ƒ å½±å“ sâ‚„                               â”‚
â”‚                                                                 â”‚
â”‚   ğŸ’¡ "å½“å‰çŠ¶æ€æ˜¯å¯¹å†å²çš„å……åˆ†ç»Ÿè®¡é‡"                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ä¸ºä»€ä¹ˆé‡è¦**:
- **ç®€åŒ–è®¡ç®—**: ä¸éœ€è¦è®°å¿†æ•´ä¸ªå†å²ï¼Œåªéœ€å½“å‰çŠ¶æ€
- **Bellman æ–¹ç¨‹æˆç«‹**: ä»·å€¼å‡½æ•°å¯ä»¥é€’å½’å®šä¹‰
- **å®é™…åº”ç”¨**: æœºå™¨äººçŠ¶æ€é€šå¸¸åŒ…å«ä½ç½®+é€Ÿåº¦ï¼Œæ»¡è¶³é©¬å°”å¯å¤«æ€§ï¼›è‹¥åªæœ‰ä½ç½®åˆ™ä¸æ»¡è¶³

### 2.3 æ ¸å¿ƒç›®æ ‡

æœ€å¤§åŒ–**ç´¯ç§¯æŠ˜æ‰£å›æŠ¥ (Cumulative Discounted Return)**:

```
G_t = Î£_{k=0}^{âˆ} Î³^k Ã— R_{t+k+1}
```

### 2.4 ä»·å€¼å‡½æ•° (Value Functions)

**çŠ¶æ€ä»·å€¼å‡½æ•° (State Value)**:

```
V^Ï€(s) = E_Ï€[ G_t | S_t = s ]
```

**åŠ¨ä½œä»·å€¼å‡½æ•° (Action Value / Q-Function)**:

```
Q^Ï€(s, a) = E_Ï€[ G_t | S_t = s, A_t = a ]
```

**Bellman æ–¹ç¨‹**:

```
Q^Ï€(s, a) = R(s, a) + Î³ Ã— E_{s' ~ P}[ V^Ï€(s') ]
```

### 2.5 æœ€ä¼˜ä»·å€¼å‡½æ•°ä¸æœ€ä¼˜ç­–ç•¥

**æœ€ä¼˜ä»·å€¼å‡½æ•°**:

```
V*(s) = max_Ï€ V^Ï€(s)
Q*(s, a) = max_Ï€ Q^Ï€(s, a)
```

**æœ€ä¼˜ç­–ç•¥**:

```
Ï€*(s) = argmax_a Q*(s, a)
```

**ä¸ºä»€ä¹ˆæœ€ä¼˜ä»·å€¼å‡½æ•°å°±æ˜¯æœ€ä¼˜ç­–ç•¥ï¼Ÿ**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                æœ€ä¼˜ä»·å€¼å‡½æ•° â†” æœ€ä¼˜ç­–ç•¥                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚   æ ¸å¿ƒå®šç†: ç»™å®š Q*(s, a)ï¼Œæœ€ä¼˜ç­–ç•¥å¯ç›´æ¥å¯¼å‡º                    â”‚
â”‚                                                                 â”‚
â”‚   Ï€*(s) = argmax_a Q*(s, a)                                     â”‚
â”‚                                                                 â”‚
â”‚   è¯æ˜æ€è·¯:                                                     â”‚
â”‚   1. Q*(s,a) è¡¨ç¤ºåœ¨çŠ¶æ€ s æ‰§è¡ŒåŠ¨ä½œ a åï¼ŒæŒ‰æœ€ä¼˜ç­–ç•¥è¡ŒåŠ¨çš„æœŸæœ›å›æŠ¥ â”‚
â”‚   2. è¦æœ€å¤§åŒ–å›æŠ¥ï¼Œåªéœ€åœ¨æ¯ä¸ªçŠ¶æ€é€‰æ‹© Q* æœ€å¤§çš„åŠ¨ä½œ              â”‚
â”‚   3. è¿™æ­£æ˜¯è´ªå¿ƒç­–ç•¥ï¼Œè€Œå¯¹äº Q* è´ªå¿ƒå°±æ˜¯æœ€ä¼˜çš„                    â”‚
â”‚                                                                 â”‚
â”‚   åè¿‡æ¥:                                                       â”‚
â”‚   ç»™å®šæœ€ä¼˜ç­–ç•¥ Ï€*ï¼Œå¯ä»¥è®¡ç®—å‡º Q*(s,a) = Q^{Ï€*}(s,a)             â”‚
â”‚                                                                 â”‚
â”‚   ğŸ’¡ æœ€ä¼˜ä»·å€¼å‡½æ•°å’Œæœ€ä¼˜ç­–ç•¥æ˜¯"ä¸€ä½“ä¸¤é¢"                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**æ•°å­¦æ¨å¯¼**:
1. **Bellman æœ€ä¼˜æ–¹ç¨‹**: `V*(s) = max_a [ R(s,a) + Î³ Ã— Î£_{s'} P(s'|s,a) Ã— V*(s') ]`
2. å¦‚æœæˆ‘ä»¬çŸ¥é“ `V*`ï¼Œåˆ™æœ€ä¼˜åŠ¨ä½œæ˜¯ä½¿ä¸Šå¼å–æœ€å¤§å€¼çš„ `a`
3. è¿™ç­‰ä»·äº `Ï€*(s) = argmax_a Q*(s,a)`

### 2.6 ç­–ç•¥ (Policy)

ç­–ç•¥ `Ï€(a|s)` å®šä¹‰äº†åœ¨çŠ¶æ€ `s` ä¸‹é‡‡å–åŠ¨ä½œ `a` çš„æ¦‚ç‡ã€‚

- **ç¡®å®šæ€§ç­–ç•¥**: `a = Ï€(s)`
- **éšæœºç­–ç•¥**: `a ~ Ï€(Â·|s)`

## 3. RL ç®—æ³•åˆ†ç±» (RL Algorithm Taxonomy)

```
                        RL ç®—æ³•
                           â”‚
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚               â”‚               â”‚
      Model-Free      Model-Based    Offline RL
           â”‚               â”‚               â”‚
     â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”         â”‚          â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
     â”‚           â”‚         â”‚          â”‚         â”‚
 Value-Based  Policy-Based â”‚       CQL/IQL   Recap
     â”‚           â”‚         â”‚
   DQN/SAC   PPO/TRPO   Dreamer/MBPO
```

### 3.1 Model-Free vs Model-Based

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                Model-Free vs Model-Based                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚   Model-Free (æ— æ¨¡å‹):                                          â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚  Agent â†â”€â”€â”€â”€ äº¤äº’ â”€â”€â”€â”€â†’ Environment                     â”‚   â”‚
â”‚   â”‚    â”‚                         â”‚                          â”‚   â”‚
â”‚   â”‚    â””â”€â”€ ç›´æ¥å­¦ä¹  Ï€ æˆ– Q â”€â”€â”€â”€â”€â”€â”˜                          â”‚   â”‚
â”‚   â”‚        (ä¸å…³å¿ƒç¯å¢ƒå¦‚ä½•å·¥ä½œ)                              â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚   ä»£è¡¨: DQN, PPO, SAC                                           â”‚
â”‚   ç‰¹ç‚¹: ç®€å•ç›´æ¥ï¼Œä½†éœ€è¦å¤§é‡äº¤äº’æ•°æ®                            â”‚
â”‚                                                                 â”‚
â”‚   Model-Based (åŸºäºæ¨¡å‹):                                       â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚  Agent â†â”€â”€â”€â”€ äº¤äº’ â”€â”€â”€â”€â†’ Environment                     â”‚   â”‚
â”‚   â”‚    â”‚                         â”‚                          â”‚   â”‚
â”‚   â”‚    â”œâ”€â”€ å­¦ä¹ ç¯å¢ƒæ¨¡å‹ P(s'|s,a) â”˜                         â”‚   â”‚
â”‚   â”‚    â”‚                                                    â”‚   â”‚
â”‚   â”‚    â””â”€â”€ åœ¨æ¨¡å‹ä¸­è§„åˆ’/æ¨¡æ‹Ÿ â”€â”€â†’ ç­–ç•¥                       â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚   ä»£è¡¨: Dreamer, MBPO, MuZero                                   â”‚
â”‚   ç‰¹ç‚¹: æ ·æœ¬é«˜æ•ˆï¼Œä½†æ¨¡å‹è¯¯å·®ä¼šç´¯ç§¯                              â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

| ç±»å‹ | åŸç† | ä¼˜ç‚¹ | ç¼ºç‚¹ | é€‚ç”¨åœºæ™¯ |
| :--- | :--- | :--- | :--- | :--- |
| **Model-Free** | ç›´æ¥å­¦ä¹ ç­–ç•¥/ä»·å€¼ | ç®€å•ï¼Œæ— æ¨¡å‹åå·® | æ ·æœ¬æ•ˆç‡ä½ | çœŸæœºäº¤äº’æˆæœ¬ä½ |
| **Model-Based** | å­¦ä¹ ç¯å¢ƒåŠ¨åŠ›å­¦ $P(s'|s,a)$ | æ ·æœ¬æ•ˆç‡é«˜ | æ¨¡å‹è¯¯å·®ç´¯ç§¯ | ä»¿çœŸç¯å¢ƒã€Sim-to-Real |

**å…³é”®åŒºåˆ«**:
- **Model-Free**: ä¸å°è¯•ç†è§£ç¯å¢ƒå¦‚ä½•å·¥ä½œï¼Œåªå…³å¿ƒ"ä»€ä¹ˆåŠ¨ä½œèƒ½è·å¾—é«˜å›æŠ¥"
- **Model-Based**: å…ˆå­¦ä¹ ç¯å¢ƒçš„"è§„åˆ™"ï¼ˆçŠ¶æ€è½¬ç§»ï¼‰ï¼Œå†åˆ©ç”¨è§„åˆ™è¿›è¡Œè§„åˆ’

**VLA ä¸­çš„åº”ç”¨**:
- **Model-Free**: Ï€0.6 çš„ Recap ç®—æ³•ï¼ˆç›´æ¥ä»æ•°æ®å­¦ä¹ ç­–ç•¥ï¼‰
- **Model-Based**: ä¸–ç•Œæ¨¡å‹ (World Model) ç”¨äºé¢„æµ‹æœªæ¥çŠ¶æ€ï¼Œè¾…åŠ©è§„åˆ’

### 3.2 ç­–ç•¥è¿­ä»£ vs å€¼è¿­ä»£ (Policy Iteration vs Value Iteration)

ä¸¤ç§ç»å…¸çš„åŠ¨æ€è§„åˆ’ç®—æ³•ï¼Œç”¨äºæ±‚è§£ MDPã€‚

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              ç­–ç•¥è¿­ä»£ vs å€¼è¿­ä»£                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚   ç­–ç•¥è¿­ä»£ (Policy Iteration):                                  â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚  åˆå§‹åŒ– Ï€â‚€                                               â”‚   â”‚
â”‚   â”‚      â”‚                                                   â”‚   â”‚
â”‚   â”‚      â–¼                                                   â”‚   â”‚
â”‚   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                    â”‚   â”‚
â”‚   â”‚  â”‚ ç­–ç•¥è¯„ä¼° (PE)    â”‚ â† è®¡ç®— V^Ï€ (è¿­ä»£è‡³æ”¶æ•›)            â”‚   â”‚
â”‚   â”‚  â”‚ V^Ï€(s) = E[...]  â”‚                                    â”‚   â”‚
â”‚   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                    â”‚   â”‚
â”‚   â”‚           â”‚                                              â”‚   â”‚
â”‚   â”‚           â–¼                                              â”‚   â”‚
â”‚   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                    â”‚   â”‚
â”‚   â”‚  â”‚ ç­–ç•¥æ”¹è¿› (PI)    â”‚ â† Ï€(s) = argmax_a Q(s,a)           â”‚   â”‚
â”‚   â”‚  â”‚ Ï€ â† greedy(V)    â”‚                                    â”‚   â”‚
â”‚   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                    â”‚   â”‚
â”‚   â”‚           â”‚                                              â”‚   â”‚
â”‚   â”‚           â””â”€â”€â”€â”€ é‡å¤ç›´åˆ° Ï€ ä¸å†å˜åŒ– â”€â”€â”€â”€â”˜                â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                 â”‚
â”‚   å€¼è¿­ä»£ (Value Iteration):                                     â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚  åˆå§‹åŒ– Vâ‚€                                               â”‚   â”‚
â”‚   â”‚      â”‚                                                   â”‚   â”‚
â”‚   â”‚      â–¼                                                   â”‚   â”‚
â”‚   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”‚
â”‚   â”‚  â”‚ V(s) â† max_a [R(s,a) + Î³ Î£ P(s'|s,a) V(s')]      â”‚   â”‚   â”‚
â”‚   â”‚  â”‚       (Bellman æœ€ä¼˜æ–¹ç¨‹çš„è¿­ä»£æ›´æ–°)                â”‚   â”‚   â”‚
â”‚   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â”‚
â”‚   â”‚           â”‚                                              â”‚   â”‚
â”‚   â”‚           â””â”€â”€â”€â”€ é‡å¤ç›´åˆ° V æ”¶æ•› â”€â”€â”€â”€â”˜                    â”‚   â”‚
â”‚   â”‚                                                          â”‚   â”‚
â”‚   â”‚  æœ€å: Ï€(s) = argmax_a Q(s,a)                            â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

| å¯¹æ¯” | ç­–ç•¥è¿­ä»£ | å€¼è¿­ä»£ |
| :--- | :--- | :--- |
| **æ ¸å¿ƒæ“ä½œ** | è¯„ä¼° + æ”¹è¿›äº¤æ›¿ | ç›´æ¥è¿­ä»£ Bellman æœ€ä¼˜æ–¹ç¨‹ |
| **æ¯è½®è®¡ç®—** | ç­–ç•¥è¯„ä¼°éœ€è¿­ä»£è‡³æ”¶æ•› | åªåšä¸€æ¬¡ Bellman æ›´æ–° |
| **æ”¶æ•›é€Ÿåº¦** | è¿­ä»£æ¬¡æ•°å°‘ | æ¯è½®è®¡ç®—é‡å° |
| **æ€»ä½“æ•ˆç‡** | å¤§çŠ¶æ€ç©ºé—´æ›´å¿« | å°çŠ¶æ€ç©ºé—´æ›´å¿« |
| **ç­–ç•¥è¾“å‡º** | æ¯è½®éƒ½æœ‰æ˜¾å¼ç­–ç•¥ | æœ€åæ‰æå–ç­–ç•¥ |

**ç›´è§‰ç†è§£**:
- **ç­–ç•¥è¿­ä»£**: "å…ˆå®Œæ•´è¯„ä¼°å½“å‰ç­–ç•¥æœ‰å¤šå¥½ï¼Œå†æ”¹è¿›"
- **å€¼è¿­ä»£**: "ç›´æ¥æœæœ€ä¼˜ä»·å€¼å‡½æ•°è¿­ä»£ï¼Œæœ€åå†æå–ç­–ç•¥"

### 3.3 On-Policy vs Off-Policy

| ç±»å‹ | ä»£è¡¨ç®—æ³• | ç‰¹ç‚¹ |
| :--- | :--- | :--- |
| **On-Policy** | PPO, TRPO | åªç”¨å½“å‰ç­–ç•¥çš„æ•°æ®ï¼Œç¨³å®šä½†ä½æ•ˆ |
| **Off-Policy** | SAC, TD3 | å¯å¤ç”¨å†å²æ•°æ®ï¼Œé«˜æ•ˆä½†ä¸ç¨³å®š |

## 4. VLA å¸¸ç”¨ RL ç®—æ³• (RL Algorithms for VLA)

### 4.1 PPO (Proximal Policy Optimization)

**æ ¸å¿ƒæ€æƒ³**: é™åˆ¶ç­–ç•¥æ›´æ–°å¹…åº¦ï¼Œé˜²æ­¢è®­ç»ƒå´©æºƒã€‚

**ç›®æ ‡å‡½æ•°**:

```
L_CLIP(Î¸) = E_t[ min( r_t(Î¸) Ã— Ã‚_t, clip(r_t(Î¸), 1-Îµ, 1+Îµ) Ã— Ã‚_t ) ]
```

å…¶ä¸­ `r_t(Î¸) = Ï€_Î¸(a_t|s_t) / Ï€_{Î¸_old}(a_t|s_t)` æ˜¯é‡è¦æ€§é‡‡æ ·æ¯”ç‡ã€‚

```python
import torch
import torch.nn as nn
import torch.nn.functional as F

class PPO:
    def __init__(self, policy, value_net, clip_epsilon=0.2, lr=3e-4):
        self.policy = policy
        self.value_net = value_net
        self.clip_epsilon = clip_epsilon
        self.optimizer = torch.optim.Adam(
            list(policy.parameters()) + list(value_net.parameters()), lr=lr
        )
    
    def compute_gae(self, rewards, values, dones, gamma=0.99, lam=0.95):
        """Generalized Advantage Estimation"""
        advantages = []
        gae = 0
        for t in reversed(range(len(rewards))):
            if t == len(rewards) - 1:
                next_value = 0
            else:
                next_value = values[t + 1]
            
            delta = rewards[t] + gamma * next_value * (1 - dones[t]) - values[t]
            gae = delta + gamma * lam * (1 - dones[t]) * gae
            advantages.insert(0, gae)
        
        return torch.tensor(advantages)
    
    def update(self, states, actions, old_log_probs, rewards, dones):
        # è®¡ç®—ä»·å€¼å’Œä¼˜åŠ¿
        values = self.value_net(states).squeeze()
        advantages = self.compute_gae(rewards, values.detach(), dones)
        returns = advantages + values.detach()
        
        # å½’ä¸€åŒ–ä¼˜åŠ¿
        advantages = (advantages - advantages.mean()) / (advantages.std() + 1e-8)
        
        # PPO æ›´æ–°
        for _ in range(10):  # å¤šè½®æ›´æ–°
            # è®¡ç®—æ–°çš„ log_prob
            dist = self.policy(states)
            new_log_probs = dist.log_prob(actions)
            
            # é‡è¦æ€§é‡‡æ ·æ¯”ç‡
            ratio = torch.exp(new_log_probs - old_log_probs)
            
            # Clipped ç›®æ ‡
            surr1 = ratio * advantages
            surr2 = torch.clamp(ratio, 1 - self.clip_epsilon, 1 + self.clip_epsilon) * advantages
            policy_loss = -torch.min(surr1, surr2).mean()
            
            # ä»·å€¼æŸå¤±
            value_loss = F.mse_loss(self.value_net(states).squeeze(), returns)
            
            # ç†µæ­£åˆ™åŒ– (é¼“åŠ±æ¢ç´¢)
            entropy = dist.entropy().mean()
            
            # æ€»æŸå¤±
            loss = policy_loss + 0.5 * value_loss - 0.01 * entropy
            
            self.optimizer.zero_grad()
            loss.backward()
            self.optimizer.step()
```

### 4.2 SAC (Soft Actor-Critic)

**æ ¸å¿ƒæ€æƒ³**: æœ€å¤§åŒ–å¥–åŠ±çš„åŒæ—¶æœ€å¤§åŒ–ç­–ç•¥ç†µï¼ˆé¼“åŠ±æ¢ç´¢ï¼‰ã€‚

**ç›®æ ‡**:

```
J(Ï€) = E_{Ï„ ~ Ï€}[ Î£_t R(s_t, a_t) + Î± Ã— H(Ï€(Â·|s_t)) ]
```

```python
class SAC:
    def __init__(self, actor, critic1, critic2, target_critic1, target_critic2, 
                 alpha=0.2, gamma=0.99, tau=0.005):
        self.actor = actor
        self.critic1 = critic1
        self.critic2 = critic2
        self.target_critic1 = target_critic1
        self.target_critic2 = target_critic2
        self.alpha = alpha  # ç†µç³»æ•°
        self.gamma = gamma
        self.tau = tau
    
    def update(self, batch):
        states, actions, rewards, next_states, dones = batch
        
        # ===== Critic æ›´æ–° =====
        with torch.no_grad():
            # ä»å½“å‰ç­–ç•¥é‡‡æ ·ä¸‹ä¸€ä¸ªåŠ¨ä½œ
            next_actions, next_log_probs = self.actor.sample(next_states)
            
            # ç›®æ ‡ Q å€¼ (å–ä¸¤ä¸ª critic çš„æœ€å°å€¼)
            target_q1 = self.target_critic1(next_states, next_actions)
            target_q2 = self.target_critic2(next_states, next_actions)
            target_q = torch.min(target_q1, target_q2) - self.alpha * next_log_probs
            
            # TD ç›®æ ‡
            target = rewards + self.gamma * (1 - dones) * target_q
        
        # å½“å‰ Q å€¼
        current_q1 = self.critic1(states, actions)
        current_q2 = self.critic2(states, actions)
        
        critic_loss = F.mse_loss(current_q1, target) + F.mse_loss(current_q2, target)
        
        # ===== Actor æ›´æ–° =====
        new_actions, log_probs = self.actor.sample(states)
        q1 = self.critic1(states, new_actions)
        q2 = self.critic2(states, new_actions)
        q = torch.min(q1, q2)
        
        # æœ€å¤§åŒ– Q - Î± * log_prob
        actor_loss = (self.alpha * log_probs - q).mean()
        
        # ===== è½¯æ›´æ–°ç›®æ ‡ç½‘ç»œ =====
        self.soft_update(self.critic1, self.target_critic1)
        self.soft_update(self.critic2, self.target_critic2)
        
        return critic_loss, actor_loss
    
    def soft_update(self, source, target):
        for src_param, tgt_param in zip(source.parameters(), target.parameters()):
            tgt_param.data.copy_(self.tau * src_param.data + (1 - self.tau) * tgt_param.data)
```

### 4.3 Offline RL (ç¦»çº¿å¼ºåŒ–å­¦ä¹ )

**æ ¸å¿ƒé—®é¢˜**: åªæœ‰å›ºå®šçš„å†å²æ•°æ®é›†ï¼Œæ— æ³•ä¸ç¯å¢ƒäº¤äº’ã€‚

**æŒ‘æˆ˜**: åˆ†å¸ƒåç§» (Distribution Shift) - ç­–ç•¥å¯èƒ½é€‰æ‹©æ•°æ®é›†ä¸­æ²¡è§è¿‡çš„åŠ¨ä½œã€‚

#### 4.3.1 CQL (Conservative Q-Learning)

**æ€æƒ³**: ä¿å®ˆä¼°è®¡ Q å€¼ï¼Œæƒ©ç½šæ•°æ®é›†å¤–çš„åŠ¨ä½œã€‚

```
L_CQL = Î± Ã— E_{s ~ D}[ log Î£_a exp(Q(s,a)) - E_{a ~ D}[Q(s,a)] ] + L_TD
```

#### 4.3.2 IQL (Implicit Q-Learning)

**æ€æƒ³**: ä½¿ç”¨åˆ†ä½æ•°å›å½’é¿å…æ˜¾å¼æœ€å¤§åŒ– Qã€‚

#### 4.3.3 Recap (Ï€*0.6 çš„æ ¸å¿ƒç®—æ³•)

+**æ€æƒ³**: ä»æˆåŠŸå’Œå¤±è´¥çš„è½¨è¿¹ä¸­å­¦ä¹ ï¼ˆè¯¦ç»†æœºåˆ¶å¯å‚è€ƒ [pi0_6_dissection.md](./pi0_6_dissection.md) ä¸­çš„ Recap è§£æï¼‰ã€‚

```python
class RecapAlgorithm:
    """Ï€*0.6 çš„ Recap ç¦»çº¿ RL ç®—æ³•"""
    def __init__(self, policy, value_net):
        self.policy = policy
        self.value_net = value_net
    
    def label_trajectories(self, trajectories):
        """æ ‡æ³¨è½¨è¿¹: æˆåŠŸ vs å¤±è´¥"""
        labeled = []
        for traj in trajectories:
            success = traj['final_reward'] > 0  # ä»»åŠ¡æ˜¯å¦æˆåŠŸ
            for t, transition in enumerate(traj['transitions']):
                # å…³é”®: æ‰¾åˆ°å¤±è´¥è½¨è¿¹ä¸­"å¼€å§‹å‡ºé”™"çš„æ—¶åˆ»
                if not success and self.is_critical_failure(traj, t):
                    transition['label'] = 'negative'  # è´Ÿæ ·æœ¬
                elif success:
                    transition['label'] = 'positive'  # æ­£æ ·æœ¬
                labeled.append(transition)
        return labeled
    
    def is_critical_failure(self, traj, t):
        """åˆ¤æ–­æ˜¯å¦æ˜¯å¯¼è‡´å¤±è´¥çš„å…³é”®æ—¶åˆ»"""
        # ä½¿ç”¨ä»·å€¼å‡½æ•°ä¼°è®¡: å¦‚æœ V éª¤é™ï¼Œè¯´æ˜è¿™æ­¥å‡ºé”™äº†
        v_t = self.value_net(traj['states'][t])
        v_t1 = self.value_net(traj['states'][t+1])
        return (v_t - v_t1) > threshold
    
    def update(self, labeled_data):
        """å¯¹æ¯”å­¦ä¹ : æå‡æ­£æ ·æœ¬æ¦‚ç‡ï¼Œé™ä½è´Ÿæ ·æœ¬æ¦‚ç‡"""
        loss = 0
        for sample in labeled_data:
            state, action = sample['state'], sample['action']
            log_prob = self.policy.log_prob(state, action)
            
            if sample['label'] == 'positive':
                loss -= log_prob  # æå‡æ­£æ ·æœ¬æ¦‚ç‡
            else:
                loss += log_prob  # é™ä½è´Ÿæ ·æœ¬æ¦‚ç‡
        
        return loss / len(labeled_data)
```

## 5. å¥–åŠ±è®¾è®¡ (Reward Engineering)

### 5.1 ç¨€ç–å¥–åŠ± vs ç¨ å¯†å¥–åŠ±

| ç±»å‹ | ç¤ºä¾‹ | ä¼˜ç‚¹ | ç¼ºç‚¹ |
| :--- | :--- | :--- | :--- |
| **ç¨€ç–** | ä»»åŠ¡æˆåŠŸ +1ï¼Œå¦åˆ™ 0 | ä¸éœ€è¦äººå·¥è®¾è®¡ | éš¾ä»¥å­¦ä¹  |
| **ç¨ å¯†** | è·ç¦»ç›®æ ‡è¶Šè¿‘å¥–åŠ±è¶Šé«˜ | å­¦ä¹ å®¹æ˜“ | å¯èƒ½å¯¼è‡´å±€éƒ¨æœ€ä¼˜ |

### 5.2 å¥–åŠ±è®¾è®¡ç¤ºä¾‹

```python
def compute_reward(state, action, next_state, task_type="pick_and_place"):
    """æœºå™¨äººæ“ä½œä»»åŠ¡çš„å¥–åŠ±å‡½æ•°"""
    
    if task_type == "pick_and_place":
        gripper_pos = state['gripper_position']
        object_pos = state['object_position']
        target_pos = state['target_position']
        
        # é˜¶æ®µ 1: æ¥è¿‘ç‰©ä½“
        dist_to_object = np.linalg.norm(gripper_pos - object_pos)
        
        # é˜¶æ®µ 2: æŠ“å–ç‰©ä½“
        is_grasping = state['gripper_closed'] and dist_to_object < 0.02
        
        # é˜¶æ®µ 3: ç§»åŠ¨åˆ°ç›®æ ‡
        if is_grasping:
            dist_to_target = np.linalg.norm(object_pos - target_pos)
        else:
            dist_to_target = 1.0  # æƒ©ç½šæ²¡æŠ“åˆ°ç‰©ä½“
        
        # ç»„åˆå¥–åŠ±
        reward = -0.1 * dist_to_object  # æ¥è¿‘ç‰©ä½“
        reward += 0.5 * is_grasping     # æŠ“å–å¥–åŠ±
        reward -= 0.1 * dist_to_target  # æ¥è¿‘ç›®æ ‡
        
        # ç¨€ç–æˆåŠŸå¥–åŠ±
        if dist_to_target < 0.05 and is_grasping:
            reward += 10.0  # ä»»åŠ¡æˆåŠŸ
        
        return reward
```

### 5.3 å¥–åŠ±å¡‘å½¢ (Reward Shaping)

```python
def shaped_reward(state, next_state, potential_func, gamma=0.99):
    """
    åŸºäºåŠ¿å‡½æ•°çš„å¥–åŠ±å¡‘å½¢ (ä¸æ”¹å˜æœ€ä¼˜ç­–ç•¥)
    F(s, s') = Î³ * Î¦(s') - Î¦(s)
    """
    phi_s = potential_func(state)
    phi_s_next = potential_func(next_state)
    shaping = gamma * phi_s_next - phi_s
    return shaping
```

## 6. RL + VLA çš„ç»“åˆ (RL + VLA Integration)

### 6.1 RLHF å®Œæ•´æµç¨‹ (RLHF Pipeline)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    RLHF ä¸‰é˜¶æ®µæµç¨‹                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚   é˜¶æ®µ 1: SFT (Supervised Fine-Tuning)                          â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚  é¢„è®­ç»ƒæ¨¡å‹ + é«˜è´¨é‡æ•°æ® â†’ åŸºç¡€ç­–ç•¥ Ï€_SFT                 â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                          â”‚                                      â”‚
â”‚                          â–¼                                      â”‚
â”‚   é˜¶æ®µ 2: Reward Model Training                                 â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚  æ”¶é›†äººç±»åå¥½ (A > B) â†’ è®­ç»ƒå¥–åŠ±æ¨¡å‹ R(s, a)              â”‚   â”‚
â”‚   â”‚  Loss: -log Ïƒ(R(y_w) - R(y_l))  (Bradley-Terry)          â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                          â”‚                                      â”‚
â”‚                          â–¼                                      â”‚
â”‚   é˜¶æ®µ 3: RL Fine-tuning (PPO)                                  â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚  ä½¿ç”¨ R(s, a) ä½œä¸ºå¥–åŠ±ï¼ŒPPO ä¼˜åŒ–ç­–ç•¥                      â”‚   â”‚
â”‚   â”‚  + KL æƒ©ç½š: é˜²æ­¢åç¦» Ï€_SFT å¤ªè¿œ                          â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                 â”‚
â”‚   éœ€è¦åŒæ—¶åŠ è½½: Ï€_SFT (å‚è€ƒ), Ï€_Î¸ (è®­ç»ƒ), R (å¥–åŠ±), V (ä»·å€¼)    â”‚
â”‚   æ˜¾å­˜éœ€æ±‚: 4 ä¸ªæ¨¡å‹ â†’ éå¸¸æ˜‚è´µ!                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

```python
class RLHF_VLA:
    """ä½¿ç”¨äººç±»åé¦ˆå¼ºåŒ–å­¦ä¹ æ”¹è¿› VLA"""
    def __init__(self, vla_model, reward_model):
        self.vla = vla_model
        self.reward_model = reward_model  # ä»äººç±»åå¥½è®­ç»ƒ
    
    def collect_comparisons(self, states, num_samples=2):
        """æ”¶é›†äººç±»åå¥½æ¯”è¾ƒ"""
        actions = [self.vla.sample(states) for _ in range(num_samples)]
        # äººç±»é€‰æ‹©æ›´å¥½çš„åŠ¨ä½œ
        human_preference = get_human_preference(states, actions)
        return actions, human_preference
    
    def train_reward_model(self, comparisons):
        """ä»åå¥½æ•°æ®è®­ç»ƒå¥–åŠ±æ¨¡å‹"""
        for (action_win, action_lose, state) in comparisons:
            r_win = self.reward_model(state, action_win)
            r_lose = self.reward_model(state, action_lose)
            
            # Bradley-Terry æ¨¡å‹
            loss = -torch.log(torch.sigmoid(r_win - r_lose))
            loss.backward()
    
    def rl_finetune(self, states):
        """ä½¿ç”¨å­¦åˆ°çš„å¥–åŠ±è¿›è¡Œ RL å¾®è°ƒ"""
        actions = self.vla.sample(states)
        rewards = self.reward_model(states, actions)
        
        # PPO æ›´æ–°
        self.ppo_update(states, actions, rewards)
```

### 6.2 ä»æ¼”ç¤ºåˆå§‹åŒ– RL (Demo-Guided RL)

```python
class DemoGuidedRL:
    """ç»“åˆ BC é¢„è®­ç»ƒå’Œ RL å¾®è°ƒ"""
    def __init__(self, policy):
        self.policy = policy
    
    def phase1_bc_pretrain(self, demonstrations):
        """Phase 1: è¡Œä¸ºå…‹éš†é¢„è®­ç»ƒ"""
        for state, action in demonstrations:
            pred_action = self.policy(state)
            loss = F.mse_loss(pred_action, action)
            loss.backward()
    
    def phase2_rl_finetune(self, env, num_episodes=1000):
        """Phase 2: RL å¾®è°ƒè¶…è¶Šæ¼”ç¤º"""
        for episode in range(num_episodes):
            state = env.reset()
            while not done:
                action = self.policy.sample(state)
                next_state, reward, done, _ = env.step(action)
                
                # å­˜å‚¨ç»éªŒ
                self.buffer.add(state, action, reward, next_state, done)
                state = next_state
            
            # SAC/PPO æ›´æ–°
            self.rl_update()
```

## 7. GR-RL: VLA + RL èåˆæ¡†æ¶æ¡ˆä¾‹ (ByteDance Seed)

> **GR-RL**: å­—èŠ‚è·³åŠ¨ Seed å›¢é˜Ÿ 2025 å¹´å‘å¸ƒçš„æœºå™¨äººå­¦ä¹ æ¡†æ¶ï¼Œä¸“ä¸º**é•¿æ—¶ç¨‹ã€çµå·§ã€é«˜ç²¾åº¦æ“ä½œ**è®¾è®¡ã€‚
> [[å®˜ç½‘](https://seed.bytedance.com/en/gr_rl)]

### 7.1 æ ¸å¿ƒæ´å¯Ÿ

GR-RL æ­ç¤ºäº†ä¸€ä¸ªè¢«è¡Œä¸šé•¿æœŸå¿½ç•¥çš„äº‹å®ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               GR-RL è§£å†³çš„ä¸‰å¤§æ ¸å¿ƒé—®é¢˜                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚   é—®é¢˜ 1: æ¼”ç¤ºæ•°æ®æœ‰å™ªå£°                                        â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚  äººç±»æ¼”ç¤ºä¸­å­˜åœ¨å¤±è¯¯ï¼ˆé‹å¸¦æ»‘è„±ã€åå¤å°è¯•ï¼‰                  â”‚   â”‚
â”‚   â”‚  ç›´æ¥å–‚ç»™æ¨¡å‹ â†’ å­¦ä¼š"æ€ä¹ˆçŠ¯é”™"                           â”‚   â”‚
â”‚   â”‚  ğŸ’¡ è§£å†³: Offline RL Critic ç­›é€‰é«˜è´¨é‡æ•°æ®                â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                 â”‚
â”‚   é—®é¢˜ 2: è®­ç»ƒ-éƒ¨ç½²ä¸ä¸€è‡´                                       â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚  è®­ç»ƒ: è¾“å‡º"åŸå§‹åŠ¨ä½œ"                                    â”‚   â”‚
â”‚   â”‚  éƒ¨ç½²: æ‰§è¡Œ"å¹³æ»‘åå¤„ç†åŠ¨ä½œ"                              â”‚   â”‚
â”‚   â”‚  ğŸ’¡ è§£å†³: åœ¨çº¿ RL å¯¹é½ï¼ˆæ½œåœ¨ç©ºé—´æ¢ç´¢ï¼‰                    â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                 â”‚
â”‚   é—®é¢˜ 3: æ•°æ®é‡æœ‰é™                                            â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚  é«˜ç²¾åº¦ä»»åŠ¡çš„æ¼”ç¤ºæ•°æ®é‡‡é›†æˆæœ¬é«˜                           â”‚   â”‚
â”‚   â”‚  ğŸ’¡ è§£å†³: å½¢æ€å¯¹ç§°æ€§å¢å¼ºï¼ˆé•œåƒç¿»è½¬æ•°æ®ç¿»å€ï¼‰              â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 7.2 æ¨¡å‹æ¶æ„

GR-RL é‡‡ç”¨ **Mixture-of-Transformer (MoT)** æ··åˆæ¶æ„ï¼Œæ€»å‚æ•°é‡ **50 äº¿**ã€‚

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    GR-RL æ¶æ„ (5B å‚æ•°)                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚              VLA Policy (Ï€)                              â”‚   â”‚
â”‚   â”‚                                                          â”‚   â”‚
â”‚   â”‚   Vision Encoder â”€â”€â”                                     â”‚   â”‚
â”‚   â”‚                    â”‚                                     â”‚   â”‚
â”‚   â”‚   Language Encoder â”œâ”€â”€â†’ MoT Backbone â”€â”€â†’ Action Head     â”‚   â”‚
â”‚   â”‚                    â”‚                                     â”‚   â”‚
â”‚   â”‚   State Encoder â”€â”€â”€â”˜                                     â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                            â”‚                                    â”‚
â”‚                            â”‚ å…±äº«ç‰¹å¾                           â”‚
â”‚                            â–¼                                    â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚           Multi-task Critic (ä»»åŠ¡è¿›åº¦è¯„ä¼°)               â”‚   â”‚
â”‚   â”‚                                                          â”‚   â”‚
â”‚   â”‚   è¾“å…¥: (state, action, task_embedding)                  â”‚   â”‚
â”‚   â”‚   è¾“å‡º: ä»»åŠ¡è¿›åº¦å€¼ V(s) âˆˆ [0, 1]                         â”‚   â”‚
â”‚   â”‚                                                          â”‚   â”‚
â”‚   â”‚   åŠŸèƒ½:                                                  â”‚   â”‚
â”‚   â”‚   â€¢ è¯„ä¼°æ¯ä¸€æ­¥å¯¹æ•´ä½“ä»»åŠ¡çš„è´¡çŒ®                           â”‚   â”‚
â”‚   â”‚   â€¢ è¿›å±•å¿« â†’ å€¼é«˜ï¼›å‡ºé”™ â†’ å€¼éª¤é™                        â”‚   â”‚
â”‚   â”‚   â€¢ ç”¨äºç­›é€‰"éæœ€ä¼˜æ•°æ®"                                â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 7.3 å¤šé˜¶æ®µè®­ç»ƒæµç¨‹

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 GR-RL ä¸‰é˜¶æ®µè®­ç»ƒæµç¨‹                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚   é˜¶æ®µ 1: æ¼”ç¤ºè½¨è¿¹ç­›é€‰ (Offline RL Critic)                      â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚  åŸå§‹æ¼”ç¤ºæ•°æ® (å«å¤±è¯¯)                                   â”‚   â”‚
â”‚   â”‚        â”‚                                                 â”‚   â”‚
â”‚   â”‚        â–¼                                                 â”‚   â”‚
â”‚   â”‚  Critic è¯„ä¼°æ¯æ­¥è¿›åº¦å€¼ V(s)                              â”‚   â”‚
â”‚   â”‚        â”‚                                                 â”‚   â”‚
â”‚   â”‚        â”œâ”€â”€ V éª¤é™ â†’ æ ‡è®°ä¸º"å¤±è´¥æ—¶åˆ»"â†’ å‰”é™¤              â”‚   â”‚
â”‚   â”‚        â”‚                                                 â”‚   â”‚
â”‚   â”‚        â””â”€â”€ V ç¨³æ­¥ä¸Šå‡ â†’ ä¿ç•™ä¸ºé«˜è´¨é‡æ•°æ®                 â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                          â”‚                                      â”‚
â”‚                          â–¼                                      â”‚
â”‚   é˜¶æ®µ 2: å½¢æ€å¯¹ç§°æ€§å¢å¼º (Data Augmentation)                    â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚  å¯¹ç­›é€‰åçš„æ•°æ®è¿›è¡Œé•œåƒç¿»è½¬:                             â”‚   â”‚
â”‚   â”‚  â€¢ å›¾åƒæ°´å¹³ç¿»è½¬ + å·¦å³æ‰‹è§†è§’äº¤æ¢                         â”‚   â”‚
â”‚   â”‚  â€¢ çŠ¶æ€/åŠ¨ä½œåœ¨ä¸–ç•Œåæ ‡ç³»é•œåƒå˜æ¢                         â”‚   â”‚
â”‚   â”‚  â€¢ è¯­è¨€æŒ‡ä»¤ç©ºé—´æè¿°è°ƒæ•´ ("å·¦è¾¹" â†’ "å³è¾¹")               â”‚   â”‚
â”‚   â”‚                                                          â”‚   â”‚
â”‚   â”‚  æ•ˆæœ: æ•°æ®é‡ç¿»å€ï¼Œæ— éœ€é¢å¤–é‡‡é›†æˆæœ¬                      â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                          â”‚                                      â”‚
â”‚                          â–¼                                      â”‚
â”‚   é˜¶æ®µ 3: åœ¨çº¿å¼ºåŒ–å­¦ä¹ ä¼˜åŒ– (Online RL Alignment)                â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚  é—®é¢˜: è®­ç»ƒæ—¶è¾“å‡º â‰  éƒ¨ç½²æ—¶æ‰§è¡Œçš„åŠ¨ä½œ                     â”‚   â”‚
â”‚   â”‚                                                          â”‚   â”‚
â”‚   â”‚  æ–¹æ¡ˆ: åœ¨æ‰©æ•£æ¨¡å‹çš„æ½œåœ¨å™ªå£°ç©ºé—´ä¸­è¿›è¡Œç»“æ„åŒ–æ¢ç´¢          â”‚   â”‚
â”‚   â”‚        (ä¸åœ¨åŸå§‹åŠ¨ä½œç©ºé—´ç›²ç›®åŠ å™ªå£°)                       â”‚   â”‚
â”‚   â”‚                                                          â”‚   â”‚
â”‚   â”‚  æ•ˆæœ: å¼¥åˆè®­ç»ƒ-éƒ¨ç½²é¸¿æ²Ÿï¼Œç¨³å®šé•¿æ—¶ç¨‹ç²¾ç»†æ“ä½œ             â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 7.4 Critic è¿›åº¦è¯„ä¼°åŸç†

```python
class TaskProgressCritic:
    """GR-RL çš„ä»»åŠ¡è¿›åº¦è¯„ä¼°å™¨"""
    def __init__(self, encoder, threshold=0.3):
        self.encoder = encoder  # å…±äº« VLA ç¼–ç å™¨
        self.value_head = nn.Linear(hidden_dim, 1)
        self.threshold = threshold  # è¿›åº¦éª¤é™é˜ˆå€¼
    
    def forward(self, state, task_embedding):
        """è¯„ä¼°å½“å‰çŠ¶æ€çš„ä»»åŠ¡è¿›åº¦"""
        features = self.encoder(state, task_embedding)
        progress = torch.sigmoid(self.value_head(features))  # [0, 1]
        return progress
    
    def filter_demonstrations(self, trajectory):
        """ç­›é€‰é«˜è´¨é‡æ¼”ç¤ºæ•°æ®"""
        filtered = []
        for t in range(len(trajectory) - 1):
            v_t = self.forward(trajectory[t]['state'], trajectory[t]['task'])
            v_t1 = self.forward(trajectory[t+1]['state'], trajectory[t+1]['task'])
            
            progress_drop = v_t - v_t1
            
            if progress_drop > self.threshold:
                # è¿›åº¦éª¤é™ â†’ å¤±è´¥æ—¶åˆ»ï¼Œå‰”é™¤
                print(f"âš ï¸ æ£€æµ‹åˆ°å¤±è´¥æ—¶åˆ» t={t}, drop={progress_drop:.2f}")
                continue
            
            filtered.append(trajectory[t])
        
        return filtered
```

### 7.5 ä¸å…¶ä»– VLA æ–¹æ³•å¯¹æ¯”

| æ–¹æ³• | æ ¸å¿ƒæ€è·¯ | æ•°æ®åˆ©ç”¨ | åœ¨çº¿å­¦ä¹  | ç²¾ç»†æ“ä½œ |
| :--- | :--- | :--- | :--- | :--- |
| **BC (ä¼ ç»Ÿ VLA)** | çº¯æ¨¡ä»¿ | ä¸ç­›é€‰ | âŒ | å—é™ |
| **Ï€0.6 (Recap)** | Offline RL ç­›é€‰ | âœ… ç­›é€‰ | âŒ | ä¸­ç­‰ |
| **GR-RL** | Offline + Online RL | âœ… ç­›é€‰ + å¢å¼º | âœ… | âœ… é«˜ç²¾åº¦ |

### 7.6 GR-RL çš„"é€šæ‰è½¬ä¸“å®¶"èŒƒå¼

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               GR-RL "é€šæ‰è½¬ä¸“å®¶" æ–¹æ³•è®º                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚   Step 1: é€šæ‰é¢„è®­ç»ƒ (å¦‚ GR-3, 40B VLA)                         â”‚
â”‚           æ³›åŒ–ã€æ–°ç¯å¢ƒé€‚åº”ã€åŸºç¡€æ“ä½œèƒ½åŠ›                         â”‚
â”‚                    â”‚                                            â”‚
â”‚                    â–¼                                            â”‚
â”‚   Step 2: ä¸“å®¶å¾®è°ƒ (GR-RL)                                      â”‚
â”‚           â€¢ RL Critic ç­›é€‰é«˜è´¨é‡ä¸“å®¶æ•°æ®                        â”‚
â”‚           â€¢ å½¢æ€å¯¹ç§°å¢å¼ºæå‡æ³›åŒ–                                â”‚
â”‚           â€¢ åœ¨çº¿ RL å¯¹é½éƒ¨ç½²å·®å¼‚                                â”‚
â”‚                    â”‚                                            â”‚
â”‚                    â–¼                                            â”‚
â”‚   Step 3: é«˜ç²¾åº¦ä»»åŠ¡ (å¦‚ç©¿é‹å¸¦)                                 â”‚
â”‚           é•¿æ—¶ç¨‹ã€çµå·§ã€é«˜ç²¾åº¦æ“ä½œ                               â”‚
â”‚                                                                 â”‚
â”‚   ğŸ’¡ æ ¸å¿ƒ: RL ä¸æ˜¯æ›¿ä»£ BCï¼Œè€Œæ˜¯"æçº¯" + "å¯¹é½"                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 7.7 é¢è¯• Q&A

**Q1: GR-RL ä¸ Ï€0.6 çš„ Recap æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ**

A:
| å¯¹æ¯” | Ï€0.6 Recap | GR-RL |
| :--- | :--- | :--- |
| **æ•°æ®ç­›é€‰** | åŸºäºæˆåŠŸ/å¤±è´¥æ ‡ç­¾ | åŸºäºè¿›åº¦å€¼éª¤é™æ£€æµ‹ |
| **åœ¨çº¿å­¦ä¹ ** | âŒ çº¯ Offline | âœ… Offline + Online |
| **æ¢ç´¢ç©ºé—´** | - | æ‰©æ•£æ¨¡å‹æ½œåœ¨ç©ºé—´ |
| **æ•°æ®å¢å¼º** | æ—  | å½¢æ€å¯¹ç§°é•œåƒ |

**Q2: ä¸ºä»€ä¹ˆåœ¨æ½œåœ¨å™ªå£°ç©ºé—´æ¢ç´¢è€Œä¸æ˜¯åŠ¨ä½œç©ºé—´ï¼Ÿ**

A:
- **åŠ¨ä½œç©ºé—´å™ªå£°**: å¯èƒ½äº§ç”Ÿä¸åˆç†åŠ¨ä½œï¼ˆå¦‚å…³èŠ‚è¶…é™ï¼‰
- **æ½œåœ¨ç©ºé—´å™ªå£°**: ç»“æ„åŒ–ï¼Œä¿æŒåŠ¨ä½œè¯­ä¹‰åˆç†æ€§
- **æ•ˆç‡**: æ½œåœ¨ç©ºé—´ç»´åº¦ä½ï¼Œæ¢ç´¢æ•ˆç‡æ›´é«˜

**Q3: GR-RL çš„å±€é™æ€§æ˜¯ä»€ä¹ˆï¼Ÿ**

A:
- **å®éªŒæ¡ä»¶**: è®ºæ–‡ä¸­é‹å­”å¤„äº"ç†æƒ³çŠ¶æ€"ï¼ŒçœŸå®åœºæ™¯æ›´å¤æ‚
- **æ³›åŒ–æ€§**: å¯¹æœªè§è¿‡çš„ç‰©ä½“/åœºæ™¯ä»éœ€éªŒè¯
- **è®¡ç®—æˆæœ¬**: 50B å‚æ•° + åœ¨çº¿ RL è®­ç»ƒæˆæœ¬é«˜

## 8. é¢è¯•é«˜é¢‘é—®é¢˜ (Q&A)

**Q1: VLA ä¸­ BC å’Œ RL å¦‚ä½•å–èˆ?**

A:
- **ä¼˜å…ˆ BC**: æ•°æ®å……è¶³ã€ä»»åŠ¡ç®€å•ã€éœ€è¦å¿«é€Ÿè¿­ä»£
- **å¼•å…¥ RL**: éœ€è¦è¶…è¶Šäººç±»ã€é•¿åºåˆ—ä¼˜åŒ–ã€ç¨€ç–å¥–åŠ±ä»»åŠ¡
- **æœ€ä½³å®è·µ**: BC é¢„è®­ç»ƒ + RL å¾®è°ƒ (å¦‚ Ï€*0.6)

**Q2: Offline RL å’Œ Online RL çš„æ ¸å¿ƒåŒºåˆ«?**

A:
- **Online RL**: å¯ä»¥ä¸ç¯å¢ƒäº¤äº’ï¼Œæ¢ç´¢æ–°çŠ¶æ€
- **Offline RL**: åªæœ‰å›ºå®šæ•°æ®é›†ï¼Œéœ€è¦å¤„ç†åˆ†å¸ƒåç§»
- **VLA ç°çŠ¶**: å› ä¸ºçœŸæœºäº¤äº’æˆæœ¬é«˜ï¼ŒOffline RL æ›´å®ç”¨

**Q3: SAC ä¸­æ¸©åº¦å‚æ•° Î± çš„ä½œç”¨?**

A:
- **Î± å¤§**: æ›´é‡è§†ç†µ â†’ æ›´å¤šæ¢ç´¢ â†’ ç­–ç•¥æ›´éšæœº
- **Î± å°**: æ›´é‡è§†å¥–åŠ± â†’ æ›´å¤šåˆ©ç”¨ â†’ ç­–ç•¥æ›´ç¡®å®š
- **è‡ªåŠ¨è°ƒèŠ‚**: å¯ä»¥å°† Î± è®¾ä¸ºå¯å­¦ä¹ å‚æ•°

**Q4: ä¸ºä»€ä¹ˆ PPO æ¯” TRPO æ›´æµè¡Œ?**

A:
- **ç®€å•**: PPO åªéœ€ Clipï¼ŒTRPO éœ€è¦è®¡ç®— Fisher çŸ©é˜µ
- **é«˜æ•ˆ**: PPO å¯ä»¥ç”¨ SGDï¼ŒTRPO éœ€è¦å…±è½­æ¢¯åº¦
- **æ•ˆæœ**: åœ¨å¤§å¤šæ•°ä»»åŠ¡ä¸Šæ€§èƒ½ç›¸å½“

**Q5: Recap ç®—æ³•ç›¸æ¯”ä¼ ç»Ÿ Offline RL çš„ä¼˜åŠ¿?**

A:
- **åˆ©ç”¨å¤±è´¥æ•°æ®**: ä¼ ç»Ÿæ–¹æ³•åªæ¨¡ä»¿æˆåŠŸè½¨è¿¹ï¼ŒRecap ä»å¤±è´¥ä¸­å­¦ä¹ 
- **å…³é”®æ—¶åˆ»è¯†åˆ«**: é€šè¿‡ä»·å€¼å‡½æ•°å®šä½"å‡ºé”™ç‚¹"
- **ç®€å•é«˜æ•ˆ**: ä¸éœ€è¦å¤æ‚çš„çº¦æŸä¼˜åŒ–

**Q6: RLHF çš„åŸºæœ¬æµç¨‹æ˜¯ä»€ä¹ˆï¼Ÿä¸ DPO çš„å·®å¼‚æ˜¯ä»€ä¹ˆï¼Ÿ**

A: **RLHF ä¸‰é˜¶æ®µæµç¨‹**:
1. **SFT**: åœ¨é«˜è´¨é‡æ•°æ®ä¸Šç›‘ç£å¾®è°ƒï¼Œå¾—åˆ°åŸºç¡€ç­–ç•¥ $\pi_{SFT}$
2. **Reward Model**: ä»äººç±»åå¥½æ•°æ®è®­ç»ƒå¥–åŠ±æ¨¡å‹ $R(s, a)$
3. **RL (PPO)**: ä½¿ç”¨ $R$ ä½œä¸ºå¥–åŠ±ï¼ŒPPO ä¼˜åŒ–ç­–ç•¥ï¼ŒåŠ  KL æƒ©ç½šé˜²æ­¢åç¦» $\pi_{SFT}$

**DPO (Direct Preference Optimization)** çš„å·®å¼‚:
- **è·³è¿‡ Reward Model**: ç›´æ¥ä»åå¥½æ•°æ®ä¼˜åŒ–ç­–ç•¥
- **æ•°å­¦æ¨å¯¼**: å°† RL ç›®æ ‡é‡å‚æ•°åŒ–ä¸ºåˆ†ç±»é—®é¢˜

```
L_DPO = -E[ log Ïƒ( Î² Ã— log(Ï€_Î¸(y_w|x) / Ï€_ref(y_w|x)) - Î² Ã— log(Ï€_Î¸(y_l|x) / Ï€_ref(y_l|x)) ) ]
```

| å¯¹æ¯” | RLHF | DPO |
| :--- | :--- | :--- |
| **é˜¶æ®µæ•°** | 3 é˜¶æ®µ | 1 é˜¶æ®µ |
| **æ¨¡å‹æ•°** | 4 ä¸ª (Ï€, Ï€_ref, R, V) | 2 ä¸ª (Ï€, Ï€_ref) |
| **ç¨³å®šæ€§** | PPO æ˜“å´© | æ›´ç¨³å®š |
| **è®¡ç®—é‡** | é«˜ | ä½ |
| **æ•ˆæœ** | ç•¥ä¼˜ (ç†è®ºä¸Š) | æ¥è¿‘ RLHF |

## 9. ä¸»æµ RL æ¡†æ¶ (RL Frameworks)

### 8.1 æ¡†æ¶å¯¹æ¯”

| æ¡†æ¶ | å®šä½ | ä¼˜åŠ¿ | é€‚ç”¨åœºæ™¯ |
| :--- | :--- | :--- | :--- |
| **Stable Baselines3** | æ˜“ç”¨ã€ç¨³å®š | æ–‡æ¡£å®Œå–„ï¼ŒAPI ç®€æ´ | å¿«é€Ÿå®éªŒã€æ•™å­¦ |
| **RLlib** | åˆ†å¸ƒå¼ã€å¯æ‰©å±• | Ray ç”Ÿæ€ï¼Œå¤š GPU/èŠ‚ç‚¹ | å¤§è§„æ¨¡è®­ç»ƒ |
| **CleanRL** | å•æ–‡ä»¶å®ç° | ä»£ç æ¸…æ™°ï¼Œæ˜“äºä¿®æ”¹ | å­¦ä¹ ã€ç ”ç©¶ |
| **TorchRL** | PyTorch å®˜æ–¹ | ä¸ PyTorch æ·±åº¦é›†æˆ | ç”Ÿäº§çº§åº”ç”¨ |
| **SKRL** | Isaac Lab é›†æˆ | GPU å¹¶è¡Œï¼Œæœºå™¨äººä¸“ç”¨ | æœºå™¨äºº RL |

### 8.2 Stable Baselines3 (SB3)

**ç‰¹ç‚¹**: æœ€æ˜“ä¸Šæ‰‹çš„ RL åº“ï¼ŒAPI è®¾è®¡ä¼˜é›…ã€‚

```python
## Stable Baselines3 å¿«é€Ÿä¸Šæ‰‹
from stable_baselines3 import PPO, SAC, TD3
from stable_baselines3.common.env_util import make_vec_env
from stable_baselines3.common.callbacks import EvalCallback

## åˆ›å»ºå‘é‡åŒ–ç¯å¢ƒ
env = make_vec_env("Pendulum-v1", n_envs=4)

## åˆ›å»ºæ¨¡å‹
model = PPO(
    "MlpPolicy",
    env,
    learning_rate=3e-4,
    n_steps=2048,
    batch_size=64,
    n_epochs=10,
    gamma=0.99,
    verbose=1,
    tensorboard_log="./logs/"
)

## è®­ç»ƒ
model.learn(total_timesteps=100_000, callback=EvalCallback(env))

## ä¿å­˜/åŠ è½½
model.save("ppo_pendulum")
model = PPO.load("ppo_pendulum")

## æ¨ç†
obs = env.reset()
for _ in range(1000):
    action, _ = model.predict(obs, deterministic=True)
    obs, reward, done, info = env.step(action)
```

**è‡ªå®šä¹‰ç½‘ç»œ**:

```python
from stable_baselines3.common.torch_layers import BaseFeaturesExtractor
import torch.nn as nn

class CustomCNN(BaseFeaturesExtractor):
    """è‡ªå®šä¹‰ CNN ç‰¹å¾æå–å™¨ (ç”¨äºå›¾åƒè¾“å…¥)"""
    def __init__(self, observation_space, features_dim=256):
        super().__init__(observation_space, features_dim)
        n_input_channels = observation_space.shape[0]
        self.cnn = nn.Sequential(
            nn.Conv2d(n_input_channels, 32, kernel_size=8, stride=4),
            nn.ReLU(),
            nn.Conv2d(32, 64, kernel_size=4, stride=2),
            nn.ReLU(),
            nn.Conv2d(64, 64, kernel_size=3, stride=1),
            nn.ReLU(),
            nn.Flatten(),
        )
        # è®¡ç®—è¾“å‡ºç»´åº¦
        with torch.no_grad():
            n_flatten = self.cnn(torch.zeros(1, *observation_space.shape)).shape[1]
        self.linear = nn.Linear(n_flatten, features_dim)
    
    def forward(self, observations):
        return self.linear(self.cnn(observations))

## ä½¿ç”¨è‡ªå®šä¹‰ç½‘ç»œ
policy_kwargs = dict(
    features_extractor_class=CustomCNN,
    features_extractor_kwargs=dict(features_dim=256),
)
model = PPO("CnnPolicy", env, policy_kwargs=policy_kwargs)
```

### 8.3 RLlib (Ray)

**ç‰¹ç‚¹**: åˆ†å¸ƒå¼è®­ç»ƒé¦–é€‰ï¼Œæ”¯æŒå¤š GPU/å¤šèŠ‚ç‚¹ã€‚

```python
## RLlib åˆ†å¸ƒå¼è®­ç»ƒ
from ray import tune
from ray.rllib.algorithms.ppo import PPOConfig

## é…ç½®
config = (
    PPOConfig()
    .environment("CartPole-v1")
    .framework("torch")
    .rollouts(
        num_rollout_workers=4,      # å¹¶è¡Œ worker æ•°
        num_envs_per_worker=2,      # æ¯ä¸ª worker çš„ç¯å¢ƒæ•°
    )
    .training(
        lr=5e-5,
        gamma=0.99,
        train_batch_size=4000,
        sgd_minibatch_size=128,
        num_sgd_iter=30,
        model={"fcnet_hiddens": [256, 256]},
    )
    .resources(
        num_gpus=1,                  # è®­ç»ƒç”¨ GPU
        num_cpus_per_worker=1,
    )
)

## è®­ç»ƒ
algo = config.build()
for i in range(100):
    result = algo.train()
    print(f"Iter {i}: reward = {result['episode_reward_mean']:.2f}")

## æˆ–ä½¿ç”¨ Ray Tune è¿›è¡Œè¶…å‚æœç´¢
tune.run(
    "PPO",
    config=config.to_dict(),
    stop={"episode_reward_mean": 200},
    num_samples=4,  # å¹¶è¡Œæœç´¢ 4 ç»„è¶…å‚
)
```

**å¤šæ™ºèƒ½ä½“ RL**:

```python
## RLlib å¤šæ™ºèƒ½ä½“
from ray.rllib.algorithms.ppo import PPOConfig

config = (
    PPOConfig()
    .environment("MultiAgentCartPole")
    .multi_agent(
        policies={"policy_0", "policy_1"},
        policy_mapping_fn=lambda agent_id, episode, **kwargs: f"policy_{agent_id}",
    )
)
```

### 8.4 SKRL (Isaac Lab é›†æˆ)

**ç‰¹ç‚¹**: ä¸“ä¸º Isaac Lab è®¾è®¡ï¼ŒGPU å¹¶è¡Œè®­ç»ƒã€‚

```python
## SKRL + Isaac Lab
from skrl.agents.torch.ppo import PPO, PPO_DEFAULT_CONFIG
from skrl.trainers.torch import SequentialTrainer
from skrl.envs.wrappers.torch import wrap_env

## åŒ…è£… Isaac Lab ç¯å¢ƒ
env = wrap_env(isaac_lab_env)

## é…ç½®
cfg = PPO_DEFAULT_CONFIG.copy()
cfg["rollouts"] = 16
cfg["learning_epochs"] = 8
cfg["mini_batches"] = 4
cfg["discount_factor"] = 0.99
cfg["lambda"] = 0.95
cfg["learning_rate"] = 3e-4

## åˆ›å»º Agent
agent = PPO(
    models={"policy": policy_net, "value": value_net},
    memory=memory,
    cfg=cfg,
    observation_space=env.observation_space,
    action_space=env.action_space,
)

## è®­ç»ƒ
trainer = SequentialTrainer(cfg=trainer_cfg, env=env, agents=agent)
trainer.train()
```

### 8.5 æ¡†æ¶é€‰æ‹©æŒ‡å—

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    RL æ¡†æ¶é€‰æ‹©å†³ç­–æ ‘                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚   Q1: æ˜¯å¦éœ€è¦åˆ†å¸ƒå¼è®­ç»ƒ (å¤š GPU/å¤šèŠ‚ç‚¹)?                        â”‚
â”‚       â”‚                                                         â”‚
â”‚       â”œâ”€â”€ æ˜¯ â†’ RLlib (Ray ç”Ÿæ€ï¼Œåˆ†å¸ƒå¼é¦–é€‰)                     â”‚
â”‚       â”‚                                                         â”‚
â”‚       â””â”€â”€ å¦ â†’ Q2: æ˜¯å¦ä½¿ç”¨ Isaac Lab?                          â”‚
â”‚                    â”‚                                            â”‚
â”‚                    â”œâ”€â”€ æ˜¯ â†’ SKRL (å®˜æ–¹æ¨è)                     â”‚
â”‚                    â”‚                                            â”‚
â”‚                    â””â”€â”€ å¦ â†’ Q3: ç›®æ ‡æ˜¯ä»€ä¹ˆ?                     â”‚
â”‚                                 â”‚                               â”‚
â”‚                                 â”œâ”€â”€ å¿«é€Ÿå®éªŒ â†’ SB3              â”‚
â”‚                                 â”œâ”€â”€ å­¦ä¹ ç ”ç©¶ â†’ CleanRL          â”‚
â”‚                                 â””â”€â”€ ç”Ÿäº§éƒ¨ç½² â†’ TorchRL          â”‚
â”‚                                                                 â”‚
â”‚   ğŸ’¡ VLA å¸¸ç”¨ç»„åˆ:                                              â”‚
â”‚   â€¢ ä»¿çœŸè®­ç»ƒ: Isaac Lab + SKRL/RSL-RL                           â”‚
â”‚   â€¢ å¤§è§„æ¨¡: RLlib + Ray Cluster                                 â”‚
â”‚   â€¢ å¿«é€ŸéªŒè¯: SB3 + Gymnasium                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 8.6 TORCS ä¸è‡ªåŠ¨é©¾é©¶ RL

**TORCS** (The Open Racing Car Simulator) æ˜¯ç»å…¸çš„è‡ªåŠ¨é©¾é©¶ RL æµ‹è¯•å¹³å°ã€‚

```python
## TORCS ç¯å¢ƒä½¿ç”¨ (gym_torcs)
import gym
import gym_torcs

env = gym.make("Torcs-v0", vision=True, throttle=True)

## è§‚æµ‹ç©ºé—´: è½¦è¾†çŠ¶æ€ + å¯é€‰è§†è§‰
## - speed, angle, trackPos, track sensors (19)
## - å¯é€‰: RGB å›¾åƒ (64x64x3)

## åŠ¨ä½œç©ºé—´: [steering, throttle, brake]
## - steering: [-1, 1]
## - throttle: [0, 1]
## - brake: [0, 1]

obs = env.reset()
for _ in range(1000):
    action = agent.act(obs)  # ä½ çš„ç­–ç•¥
    obs, reward, done, info = env.step(action)
    if done:
        obs = env.reset()
```

**æ³¨**: TORCS ä¸»è¦ç”¨äºè‡ªåŠ¨é©¾é©¶ç ”ç©¶ï¼ŒVLA æœºå™¨äººé¢†åŸŸæ›´å¸¸ç”¨ Isaac Lab/MuJoCoã€‚

## 10. LIBERO ç»ˆèº«å­¦ä¹ åŸºå‡† (Lifelong Learning Benchmark)

> **LIBERO**: Benchmarking Knowledge Transfer for Lifelong Robot Learning [[GitHub](https://github.com/Lifelong-Robot-Learning/LIBERO)] [[Paper](https://arxiv.org/abs/2306.03310)]

### 9.1 ä¸ºä»€ä¹ˆå…³æ³¨ LIBERO?

- **ä¸»æµåŸºå‡†**: å¤šä»»åŠ¡ / ç»ˆèº«å­¦ä¹  / çŸ¥è¯†è¿ç§»ç ”ç©¶é»˜è®¤å¼•ç”¨çš„æ•°æ®ä¸ä»»åŠ¡é›†
- **ä»»åŠ¡è¦†ç›–å…¨é¢**: æä¾›å—æ§åˆ†å¸ƒåç§» (Spatial / Object / Goal) ä¸ entangled ä»»åŠ¡ (LIBERO-100)
- **å¼€ç®±å³ç”¨**: æ‰“åŒ…ç¤ºèŒƒæ•°æ®ã€è¯„æµ‹è„šæœ¬ã€ç­–ç•¥ç½‘ç»œ (BC-RNN / BC-Transformer / BC-ViLT) ä¸ç®—æ³• (baseã€ERã€EWCã€PackNetã€Multitask)
- **å¯æ‰©å±•**: Procedural generation pipeline æ”¯æŒç”Ÿæˆæ›´å¤š manipulation ä»»åŠ¡ï¼Œæ–¹ä¾¿è‡ªå®šä¹‰ç ”ç©¶

### 9.2 ä»»åŠ¡å¥—ä»¶æ€»è§ˆ

| å¥—ä»¶ | ä»»åŠ¡æ•° | è¿ç§»æŒ‘æˆ˜ | è¯´æ˜ |
| :--- | :--- | :--- | :--- |
| **LIBERO-Spatial** | 30 | ç©ºé—´å…³ç³» | ç›¸åŒç‰©ä½“ï¼Œä¸åŒç©ºé—´å¸ƒç½® |
| **LIBERO-Object** | 30 | ç‰©ä½“ç±»å‹ | ä¸åŒç‰©ä½“å±æ€§ï¼Œè€ƒéªŒè¯­ä¹‰+æŠ“å–æ³›åŒ– |
| **LIBERO-Goal** | 30 | ç›®æ ‡å˜åŒ– | åŒåœºæ™¯ï¼Œå¤šç›®æ ‡ç»„åˆ |
| **LIBERO-100** | 100 | æ··åˆ (Entangled) | æ‹†æˆ **LIBERO-90** (é¢„è®­ç»ƒ) + **LIBERO-10** (ç»ˆèº«å­¦ä¹ æµ‹è¯•) |

### 9.3 æ•°æ®ä¸ç¯å¢ƒ

```bash
## ç¯å¢ƒå®‰è£…
conda create -n libero python=3.8.13
conda activate libero
git clone https://github.com/Lifelong-Robot-Learning/LIBERO.git
cd LIBERO
pip install -r requirements.txt
pip install torch==1.11.0+cu113 torchvision==0.12.0+cu113 \
            torchaudio==0.11.0 --extra-index-url https://download.pytorch.org/whl/cu113
pip install -e .

## ä¸‹è½½ç¤ºèŒƒ (å¯é€‰ --datasets æŒ‡å®šå¥—ä»¶)
python benchmark_scripts/download_libero_datasets.py --use-huggingface
```

### 9.4 è®­ç»ƒ / è¯„æµ‹å…¥å£

```bash
## ç»ˆèº«å­¦ä¹ è®­ç»ƒ
export CUDA_VISIBLE_DEVICES=0
python libero/lifelong/main.py \
    seed=0 \
    benchmark_name=LIBERO_90 \
    policy=bc_transformer_policy \
    lifelong=ewc

## è„±æœºè¯„æµ‹
python libero/lifelong/evaluate.py \
    --benchmark LIBERO_10 \
    --task_id 0 \
    --algo ewc \
    --policy bc_transformer_policy \
    --ep 50 \
    --device_id 0
```

### 9.5 ä¸ VLA çš„ç»“åˆæ–¹å¼

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                LIBERO + VLA ç»“åˆæµç¨‹                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚   1. æ•°æ®å±‚: å¤ç”¨ LIBERO ç¤ºèŒƒè®­ç»ƒ / å¾®è°ƒ VLA çš„ Action Head     â”‚
â”‚                                                                 â”‚
â”‚   2. è¯„æµ‹å±‚: ä½œä¸º"ç»ˆèº«å­¦ä¹ å›å½’æµ‹è¯•é›†"ï¼Œæ£€æŸ¥ Catastrophic        â”‚
â”‚              Forgetting                                         â”‚
â”‚                                                                 â”‚
â”‚   3. è·¨åŸŸè¿ç§»: å…ˆç”¨ LIBERO-90 é¢„è®­ç»ƒï¼Œå†åœ¨ LIBERO-10 /          â”‚
â”‚               è‡ªå®šä¹‰ä»»åŠ¡ â†’ çœŸæœºéªŒè¯ Sim-to-Real                  â”‚
â”‚                                                                 â”‚
â”‚   4. ç®—æ³•ç»„åˆ: å°† RLHF / DPO ç­‰ä¸Šå±‚ä¼˜åŒ–ä¸ EWC / PackNet ç­‰      â”‚
â”‚               åº•å±‚æ­£åˆ™ç»“åˆï¼Œå½¢æˆæ··åˆ pipeline                    â”‚
â”‚                                                                 â”‚
â”‚   ğŸ’¡ é¢è¯•å¸¸é—®: "å¦‚ä½•è¯„ä¼° VLA çš„ç»ˆèº«å­¦ä¹ èƒ½åŠ›ï¼Ÿ"                   â”‚
â”‚      â†’ ä½¿ç”¨ LIBERO-90 é¢„è®­ç»ƒ + LIBERO-10 æµ‹è¯•é—å¿˜ç¨‹åº¦            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 9.6 é¢è¯• Q&A

**Q: å¦‚ä½•ä½¿ç”¨ LIBERO è¯„ä¼° VLA çš„ç»ˆèº«å­¦ä¹ èƒ½åŠ›ï¼Ÿ**

A:
1. **é¢„è®­ç»ƒ**: åœ¨ LIBERO-90 ä¸Šè®­ç»ƒ VLA ç­–ç•¥
2. **ç»ˆèº«å­¦ä¹ **: åœ¨ LIBERO-10 çš„ 10 ä¸ªä»»åŠ¡ä¸Šé¡ºåºå¾®è°ƒ
3. **è¯„ä¼°é—å¿˜**: æ¯å­¦å®Œä¸€ä¸ªæ–°ä»»åŠ¡åï¼Œæµ‹è¯•æ‰€æœ‰æ—§ä»»åŠ¡çš„æˆåŠŸç‡
4. **å¯¹æ¯”ç®—æ³•**: æ¯”è¾ƒ Sequential Fine-tuning (baseline) vs EWC / PackNet / ER
5. **å…³é”®æŒ‡æ ‡**: Forward Transfer (æ–°ä»»åŠ¡å­¦ä¹ é€Ÿåº¦) + Backward Transfer (æ—§ä»»åŠ¡é—å¿˜ç¨‹åº¦)

## 11. å‚è€ƒèµ„æº (References)

- **PPO**: [Proximal Policy Optimization Algorithms](https://arxiv.org/abs/1707.06347)
- **SAC**: [Soft Actor-Critic: Off-Policy Maximum Entropy Deep RL](https://arxiv.org/abs/1801.01290)
- **CQL**: [Conservative Q-Learning for Offline RL](https://arxiv.org/abs/2006.04779)
- **IQL**: [Offline RL with Implicit Q-Learning](https://arxiv.org/abs/2110.06169)
- **Spinning Up**: [OpenAI Spinning Up in Deep RL](https://spinningup.openai.com/)
- **Stable Baselines3**: [Docs](https://stable-baselines3.readthedocs.io/)
- **RLlib**: [Docs](https://docs.ray.io/en/latest/rllib/)
- **SKRL**: [Docs](https://skrl.readthedocs.io/)

---

\newpage

# ç¬¬12ç«  çŸ¥è¯†è’¸é¦


> **æ ¸å¿ƒæ¦‚å¿µ**: çŸ¥è¯†è’¸é¦ (Knowledge Distillation, KD) æ˜¯ä¸€ç§æ¨¡å‹å‹ç¼©æŠ€æœ¯ï¼Œé€šè¿‡è®©å°æ¨¡å‹ï¼ˆå­¦ç”Ÿï¼‰æ¨¡ä»¿å¤§æ¨¡å‹ï¼ˆæ•™å¸ˆï¼‰çš„è¡Œä¸ºï¼Œå®ç°çŸ¥è¯†çš„è¿ç§»ã€‚åœ¨ VLA é¢†åŸŸï¼ŒçŸ¥è¯†è’¸é¦æ˜¯å®ç°è¾¹ç¼˜ç«¯éƒ¨ç½²çš„å…³é”®æŠ€æœ¯ã€‚

## 0. ä¸»è¦æ•¸å­¸æ€æƒ³ (Main Mathematical Idea)

> **ç¬¬ä¸€æ€§åŸç†**: **Smoothing the Decision Boundary (å†³ç­–è¾¹ç•Œçš„å¹³æ»‘ / Dark Knowledge)**

ä¸€ä¸ª"ç¡¬æ ‡ç­¾"ï¼ˆè¿™å¼ å›¾æ˜¯çŒ«ï¼‰åªåŒ…å« 1 bit ä¿¡æ¯ã€‚ä½†ä¸€ä¸ªæ¨¡å‹çš„é¢„æµ‹åˆ†å¸ƒï¼ˆ90%çŒ«ï¼Œ9%ç‹—ï¼Œ1%è½¦ï¼‰åŒ…å«äº†æå…¶ä¸°å¯Œçš„**ç»“æ„ä¿¡æ¯**ï¼ˆçŒ«å’Œç‹—é•¿å¾—åƒï¼Œå’Œè½¦ä¸åƒï¼‰ã€‚

- **æ ¸å¿ƒæ•°å­¦å·¥å…·**: **KL Divergence (KL æ•£åº¦)** ä¸ **Temperature Scaling (æ¸©åº¦ç¼©æ”¾)**ã€‚
- **è§£é¢˜é€»è¾‘**:
    1.  **æš—çŸ¥è¯† (Dark Knowledge)**: Hinton æŒ‡å‡ºï¼Œæ•™å¸ˆæ¨¡å‹å¯¹é”™è¯¯ç±»åˆ«çš„é¢„æµ‹æ¦‚ç‡å¹¶ééšæœºå™ªå£°ï¼Œè€Œæ˜¯åæ˜ äº†æ•°æ®çš„æµå½¢ç»“æ„ã€‚
    2.  **è½¯åŒ–**: ç›´æ¥åŒ¹é…æ¦‚ç‡åˆ†å¸ƒå¯èƒ½å¤ªå°–é”ï¼ˆæ¢¯åº¦æ¶ˆå¤±ï¼‰ã€‚é€šè¿‡å¼•å…¥æ¸©åº¦å‚æ•° $T$ï¼Œæˆ‘ä»¬"è½¯åŒ–"äº†åˆ†å¸ƒï¼Œæ”¾å¤§äº†ç»†å¾®çš„æ¦‚ç‡å·®å¼‚ï¼Œè¿«ä½¿å­¦ç”Ÿæ¨¡å‹ä¸ä»…å­¦ä¼š"æ˜¯ä»€ä¹ˆ"ï¼Œè¿˜å­¦ä¼š"åƒä»€ä¹ˆ"ã€‚
    3.  **å¯¹é½**: æ•°å­¦æœ¬è´¨æ˜¯æœ€å°åŒ–ä¸¤ä¸ªæ¦‚ç‡åˆ†å¸ƒä¹‹é—´çš„è·ç¦» ($D_{KL}(P || Q)$)ï¼Œä½¿å­¦ç”Ÿæ¨¡å‹çš„æ€ç»´æ–¹å¼ï¼ˆç‰¹å¾ç©ºé—´ç»“æ„ï¼‰è¶‹è¿‘äºæ•™å¸ˆã€‚

## 1. ä¸ºä»€ä¹ˆ VLA éœ€è¦çŸ¥è¯†è’¸é¦? (Why KD for VLA?)

### 1.1 VLA éƒ¨ç½²æŒ‘æˆ˜

| æ¨¡å‹ | å‚æ•°é‡ | æ¨ç†å»¶è¿Ÿ | æ˜¾å­˜éœ€æ±‚ |
| :--- | :--- | :--- | :--- |
| **RT-2 (PaLI-X)** | 55B | ~5s | 100+ GB |
| **OpenVLA** | 7B | ~200ms | 16 GB |
| **ç›®æ ‡ (è¾¹ç¼˜)** | < 1B | < 50ms | < 4 GB |

**ç°å®çº¦æŸ**:
- **å®æ—¶æ€§**: æœºå™¨äººæ§åˆ¶éœ€è¦ 20-50Hz (20-50ms)
- **ç¡¬ä»¶é™åˆ¶**: æœºè½½è®¡ç®—é€šå¸¸åªæœ‰ Jetson Orin (8-32GB)
- **åŠŸè€—**: ç§»åŠ¨æœºå™¨äººå¯¹åŠŸè€—æ•æ„Ÿ

### 1.2 çŸ¥è¯†è’¸é¦çš„ä»·å€¼


$$
\text{å°æ¨¡å‹æ€§èƒ½} + \text{å¤§æ¨¡å‹çŸ¥è¯†} \approx \text{å¤§æ¨¡å‹æ€§èƒ½}
$$


- **æ¨¡å‹å‹ç¼©**: 10x å‚æ•°å‡å°‘ï¼Œæ€§èƒ½æŸå¤± < 10%
- **æ¨ç†åŠ é€Ÿ**: é™ä½å»¶è¿Ÿï¼Œæ»¡è¶³å®æ—¶æ§åˆ¶éœ€æ±‚
- **é™ä½æˆæœ¬**: å‡å°‘éƒ¨ç½²ç¡¬ä»¶éœ€æ±‚

## 2. çŸ¥è¯†è’¸é¦åŸºç¡€ (KD Fundamentals)

### 2.1 åŸºæœ¬æ¡†æ¶

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Teacher Model (å¤§æ¨¡å‹)                    â”‚
â”‚                    - é¢„è®­ç»ƒå¥½çš„ VLA                          â”‚
â”‚                    - å‚æ•°å†»ç»“                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚ Soft Labels / Logits
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Distillation Loss                       â”‚
â”‚              L = Î± * L_hard + (1-Î±) * L_soft                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Student Model (å°æ¨¡å‹)                     â”‚
â”‚                    - ç›®æ ‡éƒ¨ç½²æ¨¡å‹                            â”‚
â”‚                    - å¯è®­ç»ƒ                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 è½¯æ ‡ç­¾ (Soft Labels)

**ç¡¬æ ‡ç­¾ (Hard Labels)**: One-hot å‘é‡ï¼Œåªæœ‰æ­£ç¡®ç±»åˆ«ä¸º 1ã€‚

**è½¯æ ‡ç­¾ (Soft Labels)**: æ•™å¸ˆæ¨¡å‹çš„ softmax æ¦‚ç‡åˆ†å¸ƒã€‚


$$
p_i^{(T)} = \frac{\exp(z_i / T)}{\sum_j \exp(z_j / T)}
$$


å…¶ä¸­ $T$ æ˜¯**æ¸©åº¦å‚æ•°** (Temperature)ï¼š
- **T = 1**: æ­£å¸¸ softmax
- **T > 1**: åˆ†å¸ƒæ›´å¹³æ»‘ï¼Œä¿ç•™æ›´å¤š"æš—çŸ¥è¯†"
- **T â†’ âˆ**: å‡åŒ€åˆ†å¸ƒ

### 2.3 è’¸é¦æŸå¤± (Distillation Loss)

```python
import torch
import torch.nn as nn
import torch.nn.functional as F

class DistillationLoss(nn.Module):
    def __init__(self, temperature=4.0, alpha=0.5):
        super().__init__()
        self.temperature = temperature
        self.alpha = alpha
    
    def forward(self, student_logits, teacher_logits, labels):
        """
        student_logits: å­¦ç”Ÿæ¨¡å‹è¾“å‡º
        teacher_logits: æ•™å¸ˆæ¨¡å‹è¾“å‡º
        labels: çœŸå®æ ‡ç­¾ (ç”¨äºç¡¬æ ‡ç­¾æŸå¤±)
        """
        # ç¡¬æ ‡ç­¾æŸå¤± (ä¸çœŸå®æ ‡ç­¾)
        hard_loss = F.cross_entropy(student_logits, labels)
        
        # è½¯æ ‡ç­¾æŸå¤± (ä¸æ•™å¸ˆ)
        soft_student = F.log_softmax(student_logits / self.temperature, dim=-1)
        soft_teacher = F.softmax(teacher_logits / self.temperature, dim=-1)
        soft_loss = F.kl_div(soft_student, soft_teacher, reduction='batchmean')
        soft_loss = soft_loss * (self.temperature ** 2)  # æ¸©åº¦ç¼©æ”¾
        
        # ç»„åˆæŸå¤±
        total_loss = self.alpha * hard_loss + (1 - self.alpha) * soft_loss
        return total_loss
```

## 3. VLA ä¸­çš„çŸ¥è¯†è’¸é¦ç­–ç•¥ (KD Strategies for VLA)

### 3.1 ç‰¹å¾è’¸é¦ (Feature Distillation)

é™¤äº†è¾“å‡ºå±‚ï¼Œè¿˜è’¸é¦ä¸­é—´ç‰¹å¾ã€‚

```python
class FeatureDistillation(nn.Module):
    def __init__(self, teacher, student, feature_layers):
        super().__init__()
        self.teacher = teacher
        self.student = student
        self.feature_layers = feature_layers
        
        # ç‰¹å¾æŠ•å½±å±‚ (å¯¹é½ç»´åº¦)
        self.projectors = nn.ModuleDict()
        for name in feature_layers:
            t_dim = teacher.get_feature_dim(name)
            s_dim = student.get_feature_dim(name)
            if t_dim != s_dim:
                self.projectors[name] = nn.Linear(s_dim, t_dim)
    
    def forward(self, inputs):
        # è·å–æ•™å¸ˆç‰¹å¾
        with torch.no_grad():
            teacher_features = self.teacher.get_features(inputs, self.feature_layers)
        
        # è·å–å­¦ç”Ÿç‰¹å¾
        student_features = self.student.get_features(inputs, self.feature_layers)
        
        # ç‰¹å¾å¯¹é½æŸå¤±
        feature_loss = 0
        for name in self.feature_layers:
            t_feat = teacher_features[name]
            s_feat = student_features[name]
            
            if name in self.projectors:
                s_feat = self.projectors[name](s_feat)
            
            feature_loss += F.mse_loss(s_feat, t_feat)
        
        return feature_loss / len(self.feature_layers)
```

### 3.2 æ³¨æ„åŠ›è’¸é¦ (Attention Distillation)

è®©å­¦ç”Ÿæ¨¡å‹å­¦ä¹ æ•™å¸ˆçš„æ³¨æ„åŠ›æ¨¡å¼ã€‚

```python
class AttentionDistillation(nn.Module):
    def __init__(self, teacher, student):
        super().__init__()
        self.teacher = teacher
        self.student = student
    
    def forward(self, inputs):
        # è·å–æ³¨æ„åŠ›æƒé‡
        with torch.no_grad():
            _, teacher_attns = self.teacher(inputs, output_attentions=True)
        
        _, student_attns = self.student(inputs, output_attentions=True)
        
        # æ³¨æ„åŠ›å¯¹é½æŸå¤±
        attn_loss = 0
        for t_attn, s_attn in zip(teacher_attns, student_attns):
            # t_attn, s_attn: [B, num_heads, seq_len, seq_len]
            attn_loss += F.mse_loss(s_attn, t_attn)
        
        return attn_loss / len(teacher_attns)
```

### 3.3 åŠ¨ä½œè½¨è¿¹è’¸é¦ (Action Trajectory Distillation)

VLA ç‰¹æœ‰ï¼šè’¸é¦æ•´ä¸ªåŠ¨ä½œåºåˆ—ã€‚

```python
class ActionTrajectoryDistillation(nn.Module):
    """VLA ä¸“ç”¨: è’¸é¦åŠ¨ä½œè½¨è¿¹"""
    def __init__(self, teacher_vla, student_vla, chunk_size=16):
        super().__init__()
        self.teacher = teacher_vla
        self.student = student_vla
        self.chunk_size = chunk_size
    
    def forward(self, obs, instruction):
        """
        obs: è§‚æµ‹ [B, C, H, W]
        instruction: è¯­è¨€æŒ‡ä»¤
        """
        # æ•™å¸ˆç”ŸæˆåŠ¨ä½œè½¨è¿¹
        with torch.no_grad():
            teacher_actions = self.teacher.generate_actions(obs, instruction)
            # teacher_actions: [B, chunk_size, action_dim]
        
        # å­¦ç”Ÿç”ŸæˆåŠ¨ä½œè½¨è¿¹
        student_actions = self.student.generate_actions(obs, instruction)
        
        # è½¨è¿¹çº§åˆ«çš„è’¸é¦æŸå¤±
        trajectory_loss = F.mse_loss(student_actions, teacher_actions)
        
        # å¯é€‰: æ—¶é—´åŠ æƒ (æ›´é‡è§†è¿‘æœŸåŠ¨ä½œ)
        time_weights = torch.exp(-0.1 * torch.arange(self.chunk_size))
        weighted_loss = (trajectory_loss * time_weights.unsqueeze(-1)).mean()
        
        return weighted_loss
```

### 3.4 åˆ†å¸ƒè’¸é¦ (Distribution Distillation)

å¯¹äº Diffusion/Flow Matching ç­–ç•¥ï¼Œè’¸é¦åŠ¨ä½œåˆ†å¸ƒã€‚

```python
class DiffusionDistillation(nn.Module):
    """Diffusion Policy çš„è’¸é¦"""
    def __init__(self, teacher_diffusion, student_diffusion, num_steps=10):
        super().__init__()
        self.teacher = teacher_diffusion
        self.student = student_diffusion
        self.num_steps = num_steps
    
    def forward(self, obs, condition):
        # æ•™å¸ˆé¢„æµ‹çš„å™ªå£°
        with torch.no_grad():
            x_t = torch.randn(obs.shape[0], self.action_dim)
            for t in reversed(range(self.num_steps)):
                teacher_eps = self.teacher.predict_noise(x_t, t, condition)
                x_t = self.ddim_step(x_t, teacher_eps, t)
            teacher_trajectory = x_t
        
        # å­¦ç”Ÿé¢„æµ‹ (ç›´æ¥é¢„æµ‹æœ€ç»ˆè½¨è¿¹ï¼Œä¸€æ­¥åˆ°ä½)
        student_trajectory = self.student(obs, condition)
        
        # è’¸é¦æŸå¤±
        loss = F.mse_loss(student_trajectory, teacher_trajectory)
        return loss
```

## 4. VLA è’¸é¦çš„ç‰¹æ®Šè€ƒè™‘ (Special Considerations)

### 4.1 è§†è§‰ç¼–ç å™¨è’¸é¦

```python
class VisionEncoderDistillation:
    """è’¸é¦è§†è§‰ç¼–ç å™¨: SigLIP (L) â†’ MobileViT (S)"""
    
    def __init__(self, teacher_vision, student_vision):
        self.teacher = teacher_vision  # SigLIP-L (400M)
        self.student = student_vision  # MobileViT (6M)
        
        # CLS token å¯¹é½
        self.cls_projector = nn.Linear(student.embed_dim, teacher.embed_dim)
        
        # Patch token å¯¹é½
        self.patch_projector = nn.Conv1d(student.embed_dim, teacher.embed_dim, 1)
    
    def distill(self, images):
        with torch.no_grad():
            t_cls, t_patches = self.teacher(images)
        
        s_cls, s_patches = self.student(images)
        
        # CLS æŸå¤±
        cls_loss = F.mse_loss(self.cls_projector(s_cls), t_cls)
        
        # Patch æŸå¤± (éœ€è¦å¤„ç†åˆ†è¾¨ç‡ä¸åŒ¹é…)
        t_patches_interp = F.interpolate(t_patches, size=s_patches.shape[-1])
        patch_loss = F.mse_loss(self.patch_projector(s_patches), t_patches_interp)
        
        return cls_loss + 0.5 * patch_loss
```

### 4.2 è¯­è¨€æ¨¡å‹è’¸é¦

```python
class LLMDistillation:
    """è’¸é¦è¯­è¨€æ¨¡å‹: Llama-7B â†’ TinyLlama-1B"""
    
    def __init__(self, teacher_llm, student_llm):
        self.teacher = teacher_llm
        self.student = student_llm
    
    def distill(self, input_ids, attention_mask):
        # æ•™å¸ˆè¾“å‡º
        with torch.no_grad():
            teacher_outputs = self.teacher(
                input_ids=input_ids,
                attention_mask=attention_mask,
                output_hidden_states=True
            )
        
        # å­¦ç”Ÿè¾“å‡º
        student_outputs = self.student(
            input_ids=input_ids,
            attention_mask=attention_mask,
            output_hidden_states=True
        )
        
        # Logit è’¸é¦
        logit_loss = self.soft_cross_entropy(
            student_outputs.logits,
            teacher_outputs.logits,
            temperature=2.0
        )
        
        # éšè—å±‚è’¸é¦ (è·³å±‚å¯¹é½)
        # Teacher 32 å±‚ â†’ Student 12 å±‚, æ¯éš” ~2.7 å±‚å¯¹é½
        layer_mapping = [0, 3, 6, 9, 12, 15, 18, 21, 24, 27, 30, 31]
        hidden_loss = 0
        for s_idx, t_idx in enumerate(layer_mapping):
            t_hidden = teacher_outputs.hidden_states[t_idx]
            s_hidden = student_outputs.hidden_states[s_idx]
            hidden_loss += F.mse_loss(s_hidden, t_hidden)
        
        return logit_loss + 0.1 * hidden_loss
```

### 4.3 å¤šé˜¶æ®µè’¸é¦ (Progressive Distillation)

```python
class ProgressiveDistillation:
    """æ¸è¿›å¼è’¸é¦: é€æ­¥ç¼©å°æ¨¡å‹"""
    
    def __init__(self, teacher, intermediate_sizes=[4B, 2B, 1B]):
        self.teacher = teacher
        self.stages = []
        
        prev_model = teacher
        for size in intermediate_sizes:
            student = create_model(size)
            self.stages.append((prev_model, student))
            prev_model = student
    
    def train(self, data):
        for stage_idx, (teacher, student) in enumerate(self.stages):
            print(f"Stage {stage_idx + 1}: {teacher.num_params}B â†’ {student.num_params}B")
            
            for epoch in range(num_epochs):
                for batch in data:
                    loss = self.distill_step(teacher, student, batch)
                    loss.backward()
                    optimizer.step()
            
            # å†»ç»“å½“å‰å­¦ç”Ÿï¼Œä½œä¸ºä¸‹ä¸€é˜¶æ®µçš„æ•™å¸ˆ
            for param in student.parameters():
                param.requires_grad = False
```

## 5. è’¸é¦ + é‡åŒ–è”åˆä¼˜åŒ– (KD + Quantization)

### 5.1 é‡åŒ–æ„ŸçŸ¥è’¸é¦ (Quantization-Aware Distillation)

```python
class QADistillation:
    """é‡åŒ–æ„ŸçŸ¥è’¸é¦"""
    
    def __init__(self, teacher, student, quant_bits=4):
        self.teacher = teacher
        self.student = student
        self.quant_bits = quant_bits
    
    def forward(self, inputs):
        # æ•™å¸ˆ (FP16)
        with torch.no_grad():
            teacher_out = self.teacher(inputs)
        
        # å­¦ç”Ÿ (æ¨¡æ‹Ÿé‡åŒ–)
        student_out = self.quantized_forward(self.student, inputs)
        
        # è’¸é¦æŸå¤±
        loss = F.mse_loss(student_out, teacher_out)
        return loss
    
    def quantized_forward(self, model, inputs):
        """æ¨¡æ‹Ÿ INT4 é‡åŒ–çš„å‰å‘ä¼ æ’­"""
        # ä¼ªé‡åŒ–: æ¨¡æ‹Ÿé‡åŒ–è¯¯å·®ï¼Œä½†ä¿æŒæ¢¯åº¦å¯ä¼ æ’­
        for name, module in model.named_modules():
            if isinstance(module, nn.Linear):
                # é‡åŒ–æƒé‡
                w = module.weight
                scale = w.abs().max() / (2 ** (self.quant_bits - 1) - 1)
                w_quant = torch.round(w / scale) * scale
                
                # Straight-Through Estimator
                module.weight.data = w + (w_quant - w).detach()
        
        return model(inputs)
```

### 5.2 è’¸é¦åé‡åŒ– (Post-Distillation Quantization)

```python
def post_distillation_quantize(distilled_model, calibration_data, bits=4):
    """è’¸é¦åè¿›è¡Œ PTQ"""
    from transformers import BitsAndBytesConfig
    
    # æ”¶é›†æ¿€æ´»ç»Ÿè®¡
    activations = collect_activations(distilled_model, calibration_data)
    
    # è®¡ç®—é‡åŒ–å‚æ•°
    quant_config = BitsAndBytesConfig(
        load_in_4bit=True,
        bnb_4bit_compute_dtype=torch.float16,
        bnb_4bit_quant_type="nf4",  # NormalFloat4
    )
    
    # é‡åŒ–æ¨¡å‹
    quantized_model = quantize_model(distilled_model, quant_config)
    
    return quantized_model
```

## 6. å®æˆ˜ï¼šOpenVLA è’¸é¦åˆ° 1B æ¨¡å‹

```python
class OpenVLADistillation:
    """å°† OpenVLA (7B) è’¸é¦åˆ° 1B æ¨¡å‹"""
    
    def __init__(self):
        # æ•™å¸ˆ: OpenVLA 7B
        self.teacher = AutoModelForVision2Seq.from_pretrained("openvla/openvla-7b")
        
        # å­¦ç”Ÿ: TinyLlama 1B + MobileViT
        self.student = TinyVLA(
            vision_encoder="mobilevit_small",
            language_model="TinyLlama/TinyLlama-1.1B",
            action_head_dim=7
        )
        
        # è’¸é¦é…ç½®
        self.temperature = 4.0
        self.alpha = 0.7  # è½¯æ ‡ç­¾æƒé‡
    
    def train_step(self, batch):
        images = batch['images']
        instructions = batch['instructions']
        gt_actions = batch['actions']
        
        # æ•™å¸ˆé¢„æµ‹
        with torch.no_grad():
            teacher_actions, teacher_logits = self.teacher(
                images, instructions, return_logits=True
            )
        
        # å­¦ç”Ÿé¢„æµ‹
        student_actions, student_logits = self.student(
            images, instructions, return_logits=True
        )
        
        # å¤šä»»åŠ¡è’¸é¦æŸå¤±
        
        # 1. åŠ¨ä½œè’¸é¦
        action_distill = F.mse_loss(student_actions, teacher_actions)
        
        # 2. Logit è’¸é¦ (å¦‚æœæœ‰è¯­è¨€è¾“å‡º)
        soft_loss = F.kl_div(
            F.log_softmax(student_logits / self.temperature, dim=-1),
            F.softmax(teacher_logits / self.temperature, dim=-1),
            reduction='batchmean'
        ) * (self.temperature ** 2)
        
        # 3. ç¡¬æ ‡ç­¾æŸå¤± (ä¸çœŸå®åŠ¨ä½œ)
        hard_loss = F.mse_loss(student_actions, gt_actions)
        
        # ç»„åˆ
        total_loss = (
            self.alpha * soft_loss + 
            (1 - self.alpha) * hard_loss +
            0.5 * action_distill
        )
        
        return total_loss


## è®­ç»ƒè„šæœ¬
distiller = OpenVLADistillation()
optimizer = torch.optim.AdamW(distiller.student.parameters(), lr=1e-4)

for epoch in range(10):
    for batch in dataloader:
        loss = distiller.train_step(batch)
        
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

## ä¿å­˜è’¸é¦åçš„å°æ¨¡å‹
distiller.student.save_pretrained("./openvla-1b-distilled")
```

## 7. æ•ˆæœå¯¹æ¯” (Performance Comparison)

| æ¨¡å‹ | å‚æ•°é‡ | å»¶è¿Ÿ (Jetson) | CALVIN æˆåŠŸç‡ | æ˜¾å­˜ |
| :--- | :--- | :--- | :--- | :--- |
| **OpenVLA (Teacher)** | 7B | 500ms | 78% | 16GB |
| **OpenVLA-1B (Distilled)** | 1B | 80ms | 72% | 4GB |
| **OpenVLA-1B + INT4** | 1B | 50ms | 70% | 2GB |
| **ä»å¤´è®­ç»ƒ 1B** | 1B | 80ms | 58% | 4GB |

**ç»“è®º**: è’¸é¦åçš„ 1B æ¨¡å‹æ¯”ä»å¤´è®­ç»ƒæå‡ 14%ï¼

## 8. é¢è¯•é«˜é¢‘é—®é¢˜ (Q&A)

**Q1: æ¸©åº¦å‚æ•° T çš„ä½œç”¨æ˜¯ä»€ä¹ˆ? å¦‚ä½•é€‰æ‹©?**

A:
- **T çš„ä½œç”¨**: è½¯åŒ– softmax åˆ†å¸ƒï¼Œä¿ç•™æ›´å¤š"æš—çŸ¥è¯†"ï¼ˆå¦‚ç›¸ä¼¼ç±»çš„å…³ç³»ï¼‰
- **T å° (1-2)**: åˆ†å¸ƒå°–é”ï¼Œä¿¡æ¯ä¸»è¦æ¥è‡ª top-1 é¢„æµ‹
- **T å¤§ (4-10)**: åˆ†å¸ƒå¹³æ»‘ï¼Œä¿ç•™æ›´å¤šç±»é—´å…³ç³»
- **ç»éªŒå€¼**: VLA ä¸­é€šå¸¸ T=4-6

**Q2: ä¸ºä»€ä¹ˆè’¸é¦æ¯”ä»å¤´è®­ç»ƒå°æ¨¡å‹æ•ˆæœå¥½?**

A:
- **è½¯æ ‡ç­¾ä¿¡æ¯**: åŒ…å«ç±»é—´å…³ç³»ï¼ˆå¦‚"çº¢è‰²è‹¹æœ"å’Œ"ç»¿è‰²è‹¹æœ"æ›´ç›¸ä¼¼ï¼‰
- **æ­£åˆ™åŒ–æ•ˆæœ**: è½¯æ ‡ç­¾æ¯” one-hot æ›´å¹³æ»‘ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆ
- **æ•°æ®æ•ˆç‡**: å°æ¨¡å‹éš¾ä»¥ä»æœ‰é™æ•°æ®å­¦åˆ°å¤æ‚æ¨¡å¼ï¼Œæ•™å¸ˆ"æ€»ç»“"äº†çŸ¥è¯†

**Q3: è’¸é¦ VLA æ—¶åº”è¯¥è’¸é¦å“ªäº›ç»„ä»¶?**

A:
- **å¿…é¡»è’¸é¦**: Logits (è¾“å‡ºåˆ†å¸ƒ)ã€åŠ¨ä½œè½¨è¿¹
- **æ¨èè’¸é¦**: æ³¨æ„åŠ›æƒé‡ã€ä¸­é—´ç‰¹å¾
- **å¯é€‰è’¸é¦**: è§†è§‰ç¼–ç å™¨ç‰¹å¾ï¼ˆå¦‚æœå­¦ç”Ÿç¼–ç å™¨ä¸åŒï¼‰

**Q4: è’¸é¦å’Œé‡åŒ–çš„é¡ºåº?**

A:
- **æ¨è**: å…ˆè’¸é¦ï¼Œå†é‡åŒ–
- **åŸå› **: è’¸é¦ä¿ç•™çŸ¥è¯†ï¼Œé‡åŒ–å‹ç¼©è¡¨ç¤ºï¼›å…ˆé‡åŒ–ä¼šä¸¢å¤±å¤ªå¤šä¿¡æ¯
- **é«˜çº§**: é‡åŒ–æ„ŸçŸ¥è’¸é¦ï¼ˆQADï¼‰ï¼Œåœ¨è’¸é¦æ—¶æ¨¡æ‹Ÿé‡åŒ–è¯¯å·®

**Q5: Self-Distillation æ˜¯ä»€ä¹ˆ?**

A:
- **å®šä¹‰**: æ¨¡å‹è‡ªå·±è’¸é¦è‡ªå·±ï¼ˆæ•™å¸ˆå’Œå­¦ç”Ÿæ˜¯åŒä¸€æ¨¡å‹ï¼‰
- **æ–¹æ³•**: ç”¨æ¨¡å‹çš„å†å² checkpoint ä½œä¸ºæ•™å¸ˆ
- **æ•ˆæœ**: æå‡æ¨¡å‹çš„æ ¡å‡†æ€§ (Calibration)ï¼Œå¸¸ç”¨äºå¤§æ¨¡å‹è®­ç»ƒåæœŸ

## 9. å‚è€ƒèµ„æº (References)

- **Original KD**: [Distilling the Knowledge in a Neural Network](https://arxiv.org/abs/1503.02531)
- **Feature Distillation**: [FitNets: Hints for Thin Deep Nets](https://arxiv.org/abs/1412.6550)
- **Attention Transfer**: [Paying More Attention to Attention](https://arxiv.org/abs/1612.03928)
- **Progressive Distillation**: [On the Efficacy of Knowledge Distillation](https://arxiv.org/abs/1910.01348)

---


\newpage

# ç¬¬13ç«  è‡ªç›‘ç£å­¦ä¹ 


> **æ ¸å¿ƒæ¦‚å¿µ**: è‡ªç›‘ç£å­¦ä¹  (Self-Supervised Learning, SSL) æ˜¯ä¸€ç§ä»æ— æ ‡ç­¾æ•°æ®ä¸­å­¦ä¹ æœ‰æ„ä¹‰è¡¨ç¤ºçš„æ–¹æ³•ã€‚é€šè¿‡è®¾è®¡ **Pretext Task (ä»£ç†ä»»åŠ¡)**ï¼Œè®©æ¨¡å‹ä»æ•°æ®æœ¬èº«çš„ç»“æ„ä¸­å­¦ä¹ ã€‚

## 0. ä¸»è¦æ•¸å­¸æ€æƒ³ (Main Mathematical Idea)

> **ç¬¬ä¸€æ€§åŸç†**: **Structure is Supervision (ç»“æ„å³ç›‘ç£)**

äººç±»å­¦ä¹ ä¸éœ€è¦æ¯æ—¶æ¯åˆ»çš„å¤–éƒ¨æ ‡ç­¾ï¼Œå› ä¸ºæ•°æ®æœ¬èº«å†…éƒ¨è•´å«ç€ä¸°å¯Œçš„**ç»“æ„ä¿¡æ¯**ï¼ˆæ—¶ç©ºè¿ç»­æ€§ã€å¤šè§†è§’ä¸€è‡´æ€§ï¼‰ã€‚

- **æ ¸å¿ƒæ•°å­¦å·¥å…·**: **Manifold Learning (æµå½¢å­¦ä¹ )** ä¸ **Mutual Information Maximization (äº’ä¿¡æ¯æœ€å¤§åŒ–)**ã€‚
- **è§£é¢˜é€»è¾‘**:
    1.  **ä¸å˜æ€§ (Invariance)**: åŒä¸€ä¸ªç‰©ä½“ï¼Œæ— è®ºå…‰ç…§ã€è§’åº¦å¦‚ä½•å˜åŒ–ï¼Œå…¶æœ¬è´¨ï¼ˆè¯­ä¹‰ï¼‰ä¸å˜ã€‚é€šè¿‡æ‹‰è¿‘åŒä¸€ç‰©ä½“ä¸åŒè§†å›¾çš„è·ç¦»ï¼ˆå¯¹æ¯”å­¦ä¹ ï¼‰ï¼Œæ¨¡å‹å­¦ä¼šäº†å¿½ç•¥æ— å…³å¹²æ‰°ï¼ˆå¦‚åƒç´ å™ªå£°ï¼‰ï¼ŒæŠ“ä½æ ¸å¿ƒè¯­ä¹‰ã€‚
    2.  **é¢„æµ‹æ€§ (Predictability)**: ä¸–ç•Œæ˜¯æœ‰è§„å¾‹çš„ã€‚å¦‚æœæˆ‘çŸ¥é“äº†ç°åœ¨çš„çŠ¶æ€ï¼Œæˆ‘åº”è¯¥èƒ½æŸç§ç¨‹åº¦ä¸Šé¢„æµ‹æœªæ¥ï¼ˆé¢„æµ‹å­¦ä¹ ï¼‰æˆ–å¡«è¡¥ç¼ºå¤±ï¼ˆæ©ç é¢„æµ‹ï¼‰ã€‚è¿™ç§é¢„æµ‹èƒ½åŠ›è¿«ä½¿æ¨¡å‹ç†è§£æ•°æ®çš„å†…åœ¨é€»è¾‘å’Œç‰©ç†è§„å¾‹ã€‚

## 1. ä¸ºä»€ä¹ˆ VLA éœ€è¦è‡ªç›‘ç£å­¦ä¹ ? (Why SSL for VLA?)

### 1.1 æœºå™¨äººæ•°æ®çš„å›°å¢ƒ

| æ•°æ®ç±»å‹ | è§„æ¨¡ | æ ‡æ³¨æˆæœ¬ |
| :--- | :--- | :--- |
| äº’è”ç½‘å›¾æ–‡ | æ•°åäº¿ | ä½ï¼ˆç½‘é¡µè‡ªåŠ¨çˆ¬å–ï¼‰ |
| è§†é¢‘æ•°æ® | æ•°äº¿å°æ—¶ | æä½ï¼ˆæ— éœ€æ ‡æ³¨ï¼‰ |
| **æœºå™¨äººæ“ä½œæ•°æ®** | **æ•°åä¸‡** | **æé«˜ï¼ˆéœ€çœŸæœºé¥æ“ï¼‰** |

**é—®é¢˜**: æœ‰æ ‡ç­¾çš„æœºå™¨äººæ•°æ®ç¨€ç¼ºï¼Œæ— æ³•æ”¯æ’‘å¤§æ¨¡å‹è®­ç»ƒã€‚

### 1.2 SSL çš„ä»·å€¼


$$
\text{å¤§é‡æ— æ ‡ç­¾æ•°æ®} \xrightarrow{\text{SSL é¢„è®­ç»ƒ}} \text{é€šç”¨è¡¨ç¤º} \xrightarrow{\text{å°‘é‡æ ‡ç­¾å¾®è°ƒ}} \text{é«˜æ€§èƒ½ç­–ç•¥}
$$


- **è§†è§‰è¡¨ç¤º**: ä»æµ·é‡å›¾åƒ/è§†é¢‘ä¸­å­¦ä¹ é€šç”¨è§†è§‰ç‰¹å¾
- **åŠ¨ä½œè¡¨ç¤º**: ä»äººç±»è§†é¢‘ä¸­å­¦ä¹ åŠ¨ä½œå…ˆéªŒ
- **ä¸–ç•Œæ¨¡å‹**: ä»è§†é¢‘ä¸­å­¦ä¹ ç‰©ç†è§„å¾‹

## 2. è‡ªç›‘ç£å­¦ä¹ èŒƒå¼ (SSL Paradigms)

### 2.1 å¯¹æ¯”å­¦ä¹  (Contrastive Learning)

**æ ¸å¿ƒæ€æƒ³**: æ‹‰è¿‘ç›¸ä¼¼æ ·æœ¬ï¼Œæ¨è¿œä¸åŒæ ·æœ¬ã€‚

#### 2.1.1 InfoNCE æŸå¤±


$$
\mathcal{L}_{\text{InfoNCE}} = -\log \frac{\exp(\text{sim}(z_i, z_j) / \tau)}{\sum_{k=1}^{2N} \mathbf{1}_{k \neq i} \exp(\text{sim}(z_i, z_k) / \tau)}
$$


å…¶ä¸­:
- $z_i, z_j$: åŒä¸€æ ·æœ¬çš„ä¸¤ä¸ªå¢å¼ºè§†å›¾çš„è¡¨ç¤º
- $\tau$: æ¸©åº¦ç³»æ•° (é€šå¸¸ 0.07)
- $\text{sim}(\cdot)$: ä½™å¼¦ç›¸ä¼¼åº¦

#### 2.1.2 SimCLR æ¡†æ¶

```
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚           åŸå§‹å›¾åƒ x                  â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ æ•°æ®å¢å¼º T    â”‚               â”‚ æ•°æ®å¢å¼º T'
         â–¼               â”‚               â–¼
      â”Œâ”€â”€â”€â”€â”€â”            â”‚            â”Œâ”€â”€â”€â”€â”€â”
      â”‚ x_i â”‚            â”‚            â”‚ x_j â”‚
      â””â”€â”€â”¬â”€â”€â”˜            â”‚            â””â”€â”€â”¬â”€â”€â”˜
         â”‚               â”‚               â”‚
         â–¼               â”‚               â–¼
      Encoder f          â”‚            Encoder f
         â”‚               â”‚               â”‚
         â–¼               â”‚               â–¼
      â”Œâ”€â”€â”€â”€â”€â”            â”‚            â”Œâ”€â”€â”€â”€â”€â”
      â”‚ h_i â”‚            â”‚            â”‚ h_j â”‚
      â””â”€â”€â”¬â”€â”€â”˜            â”‚            â””â”€â”€â”¬â”€â”€â”˜
         â”‚               â”‚               â”‚
         â–¼               â”‚               â–¼
      Projector g        â”‚            Projector g
         â”‚               â”‚               â”‚
         â–¼               â”‚               â–¼
      â”Œâ”€â”€â”€â”€â”€â”            â”‚            â”Œâ”€â”€â”€â”€â”€â”
      â”‚ z_i â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚ z_j â”‚
      â””â”€â”€â”€â”€â”€â”˜       å¯¹æ¯”æŸå¤±           â””â”€â”€â”€â”€â”€â”˜
                   (æœ€å¤§åŒ–ç›¸ä¼¼åº¦)
```

**æ•°æ®å¢å¼ºç­–ç•¥**:
- éšæœºè£å‰ª + ç¼©æ”¾
- é¢œè‰²æŠ–åŠ¨ (Color Jittering)
- é«˜æ–¯æ¨¡ç³Š
- æ°´å¹³ç¿»è½¬

```python
import torch
import torch.nn as nn
import torch.nn.functional as F

class SimCLR(nn.Module):
    def __init__(self, encoder, proj_dim=128, temperature=0.07):
        super().__init__()
        self.encoder = encoder
        self.projector = nn.Sequential(
            nn.Linear(encoder.output_dim, 512),
            nn.ReLU(),
            nn.Linear(512, proj_dim)
        )
        self.temperature = temperature
    
    def forward(self, x_i, x_j):
        # ç¼–ç 
        h_i = self.encoder(x_i)  # [B, D]
        h_j = self.encoder(x_j)
        
        # æŠ•å½±
        z_i = F.normalize(self.projector(h_i), dim=1)
        z_j = F.normalize(self.projector(h_j), dim=1)
        
        # è®¡ç®—ç›¸ä¼¼åº¦çŸ©é˜µ
        batch_size = z_i.shape[0]
        z = torch.cat([z_i, z_j], dim=0)  # [2B, D]
        sim_matrix = torch.mm(z, z.t()) / self.temperature  # [2B, 2B]
        
        # æ„å»ºæ ‡ç­¾: æ­£æ ·æœ¬å¯¹åœ¨å¯¹è§’çº¿ä¸Š
        labels = torch.arange(batch_size, device=z.device)
        labels = torch.cat([labels + batch_size, labels])  # [2B]
        
        # ç§»é™¤è‡ªèº«ç›¸ä¼¼åº¦
        mask = torch.eye(2 * batch_size, dtype=torch.bool, device=z.device)
        sim_matrix.masked_fill_(mask, -float('inf'))
        
        # InfoNCE æŸå¤±
        loss = F.cross_entropy(sim_matrix, labels)
        return loss
```

#### 2.1.3 CLIP: è§†è§‰-è¯­è¨€å¯¹æ¯”å­¦ä¹ 

```python
def clip_loss(image_features, text_features, temperature=0.07):
    """
    image_features: [B, D] - å›¾åƒç¼–ç 
    text_features: [B, D] - æ–‡æœ¬ç¼–ç 
    """
    # å½’ä¸€åŒ–
    image_features = F.normalize(image_features, dim=1)
    text_features = F.normalize(text_features, dim=1)
    
    # ç›¸ä¼¼åº¦çŸ©é˜µ
    logits = torch.mm(image_features, text_features.t()) / temperature
    
    # å¯¹ç§°æŸå¤±
    labels = torch.arange(len(logits), device=logits.device)
    loss_i2t = F.cross_entropy(logits, labels)      # å›¾åƒâ†’æ–‡æœ¬
    loss_t2i = F.cross_entropy(logits.t(), labels)  # æ–‡æœ¬â†’å›¾åƒ
    
    return (loss_i2t + loss_t2i) / 2
```

### 2.2 æ©ç é¢„æµ‹ (Masked Prediction)

**æ ¸å¿ƒæ€æƒ³**: é®ä½éƒ¨åˆ†è¾“å…¥ï¼Œè®©æ¨¡å‹é¢„æµ‹è¢«é®ä½çš„éƒ¨åˆ†ã€‚

#### 2.2.1 MAE (Masked Autoencoder)

```
åŸå§‹å›¾åƒ (224x224)
    â”‚
    â–¼ Patch åˆ†å‰² (16x16)
196 ä¸ª Patches
    â”‚
    â–¼ éšæœº Mask (75%)
49 ä¸ªå¯è§ Patches + 147 ä¸ª Mask Tokens
    â”‚
    â–¼ ViT Encoder (åªå¤„ç†å¯è§ Patches)
    â”‚
    â–¼ æ·»åŠ  Mask Tokens + ä½ç½®ç¼–ç 
    â”‚
    â–¼ è½»é‡ Decoder (é‡å»ºå…¨éƒ¨ Patches)
    â”‚
    â–¼ MSE Loss (åªè®¡ç®—è¢« Mask çš„ Patches)
```

**å…³é”®è®¾è®¡**:
- **é«˜ Mask æ¯”ä¾‹ (75%)**: ä»»åŠ¡è¶³å¤Ÿéš¾ï¼Œå¼ºè¿«å­¦ä¹ è¯­ä¹‰
- **éå¯¹ç§°æ¶æ„**: é‡ç¼–ç å™¨ (ViT-L)ï¼Œè½»è§£ç å™¨ (å° Transformer)
- **åªç¼–ç å¯è§ Patches**: å¤§å¹…å‡å°‘è®¡ç®—é‡

```python
class MAE(nn.Module):
    def __init__(self, encoder, decoder, mask_ratio=0.75):
        super().__init__()
        self.encoder = encoder
        self.decoder = decoder
        self.mask_ratio = mask_ratio
        
        # Mask token
        self.mask_token = nn.Parameter(torch.zeros(1, 1, encoder.embed_dim))
    
    def random_masking(self, x, mask_ratio):
        """éšæœº Mask ç­–ç•¥"""
        B, N, D = x.shape  # [Batch, N_patches, Dim]
        num_keep = int(N * (1 - mask_ratio))
        
        # éšæœºæ‰“ä¹±
        noise = torch.rand(B, N, device=x.device)
        ids_shuffle = torch.argsort(noise, dim=1)
        ids_restore = torch.argsort(ids_shuffle, dim=1)
        
        # ä¿ç•™å‰ num_keep ä¸ª
        ids_keep = ids_shuffle[:, :num_keep]
        x_masked = torch.gather(x, 1, ids_keep.unsqueeze(-1).expand(-1, -1, D))
        
        # ç”Ÿæˆ mask (1 è¡¨ç¤ºè¢«ç§»é™¤)
        mask = torch.ones(B, N, device=x.device)
        mask[:, :num_keep] = 0
        mask = torch.gather(mask, 1, ids_restore)
        
        return x_masked, mask, ids_restore
    
    def forward(self, images):
        # Patch embedding
        patches = self.encoder.patch_embed(images)  # [B, N, D]
        
        # Random masking
        patches_masked, mask, ids_restore = self.random_masking(patches, self.mask_ratio)
        
        # Encode (åªå¤„ç†å¯è§ patches)
        latent = self.encoder.forward_encoder(patches_masked)
        
        # Decode (è¡¥å…… mask tokens)
        B, N_vis, D = latent.shape
        mask_tokens = self.mask_token.expand(B, ids_restore.shape[1] - N_vis, -1)
        latent_full = torch.cat([latent, mask_tokens], dim=1)
        latent_full = torch.gather(latent_full, 1, ids_restore.unsqueeze(-1).expand(-1, -1, D))
        
        pred = self.decoder(latent_full)  # [B, N, patch_size^2 * 3]
        
        # Loss (åªè®¡ç®— masked patches)
        target = self.patchify(images)
        loss = (pred - target) ** 2
        loss = (loss.mean(dim=-1) * mask).sum() / mask.sum()
        
        return loss
```

#### 2.2.2 VideoMAE: è§†é¢‘ç‰ˆ MAE

**å…³é”®æ”¹è¿›**:
- **æ—¶ç©º Masking**: å¯¹è§†é¢‘çš„æ—¶é—´å’Œç©ºé—´ç»´åº¦åŒæ—¶ Mask
- **Tube Masking**: åœ¨æ—¶é—´ä¸Šè¿ç»­ Mask åŒä¸€ä½ç½®ï¼ˆæ›´éš¾ï¼‰
- **è¿åŠ¨å…ˆéªŒ**: å­¦ä¹ æ—¶åºåŠ¨æ€

**å¯¹ VLA çš„ä»·å€¼**: ä»äººç±»è§†é¢‘ä¸­å­¦ä¹ åŠ¨ä½œçš„æ—¶åºæ¨¡å¼

### 2.3 é¢„æµ‹å­¦ä¹  (Predictive Learning)

#### 2.3.1 æ—¶é—´å¯¹æ¯”å­¦ä¹ 

```python
class TemporalContrastive(nn.Module):
    """å­¦ä¹ è§†é¢‘å¸§çš„æ—¶åºå…³ç³»"""
    def __init__(self, encoder, pred_steps=3):
        super().__init__()
        self.encoder = encoder
        self.predictor = nn.GRU(hidden_size, hidden_size)
        self.pred_steps = pred_steps
    
    def forward(self, video_frames):
        """
        video_frames: [B, T, C, H, W]
        """
        B, T, C, H, W = video_frames.shape
        
        # ç¼–ç æ¯å¸§
        features = []
        for t in range(T):
            feat = self.encoder(video_frames[:, t])
            features.append(feat)
        features = torch.stack(features, dim=1)  # [B, T, D]
        
        # é¢„æµ‹æœªæ¥å¸§ç‰¹å¾
        loss = 0
        for t in range(T - self.pred_steps):
            context = features[:, :t+1]  # å†å²å¸§
            pred, _ = self.predictor(context)
            pred = pred[:, -1]  # æœ€åä¸€æ­¥çš„é¢„æµ‹
            
            # å¯¹æ¯”å­¦ä¹ : æ­£æ ·æœ¬æ˜¯æœªæ¥å¸§
            target = features[:, t + self.pred_steps]
            loss += contrastive_loss(pred, target)
        
        return loss / (T - self.pred_steps)
```

#### 2.3.2 R3M: ä»äººç±»è§†é¢‘å­¦ä¹ æœºå™¨äººè¡¨ç¤º

**æ ¸å¿ƒæ€æƒ³**: äººç±»çš„æ‰‹éƒ¨åŠ¨ä½œä¸æœºå™¨äºº gripper ç±»ä¼¼ï¼Œå¯ä»¥è¿ç§»ã€‚

```
äººç±»è§†é¢‘ (Ego4D æ•°æ®é›†)
    â”‚
    â”œâ”€â–¶ æ—¶é—´å¯¹æ¯”å­¦ä¹  (Time Contrastive)
    â”‚   - ç›¸é‚»å¸§ç‰¹å¾åº”è¯¥ç›¸ä¼¼
    â”‚
    â”œâ”€â–¶ è§†é¢‘-è¯­è¨€å¯¹é½ (Video-Language Alignment)
    â”‚   - è§†é¢‘ä¸æ–‡å­—æè¿°å¯¹é½
    â”‚
    â””â”€â–¶ è¯­è¨€æ¡ä»¶æ—¶é—´å¯¹æ¯” (L3)
        - è¯­è¨€å¼•å¯¼çš„æ—¶åºé¢„æµ‹

    â”‚
    â–¼
é€šç”¨è§†è§‰è¡¨ç¤º (é€‚ç”¨äºæœºå™¨äºº)
```

## 3. VLA ä¸­çš„ SSL åº”ç”¨ (SSL in VLA)

### 3.1 è§†è§‰ç¼–ç å™¨é¢„è®­ç»ƒ

| æ–¹æ³• | æ•°æ® | ç”¨äº VLA |
| :--- | :--- | :--- |
| **ImageNet ç›‘ç£** | 1M å›¾åƒ + æ ‡ç­¾ | åŸºç¡€ç‰¹å¾ |
| **CLIP** | 400M å›¾æ–‡å¯¹ | è¯­ä¹‰å¯¹é½ |
| **DINOv2** | 142M æ— æ ‡ç­¾å›¾åƒ | ç©ºé—´ç‰¹å¾ |
| **R3M** | Ego4D äººç±»è§†é¢‘ | æ“ä½œç›¸å…³ç‰¹å¾ |

### 3.2 ä¸–ç•Œæ¨¡å‹é¢„è®­ç»ƒ

```python
class WorldModelSSL(nn.Module):
    """ä»è§†é¢‘é¢„æµ‹æœªæ¥å¸§ï¼Œå­¦ä¹ ç‰©ç†è§„å¾‹"""
    def __init__(self):
        self.encoder = ViTEncoder()
        self.dynamics = TransformerDynamics()
        self.decoder = ViTDecoder()
    
    def forward(self, video, actions=None):
        """
        video: [B, T, C, H, W]
        actions: [B, T-1, A] (å¯é€‰ï¼ŒåŠ¨ä½œæ¡ä»¶)
        """
        # ç¼–ç å†å²å¸§
        B, T, C, H, W = video.shape
        latents = []
        for t in range(T):
            z_t = self.encoder(video[:, t])
            latents.append(z_t)
        latents = torch.stack(latents, dim=1)  # [B, T, D]
        
        # é¢„æµ‹ä¸‹ä¸€å¸§
        pred_latents = self.dynamics(latents[:, :-1], actions)
        
        # é‡å»º
        pred_frames = self.decoder(pred_latents)
        
        # æŸå¤±: é¢„æµ‹ä¸çœŸå®æœªæ¥å¸§çš„å·®å¼‚
        loss = F.mse_loss(pred_frames, video[:, 1:])
        return loss
```

### 3.3 åŠ¨ä½œè¡¨ç¤ºå­¦ä¹ 

```python
class ActionSSL(nn.Module):
    """ä»è§†é¢‘ä¸­å­¦ä¹ éšå¼åŠ¨ä½œè¡¨ç¤º"""
    def __init__(self):
        self.encoder = VideoEncoder()
        self.action_predictor = MLP()
    
    def forward(self, frame_t, frame_t1):
        """é¢„æµ‹ä¸¤å¸§ä¹‹é—´çš„éšå¼åŠ¨ä½œ"""
        z_t = self.encoder(frame_t)
        z_t1 = self.encoder(frame_t1)
        
        # é¢„æµ‹"åŠ¨ä½œ"ä½¿å¾— z_t â†’ z_t1
        pred_action = self.action_predictor(torch.cat([z_t, z_t1], dim=-1))
        
        # è‡ªç›‘ç£ç›®æ ‡: åŠ¨ä½œåº”è¯¥èƒ½å¤Ÿé¢„æµ‹çŠ¶æ€å˜åŒ–
        pred_z_t1 = self.dynamics(z_t, pred_action)
        loss = F.mse_loss(pred_z_t1, z_t1.detach())
        
        return loss, pred_action
```

## 4. æ•°æ®å¢å¼ºç­–ç•¥ (Data Augmentation)

### 4.1 å›¾åƒå¢å¼º

```python
import torchvision.transforms as T

## VLA å¸¸ç”¨å¢å¼º
train_transform = T.Compose([
    T.RandomResizedCrop(224, scale=(0.8, 1.0)),
    T.RandomHorizontalFlip(p=0.5),  # æ³¨æ„: æœºå™¨äººä»»åŠ¡å¯èƒ½éœ€è¦ç¦ç”¨
    T.ColorJitter(0.4, 0.4, 0.4, 0.1),
    T.GaussianBlur(kernel_size=23, sigma=(0.1, 2.0)),
    T.ToTensor(),
    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])
```

### 4.2 æœºå™¨äººç‰¹å®šå¢å¼º

```python
class RobotAugmentation:
    """æœºå™¨äººåœºæ™¯çš„æ•°æ®å¢å¼º"""
    
    @staticmethod
    def camera_shift(image, proprio, max_shift=10):
        """æ¨¡æ‹Ÿç›¸æœºä½ç½®è½»å¾®åç§»"""
        shift_x = random.randint(-max_shift, max_shift)
        shift_y = random.randint(-max_shift, max_shift)
        image = T.functional.affine(image, angle=0, translate=(shift_x, shift_y), scale=1, shear=0)
        return image, proprio
    
    @staticmethod
    def action_noise(action, noise_std=0.01):
        """ç»™åŠ¨ä½œæ·»åŠ å™ªå£°ï¼ˆç”¨äº BCï¼‰"""
        noise = torch.randn_like(action) * noise_std
        return action + noise
    
    @staticmethod
    def temporal_crop(video, crop_ratio=0.8):
        """æ—¶é—´ç»´åº¦è£å‰ª"""
        T = video.shape[0]
        crop_len = int(T * crop_ratio)
        start = random.randint(0, T - crop_len)
        return video[start:start + crop_len]
```

## 5. å¯¹æ¯”å­¦ä¹  vs æ©ç é¢„æµ‹ (Comparison)

| ç‰¹æ€§ | å¯¹æ¯”å­¦ä¹  (Contrastive) | æ©ç é¢„æµ‹ (Masked) |
| :--- | :--- | :--- |
| **ä»£è¡¨** | SimCLR, CLIP, MoCo | MAE, BEiT |
| **ç›®æ ‡** | å­¦ä¹ ä¸å˜æ€§è¡¨ç¤º | å­¦ä¹ é‡å»ºèƒ½åŠ› |
| **æ•°æ®å¢å¼º** | å¼ºä¾èµ– | ä¸ä¾èµ– |
| **è´Ÿæ ·æœ¬** | éœ€è¦ (å¤§ batch) | ä¸éœ€è¦ |
| **è®¡ç®—æ•ˆç‡** | ä½ (å¤§ batch) | é«˜ (åªç¼–ç  25%) |
| **ä¸‹æ¸¸ä»»åŠ¡** | åˆ†ç±»ã€æ£€ç´¢ | æ£€æµ‹ã€åˆ†å‰² |
| **VLA é€‚ç”¨** | è¯­ä¹‰ç†è§£ | ç©ºé—´ç²¾ç»†ä»»åŠ¡ |

## 6. é¢è¯•é«˜é¢‘é—®é¢˜ (Q&A)

**Q1: å¯¹æ¯”å­¦ä¹ ä¸­æ¸©åº¦ç³»æ•° Ï„ çš„ä½œç”¨æ˜¯ä»€ä¹ˆ?**

A:
- **Ï„ å°**: åˆ†å¸ƒæ›´ sharpï¼Œå¯¹è´Ÿæ ·æœ¬åŒºåˆ†æ›´ä¸¥æ ¼ï¼Œä½†å®¹æ˜“è¿‡æ‹Ÿåˆå™ªå£°
- **Ï„ å¤§**: åˆ†å¸ƒæ›´ uniformï¼Œå¯¹æ¯”æ›´"è½¯"ï¼Œä½†éš¾ä»¥å­¦ä¹ ç»†ç²’åº¦åŒºåˆ†
- **ç»éªŒå€¼**: 0.07 (CLIP), 0.1 (SimCLR)

**Q2: MAE ä¸ºä»€ä¹ˆè¦ Mask 75% è¿™ä¹ˆé«˜çš„æ¯”ä¾‹?**

A:
- **ä»»åŠ¡éš¾åº¦**: æ¯”ä¾‹ä½æ—¶ä»»åŠ¡å¤ªç®€å•ï¼Œé€šè¿‡æ’å€¼å°±èƒ½é‡å»º
- **è¯­ä¹‰å­¦ä¹ **: é«˜æ¯”ä¾‹å¼ºè¿«æ¨¡å‹ç†è§£å›¾åƒçš„æ•´ä½“è¯­ä¹‰ç»“æ„
- **æ•ˆç‡**: åªç¼–ç  25% patchesï¼Œè®¡ç®—é‡å‡å°‘ 4 å€
- **å¯¹æ¯”**: NLP çš„ BERT åª Mask 15%ï¼Œå› ä¸ºè¯­è¨€å†—ä½™æ›´ä½

**Q3: R3M å¦‚ä½•ä»äººç±»è§†é¢‘è¿ç§»åˆ°æœºå™¨äºº?**

A:
- **å‡è®¾**: äººç±»æ‰‹éƒ¨æ“ä½œçš„è§†è§‰ç‰¹å¾ä¸æœºå™¨äºº gripper ç±»ä¼¼
- **æ•°æ®**: Ego4D (ç¬¬ä¸€äººç§°è§†é¢‘) å«å¤§é‡æ‰‹-ç‰©äº¤äº’
- **æ–¹æ³•**: æ—¶é—´å¯¹æ¯” + è¯­è¨€å¯¹é½ï¼Œå­¦ä¹ "åŠ¨ä½œç›¸å…³"çš„è§†è§‰è¡¨ç¤º
- **è¿ç§»**: å†»ç»“ç¼–ç å™¨ï¼Œåªè®­ç»ƒç­–ç•¥å¤´

**Q4: è‡ªç›‘ç£å­¦ä¹ åœ¨ VLA ä¸­æœ€å¤§çš„ä»·å€¼æ˜¯ä»€ä¹ˆ?**

A:
- **æ•°æ®æ•ˆç‡**: åˆ©ç”¨æµ·é‡æ— æ ‡ç­¾æ•°æ®é¢„è®­ç»ƒï¼Œå‡å°‘å¯¹ç¨€ç¼ºæœºå™¨äººæ•°æ®çš„ä¾èµ–
- **æ³›åŒ–èƒ½åŠ›**: é¢„è®­ç»ƒç‰¹å¾å…·æœ‰æ›´å¥½çš„è·¨åŸŸæ³›åŒ–èƒ½åŠ›
- **ä¸–ç•Œæ¨¡å‹**: ä»è§†é¢‘å­¦ä¹ ç‰©ç†è§„å¾‹ï¼Œæ”¯æŒæ¨¡å‹é¢„æµ‹æ§åˆ¶

**Q5: å¦‚ä½•é€‰æ‹© SSL æ–¹æ³•è¿›è¡Œ VLA é¢„è®­ç»ƒ?**

A:
- **è¯­ä¹‰ç†è§£ä»»åŠ¡** (å¦‚æŒ‡ä»¤è·Ÿéš): CLIP / å¯¹æ¯”å­¦ä¹ 
- **ç©ºé—´ç²¾ç»†ä»»åŠ¡** (å¦‚ç²¾å¯†è£…é…): MAE / DINOv2
- **åŠ¨ä½œé¢„æµ‹ä»»åŠ¡**: R3M / VideoMAE

## 7. å‚è€ƒèµ„æº (References)

- **SimCLR**: [A Simple Framework for Contrastive Learning](https://arxiv.org/abs/2002.05709)
- **MAE**: [Masked Autoencoders Are Scalable Vision Learners](https://arxiv.org/abs/2111.06377)
- **CLIP**: [Learning Transferable Visual Models](https://arxiv.org/abs/2103.00020)
- **R3M**: [R3M: A Universal Visual Representation for Robot Manipulation](https://arxiv.org/abs/2203.12601)
- **DINOv2**: [DINOv2: Learning Robust Visual Features](https://arxiv.org/abs/2304.07193)

---


\newpage

# ç¬¬14ç«  è¿ç§»å­¦ä¹ ä¸ Co-training


## ä¸»è¦æ•°å­¦æ€æƒ³ (Main Mathematical Idea)

> **"Distribution Alignment (åˆ†å¸ƒå¯¹é½) & Representation Invariance (è¡¨ç¤ºä¸å˜æ€§)"**

è¿ç§»å­¦ä¹ çš„æ ¸å¿ƒæ•°å­¦é—®é¢˜æ˜¯è§£å†³ **Domain Shift (åŸŸåç§»)**ï¼Œå³æºåŸŸåˆ†å¸ƒ $P_S(X, Y)$ ä¸ç›®æ ‡åŸŸåˆ†å¸ƒ $P_T(X, Y)$ ä¸ä¸€è‡´ ($P_S \neq P_T$)ã€‚

è§£å†³è¿™ä¸€é—®é¢˜çš„ç¬¬ä¸€æ€§åŸç†æ˜¯å¯»æ‰¾ä¸€ä¸ªæ˜ å°„å‡½æ•° $\Phi$ï¼Œä½¿å¾—æ˜ å°„åçš„ç‰¹å¾åˆ†å¸ƒå°½å¯èƒ½æ¥è¿‘ï¼š
$$ \text{Minimize } \text{Distance}(P_S(\Phi(X)), P_T(\Phi(X))) $$
å…¶ä¸­ Distance é€šå¸¸ç”± MMD (æœ€å¤§å‡å€¼å·®å¼‚) æˆ– Adversarial Loss (å¯¹æŠ—æŸå¤±) æ¥è¡¡é‡ã€‚æœ¬è´¨ä¸Šï¼Œè¿™æ˜¯åœ¨å¯»æ‰¾ä¸€ç§**è·¨åŸŸä¸å˜çš„è¡¨ç¤º (Invariant Representation)**ï¼Œä½¿å¾—æ¨¡å‹åœ¨æ–°çš„ç¯å¢ƒä¸­ä¾ç„¶èƒ½è¯†åˆ«å‡ºæœ¬è´¨ç‰¹å¾ã€‚

---

> **æ ¸å¿ƒæ¦‚å¿µ**: è¿ç§»å­¦ä¹  (Transfer Learning) æ˜¯å°†åœ¨**æºåŸŸ (Source Domain)** å­¦åˆ°çš„çŸ¥è¯†åº”ç”¨åˆ°**ç›®æ ‡åŸŸ (Target Domain)** çš„æŠ€æœ¯ã€‚åœ¨ VLA é¢†åŸŸï¼Œè¿ç§»å­¦ä¹ æ˜¯å®ç°è·¨æœºå™¨äººã€è·¨åœºæ™¯æ³›åŒ–çš„å…³é”®ã€‚

## 1. ä¸ºä»€ä¹ˆ VLA éœ€è¦è¿ç§»å­¦ä¹ ? (Why Transfer Learning?)

### 1.1 æœºå™¨äººå­¦ä¹ çš„è¿ç§»æŒ‘æˆ˜

| è¿ç§»ç±»å‹ | æºåŸŸ | ç›®æ ‡åŸŸ | æŒ‘æˆ˜ |
| :--- | :--- | :--- | :--- |
| **è·¨å½¢æ€ (Cross-Embodiment)** | å•è‡‚æœºå™¨äºº | åŒè‡‚æœºå™¨äºº | åŠ¨ä½œç©ºé—´ä¸åŒ |
| **è·¨åœºæ™¯ (Cross-Environment)** | å®éªŒå®¤ | çœŸå®å®¶åº­ | è§†è§‰åˆ†å¸ƒåç§» |
| **è·¨ä»»åŠ¡ (Cross-Task)** | æŠ“å–ç‰©ä½“ | æŠ˜å è¡£ç‰© | æŠ€èƒ½å·®å¼‚å¤§ |
| **ä»¿çœŸåˆ°çœŸå® (Sim-to-Real)** | ä»¿çœŸç¯å¢ƒ | çœŸæœº | ç‰©ç†å·®å¼‚ |

### 1.2 è¿ç§»å­¦ä¹ çš„ä»·å€¼

$$
\text{æ•°æ®æ”¶é›†æˆæœ¬} = \frac{\text{æ‰€éœ€æ•°æ®é‡}}{\text{æ•°æ®æ”¶é›†æ•ˆç‡}} \propto \frac{1}{\text{è¿ç§»èƒ½åŠ›}}
$$

- **å‡å°‘æ•°æ®éœ€æ±‚**: é¢„è®­ç»ƒæ¨¡å‹åªéœ€å°‘é‡ç›®æ ‡åŸŸæ•°æ®å¾®è°ƒ
- **æé«˜æ³›åŒ–èƒ½åŠ›**: å­¦ä¹ è·¨åŸŸä¸å˜çš„ç‰¹å¾è¡¨ç¤º
- **åŠ é€Ÿéƒ¨ç½²**: æ–°æœºå™¨äºº/åœºæ™¯æ— éœ€ä»å¤´è®­ç»ƒ

## 2. è¿ç§»å­¦ä¹ èŒƒå¼ (Transfer Learning Paradigms)

### 2.1 é¢„è®­ç»ƒ-å¾®è°ƒ (Pre-training + Fine-tuning)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Phase 1: Pre-training                    â”‚
â”‚                                                             â”‚
â”‚   å¤§è§„æ¨¡æ•°æ® (ImageNet/CLIP/OXE)                            â”‚
â”‚              â”‚                                              â”‚
â”‚              â–¼                                              â”‚
â”‚        é¢„è®­ç»ƒæ¨¡å‹ (é€šç”¨ç‰¹å¾)                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Phase 2: Fine-tuning                     â”‚
â”‚                                                             â”‚
â”‚   ç›®æ ‡åŸŸå°‘é‡æ•°æ® (50-500 episodes)                           â”‚
â”‚              â”‚                                              â”‚
â”‚              â–¼                                              â”‚
â”‚        å¾®è°ƒåæ¨¡å‹ (ç›®æ ‡ä»»åŠ¡ç‰¹å®š)                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 å†»ç»“ç‰¹å¾æå– (Feature Extraction)

åªè®­ç»ƒä»»åŠ¡å¤´ï¼Œå†»ç»“é¢„è®­ç»ƒçš„ backboneã€‚

```python
class FeatureExtraction(nn.Module):
    def __init__(self, pretrained_encoder, action_dim):
        super().__init__()
        self.encoder = pretrained_encoder
        
        # å†»ç»“ç¼–ç å™¨
        for param in self.encoder.parameters():
            param.requires_grad = False
        
        # åªè®­ç»ƒç­–ç•¥å¤´
        self.policy_head = nn.Sequential(
            nn.Linear(encoder.output_dim, 256),
            nn.ReLU(),
            nn.Linear(256, action_dim)
        )
    
    def forward(self, obs):
        with torch.no_grad():
            features = self.encoder(obs)
        action = self.policy_head(features)
        return action
```

**é€‚ç”¨**: ç›®æ ‡åŸŸæ•°æ®æå°‘ (< 50 episodes)

### 2.3 å…¨é‡å¾®è°ƒ (Full Fine-tuning)

è§£å†»æ‰€æœ‰å‚æ•°è¿›è¡Œè®­ç»ƒã€‚

```python
class FullFineTuning(nn.Module):
    def __init__(self, pretrained_model):
        super().__init__()
        self.model = pretrained_model
        
        # æ‰€æœ‰å‚æ•°å¯è®­ç»ƒ
        for param in self.model.parameters():
            param.requires_grad = True
    
    def forward(self, obs):
        return self.model(obs)
```

**é€‚ç”¨**: ç›®æ ‡åŸŸæ•°æ®å……è¶³ï¼Œä¸”ä¸æºåŸŸå·®å¼‚è¾ƒå¤§

### 2.4 å‚æ•°é«˜æ•ˆå¾®è°ƒ (Parameter-Efficient Fine-Tuning, PEFT)

åªè®­ç»ƒå°‘é‡æ–°å¢å‚æ•°å³å¯é€‚é…æ–°ä»»åŠ¡ï¼Œå¸¸è§å·¥å…·åŒ…æ‹¬ LoRAã€Prompt Tuningã€Adapter ç­‰ã€‚

LoRA é€šè¿‡åœ¨æŠ•å½±å±‚ä¸­ä¸²æ¥ä½ç§©å¢é‡ï¼ˆ$W' = W_0 + BA$ï¼‰æ¥æ¨¡æ‹Ÿå¾®è°ƒæ•ˆæœï¼Œå¤§å¹…å‡å°‘å¯è®­ç»ƒå‚æ•°ã€å‡è½»æ˜¾å­˜å‹åŠ›ï¼Œè¿˜å¯ä»¥ä¸ºä¸åŒä»»åŠ¡ä¿å­˜å¤šä¸ªé€‚é…å™¨ã€‚

è¯¦ç»†çš„ LoRA æ•°å­¦æ¨å¯¼ä¸å®è·µç¤ºä¾‹è¯·å‚è€ƒ **[theory/peft_lora.md](./peft_lora.md)**ï¼ˆè¯¥æ–‡æ¡£ä¹Ÿæ˜¯ VLA ä¸­ PEFT çš„æƒå¨å‚è€ƒï¼‰ï¼Œè¿™é‡Œåªä¿ç•™é«˜å±‚æ€»ç»“å’Œç»éªŒå€¼ã€‚

## 3. è·¨å½¢æ€è¿ç§» (Cross-Embodiment Transfer)

### 3.1 åŠ¨ä½œç©ºé—´å¯¹é½

ä¸åŒæœºå™¨äººçš„åŠ¨ä½œç©ºé—´å·®å¼‚æ˜¯è·¨å½¢æ€è¿ç§»çš„æ ¸å¿ƒæŒ‘æˆ˜ã€‚

```python
class ActionSpaceAdapter(nn.Module):
    """å°†æºåŸŸåŠ¨ä½œæ˜ å°„åˆ°ç›®æ ‡åŸŸ"""
    def __init__(self, source_action_dim, target_action_dim):
        super().__init__()
        self.adapter = nn.Sequential(
            nn.Linear(source_action_dim, 128),
            nn.ReLU(),
            nn.Linear(128, target_action_dim)
        )
    
    def forward(self, source_action):
        return self.adapter(source_action)
```

### 3.2 ç»Ÿä¸€åŠ¨ä½œè¡¨ç¤º

**RDT/OpenVLA çš„æ–¹æ¡ˆ**: ç»Ÿä¸€å¡«å……åˆ°æœ€å¤§ç»´åº¦

```python
def unify_action_space(action, embodiment_type, max_dim=32):
    """ç»Ÿä¸€ä¸åŒæœºå™¨äººçš„åŠ¨ä½œç©ºé—´"""
    action_mapping = {
        "franka_7dof": 7,
        "ur5_6dof": 6,
        "bimanual_14dof": 14,
        "mobile_3dof": 3
    }
    
    original_dim = action_mapping[embodiment_type]
    
    # å¡«å……åˆ°ç»Ÿä¸€ç»´åº¦
    padded_action = F.pad(action, (0, max_dim - original_dim))
    
    # åˆ›å»ºæœ‰æ•ˆç»´åº¦ mask
    mask = torch.zeros(max_dim)
    mask[:original_dim] = 1
    
    return padded_action, mask
```

### 3.3 å½¢æ€æ— å…³ç‰¹å¾å­¦ä¹ 

```python
class EmbodimentInvariantEncoder(nn.Module):
    """å­¦ä¹ ä¸æœºå™¨äººå½¢æ€æ— å…³çš„ç‰¹å¾"""
    def __init__(self, obs_encoder, action_encoder):
        super().__init__()
        self.obs_encoder = obs_encoder
        self.action_encoder = action_encoder
        
        # å¯¹æŠ—å­¦ä¹ : åˆ†ç±»å™¨è¯•å›¾åŒºåˆ†å½¢æ€
        self.embodiment_classifier = nn.Linear(hidden_dim, num_embodiments)
        self.gradient_reversal = GradientReversalLayer()
    
    def forward(self, obs, action, embodiment_label):
        # ç¼–ç è§‚æµ‹
        obs_feat = self.obs_encoder(obs)
        
        # å¯¹æŠ—è®­ç»ƒ: è®©ç‰¹å¾æ— æ³•åŒºåˆ†å½¢æ€
        reversed_feat = self.gradient_reversal(obs_feat)
        embodiment_pred = self.embodiment_classifier(reversed_feat)
        adversarial_loss = F.cross_entropy(embodiment_pred, embodiment_label)
        
        return obs_feat, adversarial_loss
```

## 4. ä»¿çœŸåˆ°çœŸå®è¿ç§» (Sim-to-Real Transfer)

### 4.1 Domain Randomization (åŸŸéšæœºåŒ–)

åœ¨ä»¿çœŸä¸­éšæœºåŒ–å„ç§å‚æ•°ï¼Œè®©æ¨¡å‹å¯¹å˜åŒ–é²æ£’ã€‚

```python
class DomainRandomization:
    """ä»¿çœŸç¯å¢ƒçš„åŸŸéšæœºåŒ–"""
    
    @staticmethod
    def visual_randomization(image):
        """è§†è§‰éšæœºåŒ–"""
        transforms = [
            T.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3),
            T.GaussianBlur(kernel_size=5),
            T.RandomAdjustSharpness(sharpness_factor=2),
        ]
        for t in transforms:
            if random.random() > 0.5:
                image = t(image)
        return image
    
    @staticmethod
    def physics_randomization(env):
        """ç‰©ç†å‚æ•°éšæœºåŒ–"""
        # æ‘©æ“¦ç³»æ•°
        env.set_friction(random.uniform(0.5, 1.5))
        # ç‰©ä½“è´¨é‡
        env.set_object_mass(random.uniform(0.8, 1.2) * default_mass)
        # ç”µæœºå»¶è¿Ÿ
        env.set_actuator_delay(random.uniform(0, 0.05))
        return env
    
    @staticmethod
    def camera_randomization(env):
        """ç›¸æœºå‚æ•°éšæœºåŒ–"""
        # ç›¸æœºä½ç½®æ‰°åŠ¨
        env.camera_pos += np.random.uniform(-0.02, 0.02, size=3)
        # FOV å˜åŒ–
        env.camera_fov = random.uniform(55, 65)
        return env
```

### 4.2 System Identification (ç³»ç»Ÿè¾¨è¯†)

```python
class SystemIdentification(nn.Module):
    """ä»çœŸå®æ•°æ®æ¨æ–­ä»¿çœŸå‚æ•°"""
    def __init__(self):
        self.encoder = nn.LSTM(obs_dim, hidden_dim)
        self.param_predictor = nn.Linear(hidden_dim, physics_param_dim)
    
    def forward(self, trajectory):
        """
        trajectory: [T, obs_dim] - çœŸå®è½¨è¿¹
        """
        _, (h_n, _) = self.encoder(trajectory)
        predicted_params = self.param_predictor(h_n.squeeze())
        return predicted_params  # e.g., æ‘©æ“¦ç³»æ•°ã€è´¨é‡ç­‰
```

### 4.3 Real-to-Sim-to-Real

```
çœŸå®æ•°æ® (å°‘é‡)
    â”‚
    â–¼ System Identification
ä»¿çœŸå‚æ•°æ ¡å‡†
    â”‚
    â–¼ å¤§é‡ä»¿çœŸæ•°æ®ç”Ÿæˆ
    â”‚
    â–¼ ä»¿çœŸè®­ç»ƒ
    â”‚
    â–¼ Sim-to-Real Fine-tuning
çœŸæœºéƒ¨ç½²
```

## 5. åŸŸé€‚åº” (Domain Adaptation)

### 5.1 å¯¹æŠ—åŸŸé€‚åº” (Adversarial Domain Adaptation)

```python
class DANN(nn.Module):
    """Domain-Adversarial Neural Network"""
    def __init__(self):
        self.feature_extractor = FeatureExtractor()
        self.task_classifier = TaskClassifier()
        self.domain_classifier = DomainClassifier()
    
    def forward(self, source_data, target_data, alpha=1.0):
        # æºåŸŸç‰¹å¾
        source_feat = self.feature_extractor(source_data)
        source_task_pred = self.task_classifier(source_feat)
        
        # ç›®æ ‡åŸŸç‰¹å¾
        target_feat = self.feature_extractor(target_data)
        
        # åŸŸåˆ†ç±»å™¨ (é€šè¿‡æ¢¯åº¦åè½¬å¯¹æŠ—è®­ç»ƒ)
        source_domain = self.domain_classifier(
            GradientReversal.apply(source_feat, alpha)
        )
        target_domain = self.domain_classifier(
            GradientReversal.apply(target_feat, alpha)
        )
        
        # åŸŸåˆ†ç±»æŸå¤±: è®©ç‰¹å¾æ— æ³•åŒºåˆ†æ¥è‡ªå“ªä¸ªåŸŸ
        domain_loss = F.binary_cross_entropy(
            torch.cat([source_domain, target_domain]),
            torch.cat([torch.zeros_like(source_domain), 
                       torch.ones_like(target_domain)])
        )
        
        return source_task_pred, domain_loss


class GradientReversal(torch.autograd.Function):
    @staticmethod
    def forward(ctx, x, alpha):
        ctx.alpha = alpha
        return x.view_as(x)
    
    @staticmethod
    def backward(ctx, grad_output):
        # åè½¬æ¢¯åº¦
        return -ctx.alpha * grad_output, None
```

### 5.2 æœ€å¤§å‡å€¼å·®å¼‚ (MMD)

```python
def mmd_loss(source_features, target_features, kernel='rbf'):
    """Maximum Mean Discrepancy æŸå¤±"""
    def rbf_kernel(x, y, sigma=1.0):
        dist = torch.cdist(x, y) ** 2
        return torch.exp(-dist / (2 * sigma ** 2))
    
    K_ss = rbf_kernel(source_features, source_features)
    K_tt = rbf_kernel(target_features, target_features)
    K_st = rbf_kernel(source_features, target_features)
    
    mmd = K_ss.mean() + K_tt.mean() - 2 * K_st.mean()
    return mmd
```

## 6. é›¶æ ·æœ¬/å°‘æ ·æœ¬è¿ç§» (Zero/Few-Shot Transfer)

### 6.1 è¯­è¨€å¼•å¯¼çš„é›¶æ ·æœ¬è¿ç§»

```python
class LanguageGuidedTransfer(nn.Module):
    """é€šè¿‡è¯­è¨€æè¿°å®ç°é›¶æ ·æœ¬è¿ç§»"""
    def __init__(self, vlm_backbone):
        super().__init__()
        self.vlm = vlm_backbone
        
    def forward(self, image, task_description):
        """
        task_description: "pick up the red cup and place it on the tray"
        æ— éœ€è¯¥ä»»åŠ¡çš„è®­ç»ƒæ•°æ®ï¼Œä¾é  VLM çš„è¯­ä¹‰ç†è§£
        """
        # VLM ç›´æ¥ç†è§£æ–°ä»»åŠ¡
        action = self.vlm.generate_action(image, task_description)
        return action
```

### 6.2 å°‘æ ·æœ¬å­¦ä¹ ç­–ç•¥

```python
class FewShotPolicy(nn.Module):
    """å°‘æ ·æœ¬å­¦ä¹ ç­–ç•¥"""
    def __init__(self, base_policy, adaptation_steps=5):
        super().__init__()
        self.base_policy = base_policy
        self.adaptation_steps = adaptation_steps
    
    def adapt(self, support_set, lr=0.01):
        """åœ¨å°‘é‡æ”¯æŒæ ·æœ¬ä¸Šå¿«é€Ÿé€‚åº”"""
        # å¤åˆ¶å‚æ•°
        adapted_params = {k: v.clone() for k, v in self.base_policy.named_parameters()}
        
        for _ in range(self.adaptation_steps):
            # è®¡ç®—æ”¯æŒé›†ä¸Šçš„æŸå¤±
            loss = 0
            for obs, action in support_set:
                pred_action = self.base_policy(obs)
                loss += F.mse_loss(pred_action, action)
            loss /= len(support_set)
            
            # æ¢¯åº¦æ›´æ–°
            grads = torch.autograd.grad(loss, adapted_params.values())
            adapted_params = {
                k: v - lr * g 
                for (k, v), g in zip(adapted_params.items(), grads)
            }
        
        return adapted_params
```

## 7. VLA ä¸­çš„è¿ç§»å­¦ä¹ å®è·µ (Practical Transfer in VLA)

### 7.1 OpenVLA çš„è¿ç§»æµç¨‹

```python
## 1. åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
from transformers import AutoModelForVision2Seq
model = AutoModelForVision2Seq.from_pretrained("openvla/openvla-7b")

## 2. é…ç½® LoRA
from peft import LoraConfig, get_peft_model

lora_config = LoraConfig(
    r=16,
    lora_alpha=32,
    target_modules=["q_proj", "v_proj", "k_proj", "o_proj"],
    lora_dropout=0.05,
)
model = get_peft_model(model, lora_config)

## 3. åœ¨ç›®æ ‡æ•°æ®ä¸Šå¾®è°ƒ
for batch in target_dataloader:
    loss = model.compute_loss(**batch)
    loss.backward()
    optimizer.step()

## 4. ä¿å­˜é€‚é…å™¨
model.save_pretrained("./openvla-adapted-myrobot")
```

### 7.2 è¿ç§»æ•ˆæœå¯¹æ¯”

| æ–¹æ³• | ç›®æ ‡åŸŸæ•°æ®é‡ | æˆåŠŸç‡ | è®­ç»ƒæ—¶é—´ |
| :--- | :--- | :--- | :--- |
| ä»å¤´è®­ç»ƒ | 1000 episodes | 65% | 10 hours |
| å…¨é‡å¾®è°ƒ | 100 episodes | 72% | 2 hours |
| LoRA å¾®è°ƒ | 50 episodes | **78%** | **30 min** |
| å†»ç»“+ç­–ç•¥å¤´ | 20 episodes | 60% | 10 min |

## 8. é¢è¯•é«˜é¢‘é—®é¢˜ (Q&A)

**Q1: è¿ç§»å­¦ä¹ å’ŒåŸŸé€‚åº”çš„åŒºåˆ«æ˜¯ä»€ä¹ˆ?**

A:
- **è¿ç§»å­¦ä¹ **: å¹¿ä¹‰æ¦‚å¿µï¼Œä»»ä½•åˆ©ç”¨æºåŸŸçŸ¥è¯†å¸®åŠ©ç›®æ ‡åŸŸå­¦ä¹ çš„æ–¹æ³•
- **åŸŸé€‚åº”**: è¿ç§»å­¦ä¹ çš„å­ç±»ï¼Œä¸“æ³¨äºè§£å†³æºåŸŸå’Œç›®æ ‡åŸŸ**åˆ†å¸ƒä¸åŒ**çš„é—®é¢˜
- **å…³ç³»**: åŸŸé€‚åº”æ˜¯å®ç°è¿ç§»å­¦ä¹ çš„ä¸€ç§å…·ä½“æŠ€æœ¯

**Q2: ä¸ºä»€ä¹ˆ LoRA åœ¨ VLA ä¸­æ•ˆæœå¥½?**

A:
- **æ•°æ®æ•ˆç‡**: æœºå™¨äººæ•°æ®ç¨€ç¼ºï¼Œå°‘é‡å‚æ•°æ›´ä¸æ˜“è¿‡æ‹Ÿåˆ
- **çŸ¥è¯†ä¿ç•™**: VLM çš„é¢„è®­ç»ƒçŸ¥è¯†é€šè¿‡å†»ç»“ä¸»å¹²è¢«ä¿æŠ¤
- **å¤šä»»åŠ¡é€‚é…**: å¯ä»¥ä¸ºä¸åŒä»»åŠ¡/æœºå™¨äººä¿å­˜ç‹¬ç«‹çš„ LoRA é€‚é…å™¨
- **éƒ¨ç½²é«˜æ•ˆ**: æ¨ç†æ—¶å¯ä»¥åˆå¹¶ LoRA æƒé‡ï¼Œæ— é¢å¤–å¼€é”€

**Q3: Sim-to-Real ä¸­ Domain Randomization çš„å±€é™æ€§?**

A:
- **å‚æ•°æ•æ„Ÿ**: éšæœºåŒ–èŒƒå›´éœ€è¦ç²¾å¿ƒè°ƒæ•´ï¼Œè¿‡å¤§ä¼šé™ä½æ€§èƒ½
- **æ— æ³•è¦†ç›–æ‰€æœ‰å·®å¼‚**: æœ‰äº›çœŸå®ä¸–ç•Œçš„å¤æ‚æ€§éš¾ä»¥åœ¨ä»¿çœŸä¸­å»ºæ¨¡
- **è®­ç»ƒæ•ˆç‡**: æç«¯éšæœºåŒ–å¯èƒ½å¯¼è‡´å­¦ä¹ å›°éš¾
- **æ”¹è¿›æ–¹æ¡ˆ**: ç»“åˆ System Identification æˆ– Real-to-Sim

**Q4: è·¨å½¢æ€è¿ç§»çš„æ ¸å¿ƒæŒ‘æˆ˜æ˜¯ä»€ä¹ˆ?**

A:
- **åŠ¨ä½œç©ºé—´ä¸ä¸€è‡´**: ä¸åŒæœºå™¨äºº DoF ä¸åŒ
- **è§‚æµ‹ç©ºé—´å·®å¼‚**: ç›¸æœºä½ç½®ã€åˆ†è¾¨ç‡ä¸åŒ
- **åŠ¨åŠ›å­¦å·®å¼‚**: ä¸åŒæœºå™¨äººçš„è¿åŠ¨ç‰¹æ€§ä¸åŒ
- **è§£å†³æ–¹æ¡ˆ**: ç»Ÿä¸€åŠ¨ä½œè¡¨ç¤º + å½¢æ€æ— å…³ç‰¹å¾å­¦ä¹  + å¯¹æŠ—è®­ç»ƒ

**Q5: å¦‚ä½•åˆ¤æ–­æ˜¯å¦éœ€è¦å…¨é‡å¾®è°ƒ vs LoRA?**

A:
- **LoRA é€‚ç”¨**: ç›®æ ‡åŸŸä¸æºåŸŸç›¸ä¼¼ï¼Œæ•°æ®é‡å°‘ (< 500 episodes)
- **å…¨é‡å¾®è°ƒé€‚ç”¨**: ç›®æ ‡åŸŸå·®å¼‚å¤§ï¼Œæœ‰è¶³å¤Ÿæ•°æ® (> 1000 episodes)
- **ç»éªŒæ³•åˆ™**: å…ˆå°è¯• LoRAï¼Œæ•ˆæœä¸ä½³å†è€ƒè™‘å…¨é‡å¾®è°ƒ

## 9. å‚è€ƒèµ„æº (References)

- **LoRA**: [Low-Rank Adaptation of Large Language Models](https://arxiv.org/abs/2106.09685)
- **Domain Randomization**: [Domain Randomization for Transferring Deep Neural Networks](https://arxiv.org/abs/1703.06907)
- **DANN**: [Domain-Adversarial Training of Neural Networks](https://arxiv.org/abs/1505.07818)
- **Open X-Embodiment**: [Open X-Embodiment: Robotic Learning Datasets and RT-X Models](https://arxiv.org/abs/2310.08864)

---


\newpage

# ç¬¬14ç« é™„ Co-training


> **å®šä¹‰**: åœ¨è®­ç»ƒ VLA æ¨¡å‹æ—¶ï¼ŒåŒæ—¶æ··åˆ **æœºå™¨äººåŠ¨ä½œæ•°æ® (Robot Action Data)** å’Œ **äº’è”ç½‘è§†è§‰è¯­è¨€æ•°æ® (Internet Vision-Language Data)**ã€‚

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Co-training æ•°æ®æ··åˆç­–ç•¥                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚  â”‚   æœºå™¨äººæ•°æ®      â”‚       â”‚   äº’è”ç½‘æ•°æ®      â”‚               â”‚
â”‚  â”‚   (Robot Data)   â”‚       â”‚   (Web Data)     â”‚               â”‚
â”‚  â”‚                  â”‚       â”‚                  â”‚               â”‚
â”‚  â”‚  ğŸ“· + ğŸ¯ + ğŸ¦¾    â”‚       â”‚  ğŸ“· + ğŸ“         â”‚               â”‚
â”‚  â”‚  å›¾åƒ æŒ‡ä»¤ åŠ¨ä½œ   â”‚       â”‚  å›¾åƒ æ–‡æœ¬        â”‚               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚           â”‚                          â”‚                          â”‚
â”‚           â”‚    æ··åˆæ¯”ä¾‹ 1:1          â”‚                          â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â”‚                      â–¼                                          â”‚
â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                              â”‚
â”‚           â”‚      VLA æ¨¡å‹        â”‚                              â”‚
â”‚           â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”   â”‚                              â”‚
â”‚           â”‚   â”‚Actionâ”‚ Text â”‚   â”‚                              â”‚
â”‚           â”‚   â”‚ Head â”‚ Head â”‚   â”‚                              â”‚
â”‚           â”‚   â””â”€â”€â”¬â”€â”€â”€â”´â”€â”€â”¬â”€â”€â”€â”˜   â”‚                              â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”˜                              â”‚
â”‚                  â”‚      â”‚                                       â”‚
â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â” â”Œâ”€â”´â”€â”€â”€â”€â”€â”€â”                               â”‚
â”‚           â”‚ Action  â”‚ â”‚  Text  â”‚                               â”‚
â”‚           â”‚  Loss   â”‚ â”‚  Loss  â”‚                               â”‚
â”‚           â”‚ (æœºå™¨äºº)â”‚ â”‚ (äº’è”ç½‘)â”‚                               â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜                               â”‚
â”‚                                                                 â”‚
â”‚   æ•ˆæœ: ä¿æŒè¯­ä¹‰èƒ½åŠ› âœ“  å­¦ä¹ åŠ¨ä½œæ§åˆ¶ âœ“  é˜²æ­¢ç¾éš¾æ€§é—å¿˜ âœ“         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## 1. ä¸ºä»€ä¹ˆéœ€è¦ Co-training?

### 1.1. é˜²æ­¢ç¾éš¾æ€§é—å¿˜ (Catastrophic Forgetting)
VLA æ¨¡å‹é€šå¸¸åŸºäºé¢„è®­ç»ƒçš„ VLM (å¦‚ LLaVA, PaLI) å¾®è°ƒã€‚å¦‚æœåªç”¨æœºå™¨äººæ•°æ® (é€šå¸¸åªæœ‰ç®€å•çš„æŒ‡ä»¤å¦‚ "Pick apple") è®­ç»ƒï¼Œæ¨¡å‹ä¼šè¿…é€Ÿå¿˜è®°é€šç”¨çš„è§†è§‰è¯­ä¹‰çŸ¥è¯†ã€‚
- **ç°è±¡**: æ¨¡å‹èƒ½æŠ“è‹¹æœï¼Œä½†è®¤ä¸å‡º"è‹¹æœ"æ˜¯"æ°´æœ"ï¼Œæˆ–è€…è®¤ä¸å‡ºæœªè§è¿‡çš„ç‰©ä½“ã€‚
- **åæœ**: ä¸§å¤±äº† VLM æœ€å®è´µçš„é€šç”¨å¸¸è¯† (Common Sense)ã€‚

### 1.2. ä¿æŒé€šç”¨æ³›åŒ–èƒ½åŠ› (Generalization)
äº’è”ç½‘æ•°æ®åŒ…å«äº†ä¸°å¯Œçš„ç‰©ä½“ã€åœºæ™¯å’Œæ¦‚å¿µï¼ŒCo-training èƒ½è®©æœºå™¨äººåˆ©ç”¨è¿™äº›çŸ¥è¯†å¤„ç†æœªè§è¿‡çš„æŒ‡ä»¤ (Zero-shot)ã€‚
- **ä¸¾ä¾‹**: è®­ç»ƒæ•°æ®é‡Œåªæœ‰ "Pick up the apple"ï¼Œä½†ç”¨æˆ·æŒ‡ä»¤æ˜¯ "Pick up the red fruit"ã€‚å¦‚æœæ¨¡å‹ä¿ç•™äº† VLM çš„çŸ¥è¯†ï¼Œå®ƒå°±èƒ½ç†è§£ "red fruit" æŒ‡çš„æ˜¯ appleã€‚

## 2. å®æ–½ç­–ç•¥ (Implementation)

### 2.1. æ•°æ®é…æ¯” (Mixing Ratio)
é€šå¸¸é‡‡ç”¨ **1:1** æˆ– **1:X** çš„æ¯”ä¾‹æ··åˆã€‚
- **RT-2**: æœºå™¨äººæ•°æ® : äº’è”ç½‘æ•°æ® = **1 : 1** (Batch å†…éƒ¨æ··åˆ)ã€‚
- **OpenVLA**: æœºå™¨äººæ•°æ® (Bridge/DROID) : LLaVA Instruct Data = **50% : 50%**ã€‚

### 2.2. Loss è®¡ç®— (Loss Masking)
ç”±äºä¸¤ç§æ•°æ®çš„æ ‡ç­¾ä¸åŒï¼Œè®¡ç®— Loss æ—¶éœ€è¦è¿›è¡Œ Maskingï¼š

| æ•°æ®ç±»å‹ | è¾“å…¥ (Input) | è¾“å‡º (Output) | Loss è®¡ç®— |
| :--- | :--- | :--- | :--- |
| **æœºå™¨äººæ•°æ®** | Image + Instruction | Action + (Optional) Text | **Action Head Loss** (MSE/CE) + Text Loss |
| **äº’è”ç½‘æ•°æ®** | Image + Text | Text (Caption/VQA) | **Text Token Loss** (Next Token Prediction) |

> **æ³¨æ„**: å¯¹äºäº’è”ç½‘æ•°æ®ï¼ŒAction Head çš„è¾“å‡ºè¢« Mask æ‰ï¼Œä¸äº§ç”Ÿæ¢¯åº¦ï¼Œå› ä¸ºè¿™äº›æ•°æ®æ²¡æœ‰åŠ¨ä½œæ ‡ç­¾ã€‚

### 2.3. ä»£ç é€»è¾‘ (Pseudo-code)

```python
## åœ¨ä¸€ä¸ª Batch ä¸­æ··åˆä¸¤ç§æ•°æ®
batch_robot = get_robot_batch() # {image, text, action}
batch_web = get_web_batch()     # {image, text, action=None}

## 1. Forward Robot Data
out_robot = model(batch_robot.image, batch_robot.text)
## è®¡ç®—åŠ¨ä½œæŸå¤± (e.g., MSE for diffusion, CE for tokenization)
loss_action = mse_loss(out_robot.pred_action, batch_robot.gt_action)

## 2. Forward Web Data
out_web = model(batch_web.image, batch_web.text)
## è®¡ç®—æ–‡æœ¬æŸå¤± (Next Token Prediction)
loss_text = cross_entropy(out_web.logits, batch_web.gt_text)

## 3. Combined Loss
## lambda é€šå¸¸ä¸º 1.0ï¼Œä¹Ÿå¯ä»¥æ ¹æ®ä»»åŠ¡è°ƒæ•´
total_loss = loss_action + lambda * loss_text

total_loss.backward()
```

## 3. æ¡ˆä¾‹åˆ†æ (Case Studies)

### 3.1. RT-2 (Google DeepMind)
- **å‘ç°**: Co-training å¯¹äºä¿æŒæ¨¡å‹çš„é€»è¾‘æ¨ç†èƒ½åŠ›è‡³å…³é‡è¦ã€‚
- **å®éªŒ**: å¦‚æœä¸åŠ  Web Dataï¼Œæ¨¡å‹åœ¨"å°†å¯ä¹ç½æ”¾åˆ°æ³°å‹’æ–¯å¨å¤«ç‰¹ç…§ç‰‡ä¸Š"è¿™ç§éœ€è¦è¯­ä¹‰ç†è§£çš„ä»»åŠ¡ä¸ŠæˆåŠŸç‡ä¼šæš´è·Œã€‚å› ä¸ºæ¨¡å‹å¿˜è®°äº†"æ³°å‹’æ–¯å¨å¤«ç‰¹"æ˜¯è°ã€‚

### 3.2. OpenVLA (Stanford/Berkeley)
- **ç­–ç•¥**: ä½¿ç”¨ LLaVA çš„å¾®è°ƒæ•°æ® (COCO, GQA, ScienceQA) è¿›è¡Œ Co-trainingã€‚
- **æ•ˆæœ**: ç¡®ä¿äº†æ¨¡å‹åœ¨å¾®è°ƒåŠ¨ä½œæ§åˆ¶çš„åŒæ—¶ï¼Œä¾ç„¶æ˜¯ä¸€ä¸ªåˆæ ¼çš„ VLM (èƒ½èŠå¤©ï¼Œèƒ½æè¿°å›¾åƒ)ã€‚è¿™ä½¿å¾— OpenVLA æ—¢èƒ½æ§åˆ¶æœºå™¨äººï¼Œä¹Ÿèƒ½å½“ VLM ç”¨ã€‚

## 4. é¢è¯•é«˜é¢‘é—®é¢˜

**Q: ä¸ºä»€ä¹ˆ Co-training èƒ½æé«˜ Zero-shot èƒ½åŠ›ï¼Ÿ**
A: æœºå™¨äººæ•°æ®é€šå¸¸æ˜¯ Narrow Domain çš„ï¼ˆç‰¹å®šåœºæ™¯ã€ç‰¹å®šç‰©ä½“ï¼‰ã€‚é€šè¿‡æ··åˆ Web Dataï¼Œæ¨¡å‹ä¿æŒäº†å¯¹ Wide Domainï¼ˆé€šç”¨ç‰©ä½“ã€å¤æ‚è¯­ä¹‰ï¼‰çš„ç†è§£ã€‚å½“é‡åˆ°æœªè§è¿‡çš„ç‰©ä½“ï¼ˆå¦‚"æé¾™ç©å…·"ï¼‰æ—¶ï¼Œæ¨¡å‹å¯ä»¥åˆ©ç”¨ VLM çš„çŸ¥è¯†è¯†åˆ«å®ƒï¼Œå¹¶ç»“åˆå­¦åˆ°çš„æŠ“å–åŠ¨ä½œè¿›è¡Œæ“ä½œã€‚

**Q: æ··åˆæ¯”ä¾‹å¯¹æ€§èƒ½æœ‰ä»€ä¹ˆå½±å“ï¼Ÿ**
A: 
- **Web Data è¿‡å°‘**: ç¾éš¾æ€§é—å¿˜ï¼Œé€šç”¨èƒ½åŠ›ä¸‹é™ã€‚
- **Web Data è¿‡å¤š**: æœºå™¨äººåŠ¨ä½œå­¦ä¹ å˜æ…¢ï¼Œå› ä¸º Action Loss çš„æƒé‡è¢«ç¨€é‡Šã€‚
- **ç»éªŒå€¼**: 1:1 æ˜¯ä¸€ä¸ªç¨³å¥çš„èµ·ç‚¹ã€‚

\newpage

# ç¬¬15ç«  é‡åŒ–æŠ€æœ¯


é‡åŒ– (Quantization) æ˜¯å°†é«˜ç²¾åº¦æµ®ç‚¹æ•° (FP32/FP16) æ˜ å°„åˆ°ä½ç²¾åº¦æ•´æ•° (INT8/INT4) çš„è¿‡ç¨‹ã€‚å®ƒæ˜¯ VLA æ¨¡å‹è¾¹ç¼˜éƒ¨ç½²çš„æ ¸å¿ƒæŠ€æœ¯ã€‚

## 0. ä¸»è¦æ•¸å­¸æ€æƒ³ (Main Mathematical Idea)

> **ç¬¬ä¸€æ€§åŸç†**: **Resolution vs. Range (åˆ†è¾¨ç‡ä¸èŒƒå›´çš„æƒè¡¡)**

ä¸–ç•Œæ˜¯è¿ç»­çš„ï¼Œè®¡ç®—æœºæ˜¯ç¦»æ•£çš„ã€‚é‡åŒ–å°±æ˜¯ç”¨æœ‰é™çš„"æ¡¶"ï¼ˆBucketsï¼Œå¦‚ INT8 çš„ 256 ä¸ªæ¡¶ï¼‰å»è£…æ— é™çš„å®æ•°ã€‚

- **æ ¸å¿ƒæ•°å­¦å·¥å…·**: **Affine Mapping (ä»¿å°„æ˜ å°„)** ä¸ **Rounding Error Minimization**ã€‚
- **è§£é¢˜é€»è¾‘**:
    1.  **æ˜ å°„**: å°†è¿ç»­åŒºé—´ $[min, max]$ çº¿æ€§æ˜ å°„åˆ°æ•´æ•°åŒºé—´ $[0, 2^{b}-1]$ã€‚å…¬å¼ï¼š$q = \text{round}(x/S + Z)$ã€‚
    2.  **æƒè¡¡**: Scale ($S$) å†³å®šäº†æ¡¶çš„å¤§å°ï¼ˆåˆ†è¾¨ç‡ï¼‰ã€‚Scale è¶Šå°ï¼Œåˆ†è¾¨ç‡è¶Šé«˜ï¼Œä½†èƒ½è¦†ç›–çš„èŒƒå›´ï¼ˆRangeï¼‰è¶Šå°ã€‚
    3.  **æŒ‘æˆ˜**: å¦‚æœæ•°æ®ä¸­æœ‰ç¦»ç¾¤å€¼ï¼ˆOutliersï¼‰ï¼Œä¸ºäº†åŒ…ä½å®ƒï¼ŒScale å¿…é¡»å¾ˆå¤§ï¼Œå¯¼è‡´å¤§éƒ¨åˆ†æ­£å¸¸æ•°æ®çš„åˆ†è¾¨ç‡æä½ï¼ˆæ‰€æœ‰æ¡¶éƒ½ç©ºäº†ï¼‰ã€‚é‡åŒ–çš„è‰ºæœ¯å°±åœ¨äºå¦‚ä½•å¤„ç†è¿™äº›"æ£ä¹±"çš„ç¦»ç¾¤å€¼ã€‚

## 1. åŸºç¡€åŸç†
â”‚                                                                 â”‚
â”‚   FP32 æƒé‡                    INT8/INT4 æƒé‡                   â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚
â”‚   â”‚ 0.0234  â”‚                  â”‚   3     â”‚                      â”‚
â”‚   â”‚ 0.1567  â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶    â”‚   20    â”‚                      â”‚
â”‚   â”‚-0.0891  â”‚    é‡åŒ– (Q)      â”‚  -11    â”‚                      â”‚
â”‚   â”‚ 0.2103  â”‚                  â”‚   27    â”‚                      â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
â”‚       â–²                             â”‚                           â”‚
â”‚       â”‚                             â”‚                           â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚
â”‚              åé‡åŒ– (DeQ)                                        â”‚
â”‚                                                                 â”‚
â”‚   å­˜å‚¨: 32-bit â”€â”€â”€â”€â”€â”€â”€â”€â–¶ 4-bit (8x å‹ç¼©)                        â”‚
â”‚   ç²¾åº¦: é«˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ ä½ (æœ‰æŸå¤±)                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## 1. åŸºç¡€åŸç†

### 1.1. æ˜ å°„å…¬å¼
å°†æµ®ç‚¹æ•° $x$ æ˜ å°„åˆ°æ•´æ•° $q$ï¼š


$$
q = \text{round}\left( \frac{x}{S} + Z \right)
$$


åé‡åŒ– (Dequantization)ï¼š


$$
\hat{x} = S(q - Z)
$$

å…¶ä¸­ï¼š
- $S$ (Scale): ç¼©æ”¾å› å­ï¼Œå†³å®šäº†é‡åŒ–çš„ç²’åº¦ã€‚
- $Z$ (Zero-point): é›¶ç‚¹åç§»ï¼Œç”¨äºå¯¹é½é›¶ç‚¹ã€‚

### 1.2. å¯¹ç§° vs éå¯¹ç§° (Symmetric vs Asymmetric)

```
å¯¹ç§°é‡åŒ– (Symmetric)              éå¯¹ç§°é‡åŒ– (Asymmetric)
        Z = 0                           Z â‰  0

    -127 â—€â”€â”€â”€â”€â”€â”€â–¶ +127              0 â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ 255
      â”‚     0     â”‚                 â”‚      Z       â”‚
      â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¤                 â”œâ”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
      â”‚     â”‚     â”‚                 â”‚      â”‚       â”‚
   â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€           â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€
     min   0    max               min    0       max
      â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚                              â”‚
       æ•°æ®åˆ†å¸ƒå¯¹ç§°                    æ•°æ®åˆ†å¸ƒåç§»
     (é€‚åˆæƒé‡ weights)           (é€‚åˆæ¿€æ´»å€¼ activations)
```

#### å¯¹ç§°é‡åŒ– (Symmetric)
- **ç‰¹ç‚¹**: $Z=0$ã€‚æ˜ å°„èŒƒå›´æ˜¯å¯¹ç§°çš„ (e.g., INT8: $[-127, 127]$)ã€‚
- **å…¬å¼**: $q = \text{round}(x / S)$ã€‚
- **ä¼˜ç‚¹**: è®¡ç®—å¿« (ä¸éœ€è¦åŠ å‡ Zero-point)ã€‚
- **ç¼ºç‚¹**: å¦‚æœæ•°æ®åˆ†å¸ƒä¸¥é‡ä¸å¯¹ç§° (e.g., ReLU åçš„æ¿€æ´»å€¼å…¨æ˜¯æ­£çš„)ï¼Œä¼šæµªè´¹ä¸€åŠçš„é‡åŒ–èŒƒå›´ã€‚

#### éå¯¹ç§°é‡åŒ– (Asymmetric)
- **ç‰¹ç‚¹**: $Z \neq 0$ã€‚æ˜ å°„èŒƒå›´å¯ä»¥é€‚é…æ•°æ®åˆ†å¸ƒ (e.g., $[min, max]$ æ˜ å°„åˆ° $[0, 255]$)ã€‚
- **ä¼˜ç‚¹**: ç²¾åº¦æ›´é«˜ï¼Œå……åˆ†åˆ©ç”¨ bit ä½ã€‚
- **ç¼ºç‚¹**: è®¡ç®—ç¨æ…¢ã€‚

---

## 2. ç²’åº¦ (Granularity)

é‡åŒ–å‚æ•° $S$ å’Œ $Z$ æ˜¯æ€ä¹ˆç®—çš„ï¼Ÿå–å†³äºç²’åº¦ã€‚

### 2.1. Per-Tensor (Layer-wise)
- æ•´ä¸ª Tensor å…±äº«ä¸€ç»„ $(S, Z)$ã€‚
- **ä¼˜ç‚¹**: ç¡¬ä»¶å®ç°ç®€å•ã€‚
- **ç¼ºç‚¹**: ç²¾åº¦æœ€å·®ã€‚å¦‚æœ Tensor é‡Œæœ‰ä¸€ä¸ªæå¤§çš„ç¦»ç¾¤å€¼ (Outlier)ï¼Œæ•´ä¸ª Tensor çš„ Scale éƒ½ä¼šè¢«æ‹‰å¤§ï¼Œå¯¼è‡´å°æ•°å€¼å…¨éƒ¨å˜æˆ 0ã€‚

### 2.2. Per-Channel (Channel-wise)
- æ¯ä¸€è¡Œ (æˆ–æ¯ä¸€åˆ—) æœ‰ä¸€ç»„ $(S, Z)$ã€‚
- **ä¼˜ç‚¹**: ç²¾åº¦æ˜¾è‘—æå‡ï¼Œæ˜¯ CNN/LLM æƒé‡é‡åŒ–çš„æ ‡å‡†åšæ³•ã€‚
- **ç¼ºç‚¹**: å­˜å‚¨ Scale éœ€è¦é¢å¤–ç©ºé—´ (ä½†åœ¨å¤§æ¨¡å‹ä¸­å¯å¿½ç•¥)ã€‚

### 2.3. Per-Token / Per-Group
- **Per-Token**: é’ˆå¯¹æ¿€æ´»å€¼ (Activation)ï¼Œæ¯ä¸ª Token åŠ¨æ€è®¡ç®— Scaleã€‚
- **Per-Group**: å°†æƒé‡æ¯ 128 ä¸ªæ•°åˆ†ä¸ºä¸€ç»„ (Group)ï¼Œæ¯ç»„ä¸€ä¸ª Scaleã€‚è¿™æ˜¯ **4-bit é‡åŒ– (å¦‚ AWQ, GPTQ)** çš„æ ‡é…ï¼Œå› ä¸º 4-bit ç²¾åº¦å¤ªä½ï¼Œå¿…é¡»ç”¨ç»†ç²’åº¦ Scale æ¥è¡¥ã€‚

---

## 3. è¿›é˜¶éš¾é¢˜ï¼šç¦»ç¾¤å€¼ (Outliers)

LLM / VLA æ¨¡å‹æœ‰ä¸€ä¸ªç‰¹æ€§ï¼š**æ¿€æ´»å€¼ä¸­å­˜åœ¨æç«¯çš„ç¦»ç¾¤å€¼** (Outliers)ã€‚è¿™äº›å€¼è™½ç„¶å¾ˆå°‘ï¼Œä½†å¯¹æ¨¡å‹æ€§èƒ½è‡³å…³é‡è¦ã€‚

### 3.1. ä¸ºä»€ä¹ˆç›´æ¥é‡åŒ–ä¼šå¤±è´¥ï¼Ÿ
å¦‚æœç›´æ¥åš INT8 é‡åŒ–ï¼Œä¸ºäº†åŒ…ä½é‚£ä¸ªå·¨å¤§çš„ Outlierï¼ŒScale ä¼šå˜å¾—å¾ˆå¤§ï¼Œå¯¼è‡´å…¶ä»– 99.9% çš„æ­£å¸¸æ•°å€¼éƒ½è¢«å‹ç¼©åˆ°äº† 0ï¼Œæ¨¡å‹ç›´æ¥å‚»æ‰ã€‚

### 3.2. è§£å†³æ–¹æ¡ˆï¼šSmoothQuant / AWQ
- **SmoothQuant**: æ•°å­¦ç­‰ä»·å˜æ¢ã€‚
  $$ Y = X W = (X \cdot s^{-1}) \cdot (s \cdot W) $$
  æŠŠæ¿€æ´»å€¼ $X$ é‡Œçš„ Outlier "å¹³æ‘Š" (Smooth) åˆ°æƒé‡ $W$ ä¸Šã€‚è®© $X$ å˜å°ï¼Œè®© $W$ å˜å¤§ã€‚å› ä¸ºæƒé‡é€šå¸¸æ¯”è¾ƒå‡åŒ€ï¼Œæ›´å®¹æ˜“é‡åŒ–ã€‚
- **AWQ (Activation-aware Weight Quantization)**:
  ä¸é‡åŒ–é‚£äº›å¯¹åº”é‡è¦æ¿€æ´»å€¼ (Salient Weights) çš„æƒé‡ï¼Œæˆ–è€…ä¿ç•™æ›´é«˜çš„ç²¾åº¦ã€‚

---

## 4. é¢è¯•é«˜é¢‘è€ƒç‚¹

**Q: ä¸ºä»€ä¹ˆ 4-bit é‡åŒ–é€šå¸¸æ¯” 8-bit é‡åŒ–æ›´éš¾ï¼Ÿ**
A: 4-bit åªæœ‰ 16 ä¸ªæ ¼å­ã€‚å¦‚æœ Scale ç¨å¾®æ²¡é€‰å¥½ï¼Œè¯¯å·®å°±ä¼šå·¨å¤§ã€‚æ‰€ä»¥ 4-bit é€šå¸¸éœ€è¦ **Per-Group** é‡åŒ– (Group Size=128) å’Œæ›´å¤æ‚çš„æ ¡å‡†ç®—æ³• (å¦‚ GPTQ)ã€‚

**Q: Post-Training Quantization (PTQ) vs Quantization-Aware Training (QAT)**
- **PTQ**: æ‹¿è®­ç»ƒå¥½çš„æ¨¡å‹ç›´æ¥é‡åŒ– (åŠ å°‘é‡æ ¡å‡†æ•°æ®)ã€‚ç®€å•ï¼Œä¸»æµã€‚
- **QAT**: è®­ç»ƒæ—¶å°±æ¨¡æ‹Ÿé‡åŒ–è¯¯å·® (Fake Quantization)ã€‚ç²¾åº¦æœ€é«˜ï¼Œä½†è®­ç»ƒæˆæœ¬é«˜ï¼ŒVLA é¢†åŸŸè¾ƒå°‘ç”¨ã€‚

**Q: æƒé‡é‡åŒ– (Weight-only) vs æ¿€æ´»é‡åŒ– (Activation Quantization)**
- **W4A16**: æƒé‡ 4-bitï¼Œæ¿€æ´» FP16ã€‚çœæ˜¾å­˜ï¼Œæ¨ç†é€Ÿåº¦å—é™äºåé‡åŒ–å¸¦å®½ã€‚
- **W8A8**: æƒé‡ 8-bitï¼Œæ¿€æ´» 8-bitã€‚å¯ä»¥ä½¿ç”¨ INT8 Tensor Core åŠ é€Ÿè®¡ç®—ï¼ŒçœŸæ­£çš„æ¨ç†åŠ é€Ÿã€‚

\newpage

# ç¬¬å››éƒ¨åˆ†ï¼šæ„ŸçŸ¥ä¸ç©ºé—´æ™ºèƒ½


\newpage

# ç¬¬16ç«  ç©ºé—´æ•°å­¦åŸºç¡€


å¯¹äº AI èƒŒæ™¯çš„åŒå­¦æ¥è¯´ï¼Œæœºå™¨äººå­¦æœ€ä»¤äººå¤´å¤§çš„å¾€å¾€ä¸æ˜¯æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œè€Œæ˜¯**åæ ‡å˜æ¢ (Coordinate Transformations)**ã€‚ç†è§£ç©ºé—´å…³ç³»æ˜¯è®­ç»ƒ VLA æ¨¡å‹çš„åŸºç¡€ã€‚

## 0. ä¸»è¦æ•¸å­¸æ€æƒ³ (Main Mathematical Idea)

> **ç¬¬ä¸€æ€§åŸç†**: **Rigid Body Invariance (åˆšä½“ä¸å˜æ€§ / Lie Group SE(3))**

ç‰©ç†ä¸–ç•Œä¸­çš„ç‰©ä½“æ˜¯"åˆšæ€§"çš„ï¼Œç§»åŠ¨æˆ–æ—‹è½¬å®ƒä»¬ä¸ä¼šæ”¹å˜å®ƒä»¬çš„å½¢çŠ¶æˆ–å†…éƒ¨è·ç¦»ã€‚è¿™æ„å‘³ç€æˆ‘ä»¬ä¸èƒ½ç”¨æ™®é€šçš„åŠ æ³•æ¥å¤„ç†æ—‹è½¬ï¼ˆ$R_1 + R_2$ æ²¡æœ‰ç‰©ç†æ„ä¹‰ï¼‰ï¼Œè€Œå¿…é¡»éµå¾ª**ç¾¤è®º (Group Theory)** çš„è§„åˆ™ã€‚

- **æ ¸å¿ƒæ•°å­¦å·¥å…·**: **Lie Groups (æç¾¤ SE(3))** ä¸ **Lie Algebras (æä»£æ•° se(3))**ã€‚
- **è§£é¢˜é€»è¾‘**:
    1.  **éæ¬§å‡ ä½•**: æ—‹è½¬ç©ºé—´æ˜¯å¼¯æ›²çš„ï¼ˆæµå½¢ï¼‰ã€‚ä¸ºäº†åœ¨ç¥ç»ç½‘ç»œä¸­å¤„ç†å®ƒï¼Œæˆ‘ä»¬éœ€è¦æ‰¾åˆ°åˆé€‚çš„è¡¨ç¤ºï¼ˆå¦‚å››å…ƒæ•°ã€6Dè¡¨ç¤ºï¼‰ï¼Œä»¥é¿å…å¥‡å¼‚æ€§ï¼ˆä¸‡å‘èŠ‚æ­»é”ï¼‰å’Œä¸è¿ç»­æ€§ã€‚
    2.  **ç›¸å¯¹æ€§**: æ‰€æœ‰çš„ä½å§¿éƒ½æ˜¯ç›¸å¯¹çš„ ($T_A^B$)ã€‚æ•°å­¦æ ¸å¿ƒæ˜¯**é“¾å¼æ³•åˆ™** ($T_A^C = T_A^B \times T_B^C$)ï¼Œè¿™å¯¹åº”äºåœ¨ä¸åŒåæ ‡ç³»ä¹‹é—´æ— æŸåœ°ä¼ é€’ä¿¡æ¯ã€‚

## 1. æ ¸å¿ƒåæ ‡ç³» (Core Frames)

åœ¨æœºå™¨äººæ“ä½œä¸­ï¼Œæˆ‘ä»¬å¿…é¡»æ—¶åˆ»æ¸…æ¥šæ•°æ®æ˜¯åœ¨å“ªä¸ªåæ ‡ç³»ä¸‹å®šä¹‰çš„ã€‚

### 1.1. World Frame (ä¸–ç•Œåæ ‡ç³») $\{W\}$
- **å®šä¹‰**: å…¨å±€å›ºå®šçš„å‚è€ƒç³»ï¼Œé€šå¸¸æ˜¯æœºå™¨äººåº•åº§å›ºå®šçš„æ¡Œå­è§’ï¼Œæˆ–è€…æˆ¿é—´çš„æŸä¸ªè§’è½ã€‚
- **ä½œç”¨**: å¤šæœºå™¨äººåä½œæ—¶çš„ç»Ÿä¸€åŸºå‡†ã€‚

### 1.2. Base Frame (åŸºåº§åæ ‡ç³») $\{B\}$
- **å®šä¹‰**: æœºå™¨äººåº•åº§ (Base Link) çš„ä¸­å¿ƒã€‚
- **ä½œç”¨**: **ç»å¤§å¤šæ•°å•è‡‚æœºå™¨äººçš„ Action éƒ½æ˜¯ç›¸å¯¹äº Base Frame å®šä¹‰çš„**ã€‚
- **æ³¨æ„**: å¦‚æœæœºå™¨äººæ˜¯ç§»åŠ¨çš„ (Mobile Manipulator)ï¼ŒBase Frame æœ¬èº«æ˜¯åœ¨ World Frame ä¸­ç§»åŠ¨çš„ã€‚

### 1.3. End-effector Frame (æœ«ç«¯åæ ‡ç³» / TCP) $\{E\}$
- **å®šä¹‰**: æœºæ¢°è‡‚æœ«ç«¯æ‰§è¡Œå™¨ (Gripper) çš„ä¸­å¿ƒç‚¹ (Tool Center Point, TCP)ã€‚é€šå¸¸ $Z$ è½´æŒ‡å‘å¤¹çˆªå»¶ä¼¸æ–¹å‘ï¼Œ$X$ è½´æŒ‡å‘å¤¹çˆªé—­åˆæ–¹å‘ã€‚
- **ä½œç”¨**: æè¿°â€œæ‰‹â€çš„ä½ç½®å’Œæœå‘ã€‚
- **Delta Action**: å¾ˆå¤šæ—¶å€™æ¨¡å‹é¢„æµ‹çš„æ˜¯ TCP ç›¸å¯¹äº**å½“å‰æ—¶åˆ» TCP** çš„ç§»åŠ¨é‡ (å³åœ¨è‡ªå·±çš„åæ ‡ç³»ä¸‹å¾€å‰èµ° 1cm)ã€‚

### 1.4. Camera Frame (ç›¸æœºåæ ‡ç³») $\{C\}$
- **å®šä¹‰**: ä»¥ç›¸æœºå…‰å¿ƒä¸ºåŸç‚¹ï¼Œ$Z$ è½´é€šå¸¸æŒ‡å‘å‰æ–¹ï¼Œ$X$ è½´å‘å³ï¼Œ$Y$ è½´å‘ä¸‹ (OpenCV æ ‡å‡†)ã€‚
- **ä½œç”¨**: è§†è§‰è¾“å…¥ (RGB/Depth) æœ€åˆéƒ½æ˜¯åœ¨ Camera Frame ä¸‹çš„ã€‚

---

## 2. é½æ¬¡å˜æ¢çŸ©é˜µ (Homogeneous Transformation Matrix)

ä¸ºäº†ç»Ÿä¸€æè¿°æ—‹è½¬ (Rotation) å’Œå¹³ç§» (Translation)ï¼Œæˆ‘ä»¬ä½¿ç”¨ $4 \times 4$ çš„é½æ¬¡å˜æ¢çŸ©é˜µ $T$ã€‚


$$
T_{A}^{B} = \begin{bmatrix} R_{3\times3} & t_{3\times1} \\ 0_{1\times3} & 1 \end{bmatrix} \in SE(3)
$$


- **ç‰©ç†å«ä¹‰**: æè¿°äº†åæ ‡ç³» $\{A\}$ ç›¸å¯¹äºåæ ‡ç³» $\{B\}$ çš„ä½å§¿ã€‚
- **ç‚¹çš„å˜æ¢**: å¦‚æœç‚¹ $P$ åœ¨ $\{A\}$ ä¸­çš„åæ ‡æ˜¯ $P_A = [x, y, z, 1]^T$ï¼Œé‚£ä¹ˆå®ƒåœ¨ $\{B\}$ ä¸­çš„åæ ‡æ˜¯ï¼š
  $$ P_B = T_{A}^{B} \times P_A $$

### 2.1. é€†å˜æ¢ (Inverse)
æ±‚é€†çŸ©é˜µå¯¹åº”äºåå‘å˜æ¢ $T_{B}^{A} = (T_{A}^{B})^{-1}$ï¼š

$$
(T_{A}^{B})^{-1} = \begin{bmatrix} R^T & -R^T t \\ 0 & 1 \end{bmatrix}
$$

> **æ³¨æ„**: æ—‹è½¬çŸ©é˜µæ˜¯æ­£äº¤çŸ©é˜µï¼Œæ‰€ä»¥ $R^{-1} = R^T$ï¼Œè®¡ç®—éå¸¸å¿«ã€‚

### 2.2. é“¾å¼æ³•åˆ™ (Chain Rule)
è¿™æ˜¯æœºå™¨äººå­¦ä¸­æœ€å¼ºå¤§çš„å·¥å…·ã€‚ä¾‹å¦‚ï¼Œå·²çŸ¥ç›¸æœºç›¸å¯¹äºä¸–ç•Œçš„å¤–å‚ $T_{C}^{W}$ï¼Œä»¥åŠç‰©ä½“ç›¸å¯¹äºç›¸æœºçš„ä½å§¿ $T_{O}^{C}$ï¼Œæ±‚ç‰©ä½“åœ¨ä¸–ç•Œç³»ä¸‹çš„ä½å§¿ï¼š

$$
T_{O}^{W} = T_{C}^{W} \times T_{O}^{C}
$$


---

## 3. æ—‹è½¬è¡¨ç¤ºæ·±åº¦è§£æ (Rotation Representations Deep Dive)

ä½ç½® $t \in \mathbb{R}^3$ å¾ˆå¥½è¡¨ç¤ºï¼Œä½†æ—‹è½¬ $R \in SO(3)$ æ˜¯éçº¿æ€§çš„æµå½¢ç»“æ„ï¼Œç¥ç»ç½‘ç»œå¾ˆéš¾ç›´æ¥é¢„æµ‹ã€‚

### 3.1. æ¬§æ‹‰è§’ (Euler Angles)
- **è¡¨ç¤º**: $(roll, pitch, yaw)$ æˆ– $(\alpha, \beta, \gamma)$ã€‚
- **è‡´å‘½ç¼ºé™·**: **ä¸‡å‘èŠ‚æ­»é” (Gimbal Lock)**ã€‚å½“ä¸­é—´è½´æ—‹è½¬ 90 åº¦æ—¶ï¼Œç¬¬ä¸€è½´å’Œç¬¬ä¸‰è½´é‡åˆï¼Œä¸¢å¤±ä¸€ä¸ªè‡ªç”±åº¦ã€‚
- **ä¸è¿ç»­æ€§**: $\pi$ å’Œ $-\pi$ æ˜¯åŒä¸€ä¸ªè§’åº¦ï¼Œä½†æ•°å€¼ç›¸å·®å·¨å¤§ã€‚è¿™ä¼šå¯¼è‡´ Loss çˆ†ç‚¸ã€‚
- **ç»“è®º**: âŒ **VLA æ¨¡å‹ä¸¥ç¦ç›´æ¥é¢„æµ‹æ¬§æ‹‰è§’**ã€‚

### 3.2. å››å…ƒæ•° (Quaternion)
- **è¡¨ç¤º**: $q = w + xi + yj + zk$ï¼Œé€šå¸¸å†™ä¸ºå‘é‡ $[w, x, y, z]$ã€‚
- **æ€§è´¨**: å¿…é¡»æ»¡è¶³å•ä½æ¨¡çº¦æŸ $\|q\|_2 = 1$ã€‚
- **åŒå€è¦†ç›– (Double Cover)**: $q$ å’Œ $-q$ è¡¨ç¤ºå®Œå…¨ç›¸åŒçš„æ—‹è½¬ã€‚
    - **è®­ç»ƒå‘ç‚¹**: å¦‚æœçœŸå€¼æ˜¯ $q$ï¼Œæ¨¡å‹é¢„æµ‹çš„æ˜¯ $-q$ (å®é™…ä¸Šæ˜¯å¯¹çš„)ï¼Œä½† MSE Loss ä¼šå¾ˆå¤§ã€‚
    - **è§£å†³æ–¹æ¡ˆ**: åœ¨è®¡ç®— Loss å‰ï¼Œå¦‚æœ $\langle q_{pred}, q_{gt} \rangle < 0$ï¼Œåˆ™å°† $q_{gt}$ ç¿»è½¬ä¸º $-q_{gt}$ã€‚
- **ç»“è®º**: âœ… **ä¸»æµé€‰æ‹©** (å¦‚ RT-1)ï¼Œä½†éœ€è¦å¤„ç†å½’ä¸€åŒ–å’ŒåŒå€è¦†ç›–ã€‚

### 3.3. 6D æ—‹è½¬è¡¨ç¤º (6D Rotation Representation) [SOTA]
- **æ¥æº**: *On the Continuity of Rotation Representations in Neural Networks* (Zhou et al., CVPR 2019).
- **æ ¸å¿ƒæ€æƒ³**: ç¥ç»ç½‘ç»œé¢„æµ‹ $3 \times 3$ æ—‹è½¬çŸ©é˜µçš„å‰ä¸¤åˆ— $r_1, r_2$ (å…± 6 ä¸ªæ•°)ã€‚
    - $r_1$ æ˜¯ $X$ è½´æ–¹å‘ (æœªå½’ä¸€åŒ–)ã€‚
    - $r_2$ æ˜¯ $Y$ è½´æ–¹å‘ (æœªå½’ä¸€åŒ–ï¼Œä¸”ä¸ä¸€å®šå‚ç›´äº $X$)ã€‚
- **è¿˜åŸæ­¥éª¤ (Gram-Schmidt æ­£äº¤åŒ–)**:
    1. å½’ä¸€åŒ– $x = \frac{r_1}{\|r_1\|}$
    2. è®¡ç®— $z = x \times r_2$ (å‰ä¹˜å¾—åˆ°å‚ç›´äº $x, r_2$ å¹³é¢çš„è½´)
    3. å½’ä¸€åŒ– $z = \frac{z}{\|z\|}$
    4. è®¡ç®— $y = z \times x$ (å¾—åˆ°å®Œç¾çš„æ­£äº¤ç³»)
    5. ç»„è£… $R = [x, y, z]$
- **ä¼˜ç‚¹**: **è¿ç»­æ€§ (Continuity)**ã€‚è¿™æ˜¯å”¯ä¸€ä¸€ç§åœ¨æ¬§å‡ é‡Œå¾—ç©ºé—´ä¸­è¿ç»­çš„æ—‹è½¬è¡¨ç¤ºï¼Œæœ€é€‚åˆç¥ç»ç½‘ç»œå›å½’ã€‚
- **ç»“è®º**: âœ…âœ… **Diffusion Policy / Pi0 çš„é¦–é€‰**ã€‚

#### PyTorch å®ç°
```python
import torch
import torch.nn.functional as F

def compute_rotation_matrix_from_ortho6d(ortho6d):
    x_raw = ortho6d[:, 0:3]
    y_raw = ortho6d[:, 3:6]
    
    x = F.normalize(x_raw, dim=-1)
    z = torch.cross(x, y_raw, dim=-1)
    z = F.normalize(z, dim=-1)
    y = torch.cross(z, x, dim=-1)
    
    matrix = torch.stack([x, y, z], dim=-1) # (B, 3, 3)
    return matrix
```

---

## 4. ç›¸æœºæŠ•å½±å‡ ä½• (Camera Projection)

VLA æ¨¡å‹å¦‚ä½•ç†è§£ 3D ä¸–ç•Œï¼Ÿé€šè¿‡ç›¸æœºå†…å‚ã€‚

### 4.1. é’ˆå­”ç›¸æœºæ¨¡å‹ (Pinhole Model)
å°† 3D ç‚¹ $P_C = [X, Y, Z]^T$ æŠ•å½±åˆ° 2D åƒç´ å¹³é¢ $p = [u, v]^T$ï¼š

