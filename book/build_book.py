#!/usr/bin/env python3
"""
VLA Handbook - Book Builder
å°† theory/ ç›®å½•ä¸‹çš„ Markdown æ–‡ä»¶åˆå¹¶æˆä¸€æœ¬å®Œæ•´çš„ç”µå­ä¹¦

ä½¿ç”¨æ–¹æ³•:
    python build_book.py              # ç”Ÿæˆåˆå¹¶çš„ Markdown
    python build_book.py --pdf        # ç”Ÿæˆ PDF (éœ€è¦ pandoc + latex)
    python build_book.py --html       # ç”Ÿæˆ HTML
"""

import os
import re
import subprocess
import argparse
from pathlib import Path
from datetime import datetime

# ç« èŠ‚é¡ºåºå®šä¹‰
CHAPTERS = [
    # ç¬¬ä¸€éƒ¨åˆ†ï¼šåŸºç¡€æ¶æ„
    ("ç¬¬1ç«  Transformer vs CNN", "transformer_vs_cnn.md"),
    ("ç¬¬2ç«  Flash Attention ä¸æ¨ç†ä¼˜åŒ–", "flash_attention.md"),
    ("ç¬¬3ç«  å¤šæ¨¡æ€æ¨¡å‹åŸºç¡€", "multimodal_models.md"),
    ("ç¬¬4ç«  VLA æ¶æ„æ€»è§ˆ", "vla_arch.md"),
    
    # ç¬¬äºŒéƒ¨åˆ†ï¼šç­–ç•¥ç”Ÿæˆä¸åŠ¨ä½œè¡¨ç¤º
    ("ç¬¬5ç«  åŠ¨ä½œè¡¨ç¤ºæ–¹æ³•", "action_representations.md"),
    ("ç¬¬6ç«  Diffusion Policy", "diffusion_policy.md"),
    ("ç¬¬7ç«  Action Chunking Transformer (ACT)", "act.md"),
    ("ç¬¬8ç«  Flow Matching", "pi0_flow_matching.md"),
    ("ç¬¬9ç«  FAST åŠ¨ä½œåºåˆ—ç¼–ç ", "fast.md"),
    
    # ç¬¬ä¸‰éƒ¨åˆ†ï¼šè®­ç»ƒæŠ€æœ¯ä¸ä¼˜åŒ–
    ("ç¬¬10ç«  å‚æ•°é«˜æ•ˆå¾®è°ƒ (PEFT/LoRA)", "peft_lora.md"),
    ("ç¬¬11ç«  å¼ºåŒ–å­¦ä¹ åŸºç¡€ä¸ RLHF", "reinforcement_learning.md"),
    ("ç¬¬12ç«  çŸ¥è¯†è’¸é¦", "knowledge_distillation.md"),
    ("ç¬¬13ç«  è‡ªç›‘ç£å­¦ä¹ ", "self_supervised_learning.md"),
    ("ç¬¬14ç«  è¿ç§»å­¦ä¹ ä¸ Co-training", "transfer_learning.md"),
    ("ç¬¬14ç« é™„ Co-training", "co_training.md"),
    ("ç¬¬15ç«  é‡åŒ–æŠ€æœ¯", "quantization_theory.md"),
    
    # ç¬¬å››éƒ¨åˆ†ï¼šæ„ŸçŸ¥ä¸ç©ºé—´æ™ºèƒ½
    ("ç¬¬16ç«  ç©ºé—´æ•°å­¦åŸºç¡€", "spatial_math.md"),
    ("ç¬¬17ç«  æœºå™¨äººæ§åˆ¶æ–¹æ³•", "robot_control.md"),
    ("ç¬¬18ç«  æ„ŸçŸ¥æŠ€æœ¯", "perception_techniques.md"),
    ("ç¬¬19ç«  ç‚¹äº‘ä¸ SLAM", "pointcloud_slam.md"),
    ("ç¬¬20ç«  çŠ¶æ€ä¼°è®¡", "state_estimation.md"),
    ("ç¬¬21ç«  å…·èº«å¯¼èˆª (VLN) / DualVLN å¿«æ…¢ç³»ç»Ÿ", "vln_dualvln.md"),
    
    # ç¬¬äº”éƒ¨åˆ†ï¼šæŠ“å–ä¸è¿åŠ¨è§„åˆ’
    ("ç¬¬22ç«  æŠ“å–ç®—æ³•", "grasp_algorithms.md"),
    ("ç¬¬23ç«  è¿åŠ¨è§„åˆ’", "motion_planning.md"),
    ("ç¬¬24ç«  è§¦è§‰ VLA", "tactile_vla.md"),
    
    # ç¬¬å…­éƒ¨åˆ†ï¼šå‰æ²¿æ¨¡å‹è§£æ
    ("ç¬¬25ç«  RDT (Robotics Diffusion Transformer)", "rdt.md"),
    ("ç¬¬26ç«  Ï€0.5 è§£æ", "pi0_5_dissection.md"),
    ("ç¬¬27ç«  Ï€0.6 è§£æ", "pi0_6_dissection.md"),
    ("ç¬¬28ç«  Galaxea G0", "galaxea_g0.md"),
    ("ç¬¬29ç«  WALL-OSS", "wall_oss.md"),
    
    # ç¬¬ä¸ƒéƒ¨åˆ†ï¼šè¯„ä¼°ä¸æ¨ç†
    ("ç¬¬30ç«  Chain-of-Thought æ¨ç†", "chain_of_thought.md"),
    ("ç¬¬31ç«  è¯„ä¼°æ–¹æ³•è®º", "evaluation.md"),
    ("ç¬¬32ç«  çŸ¥è¯†éš”ç¦»", "knowledge_insulation.md"),
    
    # é™„å½•
    ("é™„å½•A æ•°æ®æ ¼å¼ä¸å¤„ç†", "data.md"),
    ("é™„å½•B æ–‡çŒ®ç»¼è¿°", "literature_review.md"),
    ("é™„å½•C ASCII å›¾è¡¨é€ŸæŸ¥", "ascii_cheatsheet.md"),
]

BOOK_HEADER = """---
title: "VLA Handbookï¼šä»ç†è®ºåˆ°å®è·µ"
subtitle: "Vision-Language-Action å®Œå…¨æŒ‡å—"
author: "VLA Handbook Contributors"
date: "{date}"
documentclass: report
geometry: margin=2.5cm
fontsize: 11pt
toc: true
toc-depth: 3
numbersections: true
colorlinks: true
linkcolor: blue
urlcolor: blue
header-includes:
  - \\usepackage{{ctex}}
  - \\usepackage{{fancyhdr}}
  - \\pagestyle{{fancy}}
  - \\fancyhead[L]{{VLA Handbook}}
  - \\fancyhead[R]{{\\thepage}}
  - \\fancyfoot[C]{{}}
---

\\newpage

# å‰è¨€

æœ¬ä¹¦æ˜¯ **VLA Handbook** é¡¹ç›®çš„å®Œæ•´ç†è®ºéƒ¨åˆ†ï¼Œç³»ç»Ÿæ€§åœ°ä»‹ç»äº†è§†è§‰-è¯­è¨€-åŠ¨ä½œ (Vision-Language-Action) æ¨¡å‹çš„æ ¸å¿ƒæ¦‚å¿µã€å…³é”®æŠ€æœ¯ä¸å·¥ç¨‹å®è·µã€‚

**é€‚ç”¨è¯»è€…**ï¼š
- å‡†å¤‡æœºå™¨äºº/å…·èº«æ™ºèƒ½æ–¹å‘é¢è¯•çš„å·¥ç¨‹å¸ˆ
- å¸Œæœ›ç³»ç»Ÿå­¦ä¹  VLA æŠ€æœ¯æ ˆçš„ç ”ç©¶è€…
- å¯¹å¤šæ¨¡æ€æœºå™¨äººæ„Ÿå…´è¶£çš„å­¦ç”Ÿ

**å¦‚ä½•ä½¿ç”¨æœ¬ä¹¦**ï¼š
1. **ç³»ç»Ÿå­¦ä¹ **ï¼šæŒ‰ç« èŠ‚é¡ºåºé˜…è¯»ï¼Œå»ºç«‹å®Œæ•´çŸ¥è¯†ä½“ç³»
2. **é¢è¯•å‡†å¤‡**ï¼šé‡ç‚¹å…³æ³¨æ¯ç« æœ«å°¾çš„ Q&A éƒ¨åˆ†
3. **æŸ¥é˜…å‚è€ƒ**ï¼šä½¿ç”¨ç›®å½•å¿«é€Ÿå®šä½ç‰¹å®šä¸»é¢˜

**åœ¨çº¿ç‰ˆæœ¬**ï¼šhttps://github.com/sou350121/VLA-Handbook

\\newpage

"""


def clean_markdown(content: str, chapter_title: str) -> str:
    """æ¸…ç†å’Œè°ƒæ•´ Markdown å†…å®¹"""
    lines = content.split('\n')
    cleaned_lines = []
    skip_header = True
    
    for line in lines:
        # è·³è¿‡åŸæ–‡ä»¶çš„ç¬¬ä¸€ä¸ªæ ‡é¢˜ï¼ˆä¼šç”¨ç« èŠ‚æ ‡é¢˜æ›¿æ¢ï¼‰
        if skip_header and line.startswith('# '):
            skip_header = False
            continue
        
        # ç§»é™¤è¿”å›é“¾æ¥
        if '[â† Back to' in line or '[â† è¿”å›' in line:
            continue
            
        # è°ƒæ•´æ ‡é¢˜çº§åˆ«ï¼ˆ## -> ###ï¼Œ### -> ####ï¼‰
        if line.startswith('## '):
            line = '##' + line[2:]  # ä¿æŒ ## ä¸å˜ï¼Œä½œä¸ºç« èŠ‚å†…çš„ä¸»è¦æ ‡é¢˜
        elif line.startswith('# '):
            line = '##' + line[1:]  # # å˜æˆ ##
            
        cleaned_lines.append(line)
    
    # æ·»åŠ ç« èŠ‚æ ‡é¢˜
    result = f"\n\\newpage\n\n# {chapter_title}\n\n"
    result += '\n'.join(cleaned_lines)
    
    return result


def build_combined_markdown(theory_dir: Path, output_path: Path):
    """åˆå¹¶æ‰€æœ‰ç« èŠ‚ä¸ºå•ä¸ª Markdown æ–‡ä»¶"""
    
    content = BOOK_HEADER.format(date=datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥"))
    
    current_part = ""
    part_titles = {
        "ç¬¬1ç« ": "# ç¬¬ä¸€éƒ¨åˆ†ï¼šåŸºç¡€æ¶æ„\n\n",
        "ç¬¬5ç« ": "\n\\newpage\n\n# ç¬¬äºŒéƒ¨åˆ†ï¼šç­–ç•¥ç”Ÿæˆä¸åŠ¨ä½œè¡¨ç¤º\n\n",
        "ç¬¬10ç« ": "\n\\newpage\n\n# ç¬¬ä¸‰éƒ¨åˆ†ï¼šè®­ç»ƒæŠ€æœ¯ä¸ä¼˜åŒ–\n\n",
        "ç¬¬16ç« ": "\n\\newpage\n\n# ç¬¬å››éƒ¨åˆ†ï¼šæ„ŸçŸ¥ä¸ç©ºé—´æ™ºèƒ½\n\n",
        "ç¬¬21ç« ": "\n\\newpage\n\n# ç¬¬äº”éƒ¨åˆ†ï¼šæŠ“å–ä¸è¿åŠ¨è§„åˆ’\n\n",
        "ç¬¬24ç« ": "\n\\newpage\n\n# ç¬¬å…­éƒ¨åˆ†ï¼šå‰æ²¿æ¨¡å‹è§£æ\n\n",
        "ç¬¬29ç« ": "\n\\newpage\n\n# ç¬¬ä¸ƒéƒ¨åˆ†ï¼šè¯„ä¼°ä¸æ¨ç†\n\n",
        "é™„å½•A": "\n\\newpage\n\n# é™„å½•\n\n",
    }
    
    for chapter_title, filename in CHAPTERS:
        # æ·»åŠ éƒ¨åˆ†æ ‡é¢˜
        for part_key, part_title in part_titles.items():
            if chapter_title.startswith(part_key) and current_part != part_key:
                content += part_title
                current_part = part_key
                break
        
        filepath = theory_dir / filename
        if not filepath.exists():
            print(f"[WARN] è·³è¿‡ä¸å­˜åœ¨çš„æ–‡ä»¶: {filename}")
            continue
            
        print(f"[CHAPTER] å¤„ç†: {chapter_title}")
        chapter_content = filepath.read_text(encoding='utf-8')
        content += clean_markdown(chapter_content, chapter_title)
    
    # å†™å…¥åˆå¹¶æ–‡ä»¶
    output_path.write_text(content, encoding='utf-8')
    print(f"\n[OK] åˆå¹¶å®Œæˆ: {output_path}")
    print(f"   æ–‡ä»¶å¤§å°: {output_path.stat().st_size / 1024:.1f} KB")
    
    return output_path


def build_pdf(markdown_path: Path, output_path: Path):
    """ä½¿ç”¨ pandoc ç”Ÿæˆ PDF"""
    print("\n[INFO] ç”Ÿæˆ PDF...")
    
    cmd = [
        "pandoc",
        str(markdown_path),
        "-o", str(output_path),
        "--pdf-engine=xelatex",
        "-V", "mainfont=Noto Sans CJK SC",
        "-V", "monofont=Noto Sans Mono CJK SC",
        "--highlight-style=tango",
        "--toc",
        "--toc-depth=3",
    ]
    
    try:
        subprocess.run(cmd, check=True)
        print(f"[OK] PDF ç”Ÿæˆå®Œæˆ: {output_path}")
        print(f"   æ–‡ä»¶å¤§å°: {output_path.stat().st_size / 1024 / 1024:.1f} MB")
    except subprocess.CalledProcessError as e:
        print(f"[ERR] PDF ç”Ÿæˆå¤±è´¥: {e}")
        print("   è¯·ç¡®ä¿å·²å®‰è£… pandoc å’Œ texlive-xetex")
        print("   Ubuntu: sudo apt install pandoc texlive-xetex texlive-lang-chinese fonts-noto-cjk")
    except FileNotFoundError:
        print("[ERR] æœªæ‰¾åˆ° pandocï¼Œè¯·å…ˆå®‰è£…")
        print("   Ubuntu: sudo apt install pandoc")


def build_html(markdown_path: Path, output_path: Path):
    """ä½¿ç”¨ pandoc ç”Ÿæˆ HTML"""
    print("\nğŸŒ ç”Ÿæˆ HTML...")
    
    cmd = [
        "pandoc",
        str(markdown_path),
        "-o", str(output_path),
        "--standalone",
        "--toc",
        "--toc-depth=3",
        "-c", "https://cdn.jsdelivr.net/npm/github-markdown-css/github-markdown.min.css",
        "--metadata", "title=VLA Handbook",
    ]
    
    try:
        subprocess.run(cmd, check=True)
        print(f"[OK] HTML ç”Ÿæˆå®Œæˆ: {output_path}")
    except (subprocess.CalledProcessError, FileNotFoundError) as e:
        print(f"[ERR] HTML ç”Ÿæˆå¤±è´¥: {e}")


def main():
    parser = argparse.ArgumentParser(description="Build VLA Handbook Book")
    parser.add_argument("--pdf", action="store_true", help="Generate PDF")
    parser.add_argument("--html", action="store_true", help="Generate HTML")
    args = parser.parse_args()
    
    # è·¯å¾„è®¾ç½®
    script_dir = Path(__file__).resolve().parent
    theory_dir = script_dir.parent / "theory"
    output_dir = script_dir / "output"
    output_dir.mkdir(exist_ok=True)
    
    print(f"[INFO] Theory ç›®å½•: {theory_dir}")
    print(f"[INFO] è¾“å‡ºç›®å½•: {output_dir}")
    
    # ç”Ÿæˆåˆå¹¶çš„ Markdown
    md_path = output_dir / "VLA_Handbook.md"
    build_combined_markdown(theory_dir, md_path)
    
    # ç”Ÿæˆ PDF
    if args.pdf:
        pdf_path = output_dir / "VLA_Handbook.pdf"
        build_pdf(md_path, pdf_path)
    
    # ç”Ÿæˆ HTML
    if args.html:
        html_path = output_dir / "VLA_Handbook.html"
        build_html(md_path, html_path)
    
    print("\n[OK] æ„å»ºå®Œæˆ!")
    print(f"   è¾“å‡ºç›®å½•: {output_dir}")


if __name__ == "__main__":
    main()

